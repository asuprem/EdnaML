To truly replicate runs properly, we need to track a few things:






EdnaML needs to track:

config file used for something
Any custom things added for this execution



We will define a `run` as an execution with a specific config file, excepting the SAVE parameter, which is required to sync runs

If config files are different in some way, i.e. some parameter is changed, that constitutes a new run (exceptions are when a user changes something that is meant to clarify and WOULD NOT CONFLICT WITH A PRIOR RUN, for continuation, i.e. if we discover that the transformations were not set correctly but don't need to restart this run, and we will discuss this later)


In a run, we will need to record the following:
    The exact way this run occured. 
    The exact files used in this run
    The metrics for this run


The exact way this run occured:
    every EdnaML command records, into an EdnaLog, that it occured. This way, if we are asked to reconstruct a run, we can programmatically perform the commands again. ðŸŸ¢
        MODIFIED: only the primary commands of init, add(), apply() need to be done. This is because the individual add commands do not store the source code ðŸŸ¢
        FUTURE: we will need to convert the addStorage and addStorageInstance to backend methods (_addStorage). Then create new addStorage commands. Then these commands will 
            pickle the actual object, and keep a name for the object in the alias list. This adds significant complexity. So we will deal with them later.
    If we "continue a run", we can ask ednaml to execute the EdnaLog, or redo our commands
    When we redo our commands, and it is an existing run, EdnaML will simply move the old EdnaLog to EdnaLog<int> and create a new EdnaLog
    We keep a running list of EdnaLog (or rather, the most recent increment) in run.yml, which contains the run information (e.g. `mostRecentRunNumber`)

    If the exact way this run occured is different, what then...and how do we detect difference???
        Detecting difference: when we do apply, or train/eval(), we check whether our current EdnaLog matches the prior EdnaLogs
        If it does, then we ask user whether they want to proceed with a different run

    What does an EdnaLog actually record
        The sequence of commands. Specifically:
            command
            keyword1:
            argument1:
            alias1:
            etc, etc

            Alias is when the argument should be replaced by something else
            This is, for now, ONLY for paths to files, for reconstruction, because we will keep a copy of config, and input files in the run
            Anything else that is NOT an outside reference, will get saved as argument without alias

            https://stackoverflow.com/questions/10724495/getting-all-arguments-and-values-passed-to-a-function


The exact files used in this run
    Any EdnaML or EdnaDeploy (or variety) function that accepts files also performs a copy of these files into the `run` folder.
    `run` folder is created and saved during the initialization process, along with helper functions, etc that save the run directory and add an update to the EdnaLog
    When we save the command, we also add an alias, basically an update file path that takes the basename. This means the file will be in the run directory
    What happens when 2 files are named the same -- simply, the alias is updated, silly...


The metrics for this run
    Ok, this is more complicated...
    So, we need to attach Metrics to a Deployment or Execution
    During execution, Metrics are given access to the results, plus anything else they might need
    Metrics, like plugins, come from a file...or are built in

    During a run, any metrics we compute are saved for that run.
    So, EdnaML, or BaseTrainer, will record all metrics as and when they appear in a MetricsManager
    Then, MetricsManager saves when BaseTrainer saves, etc, etc
    The Save can take advantage of SaveStorage for specifics, i.e. saving in Local, or Azure, or MlFlow, etc...

    For a deployment, this is different
    Deployments can happen for any dataset, etc, etc
    So...what to do about Metrics in this case...

    So, we need an EdnaML and maybe an EdnaDeploy section in our saves
    Deployments do not rely on each other
    They are independent of each other
    BUT, plugins ina deployment are NOT ephemeral
    But, also, plugins are loaded indendently
    But also, plugins are tracked independently
    
    At some point in future, we will need to distinguish a ModelPlugin and a DataPlugin
    ModelPlugin tied to a Model
    DataPlugin tied to Data, such as a KMeansProxy; This needs the Data architecture, so we will deal with this later...
        But briad strokes: we can register a data source with EdnaML
        When registering, we will specifically register a Datareader, or something.
        Figure this out later...
    

    So... Metrics
    we track through mlflow, right...?
    So during save, we use MetricManager.save to save through mlflow
    things tagged for all metrics:
        epoch
        step
        the run-id for this run

TODO:
    establish EdnaLog
    establish saving and checking if commands are same
    THEN, establish runs as canonical
    establish that if something does not have a run, we will create one next time

        



NOTE -- Plugins update:
    plugins need to be saved in their individual files
    This is to prevent overwriting, I think



------------------
Ok, now that we have the beginnings of EdnaExecutionLog, let's deal with a run.

We will make them backwards compatible, so existing versions are converted to runs
We won't deal with config checking, so just assume that a run is perfect. So basically a single run per experiment


What is the process for Runs...?

Well, we are given a way to index an experiment from the SaveMetadata, specifically the experiment information

So, based on the ConfigStorage method, we will need to check if that experiment already exists


Problem right now -- we are trying to do both Gdrive backup AND mongo config backup

Can both work simultaneously

YES, they have to

Basically, we have a local backup.

Then user decides whether the local version should be backed up to Gdrive, or network drive, or mongo, or some combination


So, to rehash, what are the things we are backing up:

Config              -> ConfigBackup ----------> the final EdnaMLConfig. Unique to a Run.
Model               -> ModelBackup  ----------> Model .pth files (per save frequency). Unique to a Run.
ModelArtifacts      -> ModelArtifactsBackup --> Artifacts .pth files (per save frequency). Unique to a Run.
ModelPlugins        -> ModelPluginBackup -----> Plugin .pth (per epoch). Unique to a Run.
Metrics             -> MetricsBackup ---------> Per epoch (OR step, basically a continuous backup, I think). Unique to a Run.

DataPlugins         -> DataPluginBackup ------> Unique to a Datareader


So, in EdnaML, EdnaDeploy

- during Save and Load, we rely on implicit assumption of a file backup.
- Now, we need to, in Save and Load, call the respective Backup classes, and use their save and load thingamajigs
- We will use the file as the canonical notion
- A <ItemBackup> class is provided a file, and an indexing mechanism for SAVING
- for Loading, <ItemBackup> class is provided an indexing mechanism, a local path, and must return a path to a file stored in that local path


Examples

1.  we execute a ml config, with inferred ItemBackups to gdrive
    When we execute that ml config again, EdnaML/Deploy will identify the Run / Run Id / Run idx
    They do this based on the ConfigBackup specified in our config, and choose the most recent run which ConfigBackup must implement (we can adjust this later to control specific runs)
    Then that run-id/x combined with the SaveMetadata allows ModelBackup to copy the model file, model artifacts to copy the model artifacts file, model plugins to etc, etc

2. We provide the config-identifier to edna. It wil download the respective config to the local SaveMetadata (this is the job of the mongobackup...etc.etc)

So, our task right now is to create the custom ConfigBackup that can accept a StorageClass (or the default LocalStorage)





Triggers --> but these are possibly based on ModelPlugins or DataPlugins, so we will deal with these later. These are EdnaJobs
