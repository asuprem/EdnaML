{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJQ1vkUS-4hv"
      },
      "source": [
        "# 0. Fake News Labeler\n",
        "\n",
        "This notebook contains code to label the FNC-Core dataset with a team of pre-trained experts. \n",
        "\n",
        "## Dataset\n",
        "\n",
        "The FNC (Fake-News-Covid) dataset is a twitter-sampled stream of tweets for fake news detection.It is collected along with its social context of usernames, account details, retweets, likes, quote tweets, among other features.\n",
        "\n",
        "FNC has several components:\n",
        "\n",
        "- **FNC-Raw**: The raw stream collected from the Twitter Sampled Stream\n",
        "- **FNC-Filtered**: The filtered stream obtained from the Twitter Sampled Stream with covid-related keyword filters.\n",
        "- **FNC-Neighbors**: Samples from FNC-Raw that were not filtered into FNC-Filtered due to missing, censored, or mispelled keywords, but are semantically similar to FNC-Filtered. We detect these with embedding extensions.\n",
        "- **FNC-Extended**: FNC-Filtered combined with FNC-Neighbors to yield a more complete filtered dataset. We can refer to monthly subsets as FNC-Extended-\\<MonthYear\\>, e.g. FNC-Extended-Jan2020\n",
        "\n",
        "These are the unlabeled parts of FNC. With this notebook, we can label a subset of FNC-Extended with high accuracy. These also fall under several components:\n",
        "\n",
        "- **FNC-Extended-Oracle**: Samples from FNC-Extended that are labeled with human annotators. FNC-Extended-Oracle has 10k samples. Since FNC-Extended spans 25 months, we have 400 labeled samples per month.\n",
        "- **FNC-Expert-\\<Expert\\>-\\<MonthYear\\>**: The FNC-Extended-\\<MonthYear\\> subset is labeled by an expert with name \\<Expert\\>.\n",
        "- **FNC-Labeled**: We integrate labels from several experts to generate the final labeled set. We can evaluate labeling accuracy on the intersection with FNC-Extended-Oracle. Monthly subsets are FNC-Labeled-\\<MonthYear\\>\n",
        "\n",
        "## This Notebook\n",
        "In this notebook, we will:\n",
        "\n",
        "- Generate FNC-Filtered (unless the raw data is already of this format...should recheck)\n",
        "- Possibly generate FNC-Neighbors (unless raw data is already of this format...should recheck)\n",
        "- Generate FNC-Expert. For this, we have a list of experts already generated. We will use EdnaML Deployments to load an expert, then load our data from Azure, then label each point, and save the generated label. If a model abstains for some point, we will score that as a [-1]. True News is [1]. Fake News is [0]. Then, the labels will be saved to this instance. We will download the labels, labeled as FNC-Expert-[ExpertName]-[MonthYear]. For each file, we will also save any necessary label characteristics in the same line, i.e.: [label,L-score, model-l-score-threshold, etc]\n",
        "- Possibly Generate FNC-Labeled. Once we have several expert labeled sets, we will integrate them together using Snorkel, EEWS, etc... Snorkel is easy to implement. We might skip EEWS and ATEAM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMDUT5TWE7-N",
        "outputId": "8b79d0ac-6333-4c50-f42d-6f48b5132bf1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m87.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.12.1-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m108.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.26.14)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.12.1 tokenizers-0.13.2 transformers-4.26.1\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUETMOy3gGvu"
      },
      "source": [
        "# 1. Setup -- Gdrive Connect, Git clone, Model  Downloads"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4h8JjeAfpDo"
      },
      "source": [
        "## Connect to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_P6hPRDqyi4",
        "outputId": "33807a39-f30e-4045-c73a-5afc40de390f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Mar  7 15:17:31 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   68C    P0    31W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aZtdWNypnP72"
      },
      "outputs": [],
      "source": [
        "import os.path as osp\n",
        "import os, glob, shutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xiPHbFAZjWlv",
        "outputId": "41fc13e9-2cc0-4c1f-879a-988ae35f977c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Set Gogle Drive Connection\n",
        "#if not osp.exists(\"./drive\"):\n",
        "from google.colab import drive\n",
        "\n",
        "#https://stackoverflow.com/questions/69822304/google-colab-google-drive-can%c2%b4t-be-mounted-anymore-browser-popup-google-dri\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqJoyEW1f_a1"
      },
      "source": [
        "## Git Clone"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oisq4kE8IMHi"
      },
      "source": [
        "### From Source"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bJfycQTLVkEj"
      },
      "outputs": [],
      "source": [
        "! rm -rf -- GLAMOR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "goBMKUmagBIx",
        "outputId": "92da24bf-40b0-4ab6-a2b9-3c094dc91ced"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'GLAMOR'...\n",
            "remote: Enumerating objects: 9540, done.\u001b[K\n",
            "remote: Counting objects: 100% (1443/1443), done.\u001b[K\n",
            "remote: Compressing objects: 100% (469/469), done.\u001b[K\n",
            "remote: Total 9540 (delta 892), reused 1373 (delta 827), pack-reused 8097\u001b[K\n",
            "Receiving objects: 100% (9540/9540), 2.53 MiB | 5.78 MiB/s, done.\n",
            "Resolving deltas: 100% (6285/6285), done.\n"
          ]
        }
      ],
      "source": [
        "! git clone -b master https://github.com/asuprem/GLAMOR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T80AC-kx4v4Y",
        "outputId": "3ef83ae5-7d41-4571-bad5-be756ffffefd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Obtaining file:///content/GLAMOR\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.8/dist-packages (from ednaml==0.1.5) (1.2.1)\n",
            "Requirement already satisfied: torch>=1.10.* in /usr/local/lib/python3.8/dist-packages (from ednaml==0.1.5) (1.13.1+cu116)\n",
            "Collecting torchinfo>=1.6.5\n",
            "  Downloading torchinfo-1.7.2-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: torchvision>=0.11.* in /usr/local/lib/python3.8/dist-packages (from ednaml==0.1.5) (0.14.1+cu116)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.8/dist-packages (from ednaml==0.1.5) (8.4.0)\n",
            "Requirement already satisfied: tqdm>=4.63.* in /usr/local/lib/python3.8/dist-packages (from ednaml==0.1.5) (4.64.1)\n",
            "Collecting sentencepiece>=0.1.96\n",
            "  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m67.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sortedcontainers>=2.4.0 in /usr/local/lib/python3.8/dist-packages (from ednaml==0.1.5) (2.4.0)\n",
            "Requirement already satisfied: pyyaml>=6.0 in /usr/local/lib/python3.8/dist-packages (from ednaml==0.1.5) (6.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.2->ednaml==0.1.5) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.2->ednaml==0.1.5) (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.2->ednaml==0.1.5) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.2->ednaml==0.1.5) (1.10.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.*->ednaml==0.1.5) (4.5.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision>=0.11.*->ednaml==0.1.5) (2.25.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision>=0.11.*->ednaml==0.1.5) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision>=0.11.*->ednaml==0.1.5) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision>=0.11.*->ednaml==0.1.5) (1.26.14)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision>=0.11.*->ednaml==0.1.5) (4.0.0)\n",
            "Installing collected packages: sentencepiece, torchinfo, ednaml\n",
            "  Running setup.py develop for ednaml\n",
            "Successfully installed ednaml-0.1.5 sentencepiece-0.1.97 torchinfo-1.7.2\n"
          ]
        }
      ],
      "source": [
        "!pip install -e GLAMOR/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5j3WfN0fpIT"
      },
      "source": [
        "###  From PyPi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7dkOhZi08dU"
      },
      "outputs": [],
      "source": [
        "#! python -V"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FwqgjiZ331ik"
      },
      "outputs": [],
      "source": [
        "#! pip3 install --pre ednaml==0.1.4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQCbxSJDf7Ix"
      },
      "source": [
        "## AlBERT / ModelFile Data Download\n",
        "\n",
        "(And assume they are FNC-Extended-MonthYear)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "27LK1AmgfuCk"
      },
      "outputs": [],
      "source": [
        "# Commented in for Sp 23\n",
        "!cp ./drive/MyDrive/Datasets/PreTrained/Albertv2/30k* .\n",
        "!cp ./drive/MyDrive/Datasets/PreTrained/Albertv2/pytorch_model.bin ."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Restart Runtime Here!!!!"
      ],
      "metadata": {
        "id": "TfspmIFRmgd6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KjvT_ZJovGY"
      },
      "source": [
        "# 2. Raw Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KoQKEy4Douez"
      },
      "outputs": [],
      "source": [
        "tweet_file = \"tweets-2020-01-22\"\n",
        "proxy = 40"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqCdOF7tCj8N"
      },
      "source": [
        "# 3. Generating FNC-Filtered from FNC-Raw\n",
        "\n",
        "Here, we will use an EdnaML workflow to generate FNC-Filtered from FNC-Raw. This is not really a learnable model, rather a simple keyword matcher.\n",
        "\n",
        "Essentially, we will build a workflow where we:\\\n",
        "\n",
        "1. Crawl an FNC Source and download if it does not exist\n",
        "2. Create datashards from the Source, with only testing data since there is no \"training\" to be performed\n",
        "3. Deploy a ModelAbstract model that reads a batch of raw text data, and checks whether elements of this batch contain our keywords. If they do, we label 1. If they do not, we label 0. \n",
        "4. The Deployment thus generates 2 outputs: a file containing fnc-filtered, and a file fnc-nonfiltered"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zEwLZP2RnPe3"
      },
      "outputs": [],
      "source": [
        "# cleanup\n",
        "!rm -rf -- test-datashard-artifacts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EbgIkVzUi8RM"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "upU2x5V1CFqi",
        "outputId": "b88c3fbb-95e4-4304-e32a-f8fdbb67f53e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.13.1+cu116'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import torch\n",
        "import ednaml\n",
        "import glob, os\n",
        "from ednaml.core import EdnaDeploy, EdnaML\n",
        "torch.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fj4K8740CFoI"
      },
      "outputs": [],
      "source": [
        "config = \"./GLAMOR/profiles/FNC/filtered/config.yml\"\n",
        "crawler_generator = \"./GLAMOR/profiles/FNC/fnc-crawler.py\"\n",
        "filter_model_deployment = \"./GLAMOR/profiles/FNC/fnc-filtered.py\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lstv_fo4CFlo"
      },
      "outputs": [],
      "source": [
        "ed = EdnaDeploy(config=config)\n",
        "ed.cfg.DEPLOYMENT.OUTPUT_ARGS[\"basename\"] = \"%s\"%tweet_file\n",
        "ed.cfg.DEPLOYMENT.DATAREADER.CRAWLER_ARGS[\"azfile\"] = \"%s.json.gz\"%tweet_file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZNRsfX7HAGj",
        "outputId": "9c71bbbe-ff80-48a5-c56b-45db7c5a5763"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "15:22:00 Adding a crawler, from /content/GLAMOR/profiles/FNC/fnc-crawler.py, with inferred name FNCCrawler\n",
            "15:22:00 Adding a generator, from /content/GLAMOR/profiles/FNC/fnc-crawler.py, with inferred name FNCRawGenerator\n",
            "15:22:00 Adding a model, from /content/GLAMOR/profiles/FNC/fnc-filtered.py, with inferred name FNCFilter\n",
            "15:22:00 Adding a deployment, from /content/GLAMOR/profiles/FNC/fnc-filtered.py, with inferred name FNCFilterDeployment\n",
            "15:22:00 ****************************************\n",
            "15:22:00 \n",
            "15:22:00 \n",
            "15:22:00 Using the following configuration:\n",
            "15:22:00 DEPLOYMENT:\n",
            "  DATAREADER:\n",
            "    CRAWLER_ARGS:\n",
            "      azcontainer: edna-covid-raw\n",
            "      azfile: tweets-2020-01-22.json.gz\n",
            "      azstorage: ednadatasets\n",
            "    DATAREADER: AlbertReader\n",
            "    DATASET_ARGS:\n",
            "      classificationclass:\n",
            "      - fnews\n",
            "      shard_replace: false\n",
            "      shardname: fnc-raw-shard\n",
            "      shardpath: datashard-artifacts\n",
            "      shardsize: 20000\n",
            "      shuffle: false\n",
            "    GENERATOR: null\n",
            "    GENERATOR_ARGS: {}\n",
            "  DEPLOY: BaseDeploy\n",
            "  DEPLOYMENT_ARGS: {}\n",
            "  EPOCHS: 1\n",
            "  OUTPUT_ARGS:\n",
            "    basename: tweets-2020-01-22\n",
            "    filtered_output: filtered\n",
            "    unfiltered_output: unfiltered\n",
            "  PLUGIN:\n",
            "    HOOKS: always\n",
            "    RESET: false\n",
            "EXECUTION:\n",
            "  DATAREADER:\n",
            "    CRAWLER_ARGS: {}\n",
            "    DATAREADER: DataReader\n",
            "    DATASET_ARGS: {}\n",
            "    GENERATOR: null\n",
            "    GENERATOR_ARGS: {}\n",
            "  EPOCHS: 10\n",
            "  FP16: false\n",
            "  MODEL_SERVING: false\n",
            "  OPTIMIZER_BUILDER: ClassificationOptimizer\n",
            "  PLUGIN:\n",
            "    HOOKS: always\n",
            "    RESET: false\n",
            "  SKIPEVAL: false\n",
            "  TEST_FREQUENCY: 1\n",
            "  TRAINER: BaseTrainer\n",
            "  TRAINER_ARGS:\n",
            "    accumulation_steps: 1\n",
            "LOGGING:\n",
            "  INPUT_SIZE: null\n",
            "  STEP_VERBOSE: 100\n",
            "LOSS: []\n",
            "LOSS_OPTIMIZER:\n",
            "- BASE_LR: 0.001\n",
            "  LR_BIAS_FACTOR: 1.0\n",
            "  OPTIMIZER: Adam\n",
            "  OPTIMIZER_KWARGS: {}\n",
            "  OPTIMIZER_NAME: opt-1\n",
            "  WEIGHT_BIAS_FACTOR: 0.0005\n",
            "  WEIGHT_DECAY: 0.0005\n",
            "LOSS_SCHEDULER:\n",
            "- LR_KWARGS:\n",
            "    step_size: 20\n",
            "  LR_SCHEDULER: StepLR\n",
            "  SCHEDULER_NAME: opt-1\n",
            "MODEL:\n",
            "  BUILDER: ednaml_model_builder\n",
            "  MODEL_ARCH: FNCFilter\n",
            "  MODEL_BASE: NoBase\n",
            "  MODEL_KWARGS:\n",
            "    filter_list:\n",
            "    - covid\n",
            "    - corona\n",
            "    - mask\n",
            "    - wuhan\n",
            "    - n95\n",
            "    - sars\n",
            "    - monkey\n",
            "    - pandemic\n",
            "    - social\n",
            "    - quarantin\n",
            "    - virus\n",
            "    - infect\n",
            "    - lock\n",
            "    - ppe\n",
            "    - variant\n",
            "    - vaccine\n",
            "    - travel\n",
            "    - omicron\n",
            "    - ivermectin\n",
            "    - plandemic\n",
            "    - 5g\n",
            "    - gates\n",
            "    - hoax\n",
            "    - bioweapon\n",
            "    - bat\n",
            "    - fauci\n",
            "  MODEL_NORMALIZATION: bn\n",
            "  PARAMETER_GROUPS:\n",
            "  - opt-1\n",
            "MODEL_PLUGIN: {}\n",
            "OPTIMIZER:\n",
            "- BASE_LR: 0.001\n",
            "  LR_BIAS_FACTOR: 1.0\n",
            "  OPTIMIZER: Adam\n",
            "  OPTIMIZER_KWARGS: {}\n",
            "  OPTIMIZER_NAME: opt-1\n",
            "  WEIGHT_BIAS_FACTOR: 0.0005\n",
            "  WEIGHT_DECAY: 0.0005\n",
            "SAVE:\n",
            "  CHECKPOINT_DIRECTORY: ./drive/MyDrive/Projects/FNC/Models/\n",
            "  DRIVE_BACKUP: false\n",
            "  LOG_BACKUP: false\n",
            "  MODEL_BACKBONE: offshelf\n",
            "  MODEL_CORE_NAME: fnc-filter\n",
            "  MODEL_QUALIFIER: raw\n",
            "  MODEL_VERSION: 1\n",
            "  SAVE_FREQUENCY: 5\n",
            "  STEP_SAVE_FREQUENCY: 0\n",
            "SCHEDULER:\n",
            "- LR_KWARGS:\n",
            "    step_size: 20\n",
            "  LR_SCHEDULER: StepLR\n",
            "  SCHEDULER_NAME: opt-1\n",
            "STORAGE:\n",
            "  STORAGE_ARGS: {}\n",
            "  TYPE: BaseStorage\n",
            "  URL: ./\n",
            "TEST_TRANSFORMATION:\n",
            "  ARGS: {}\n",
            "  BATCH_SIZE: 128\n",
            "  WORKERS: 2\n",
            "TRAIN_TRANSFORMATION:\n",
            "  ARGS: {}\n",
            "  BATCH_SIZE: 128\n",
            "  WORKERS: 2\n",
            "extensions:\n",
            "- EXECUTION\n",
            "- SAVE\n",
            "- STORAGE\n",
            "- TRANSFORMATION\n",
            "- MODEL\n",
            "- LOSS\n",
            "- OPTIMIZER\n",
            "- SCHEDULER\n",
            "- LOSS_OPTIMIZER\n",
            "- LOSS_SCHEDULER\n",
            "- LOGGING\n",
            "- DEPLOYMENT\n",
            "- MODEL_PLUGIN\n",
            "\n",
            "15:22:00 \n",
            "15:22:00 \n",
            "15:22:00 ****************************************\n",
            "/content/GLAMOR/src/ednaml/core/EdnaML.py:222: UserWarning: Mode is `test` but weights is `None`. This will cause issues when EdnaML attempts to load weights\n",
            "  warnings.warn(\n",
            "15:22:00 No previous stop detected. Will start from epoch 0\n",
            "15:22:00 Reading data with DataReader AlbertReader\n",
            "15:22:00 Default CRAWLER is <class 'ednaml.crawlers.Crawler'>\n",
            "15:22:00 Default DATASET is <class 'ednaml.generators.AlbertGenerator.AlbertDataset'>\n",
            "15:22:00 Default GENERATOR is <class 'ednaml.generators.AlbertGenerator.AlbertGenerator'>\n",
            "15:22:00 Updating GENERATOR to queued class FNCRawGenerator\n",
            "15:22:00 Updating CRAWLER to FNCCrawler\n",
            "15:22:00 Crawling https://ednadatasets.blob.core.windows.net/edna-covid-raw/tweets-2020-01-22.json.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Registering a crawler: <class './GLAMOR/profiles/FNC/fnc-crawler.py.FNCCrawler'>, from file: /content/GLAMOR/profiles/FNC/fnc-crawler.py\n",
            "Registering a generator: <class './GLAMOR/profiles/FNC/fnc-crawler.py.FNCRawGenerator'>, from file: /content/GLAMOR/profiles/FNC/fnc-crawler.py\n",
            "Registering a model: <class './GLAMOR/profiles/FNC/fnc-filtered.py.FNCFilter'>, from file: /content/GLAMOR/profiles/FNC/fnc-filtered.py\n",
            "Registering a deployment: <class './GLAMOR/profiles/FNC/fnc-filtered.py.FNCFilterDeployment'>, from file: /content/GLAMOR/profiles/FNC/fnc-filtered.py\n",
            "5637377/5637377 bytes [████████████████████████████████████████████████████████████████████████████████████████████████████]\n",
            "Download of tweets-2020-01-22.json.gz to https://ednadatasets.blob.core.windows.net/edna-covid-raw/tweets-2020-01-22.json.gz completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "15:22:05 Generating dataloader `FNCRawGenerator` with `test` mode\n",
            "15:22:20 Generated test data/query generator\n",
            "15:22:20 Loaded ednaml_model_builder from ednaml.models to build model\n",
            "15:22:20 Finished instantiating model with FNCFilter architecture\n",
            "15:22:20 Adding plugins after constructing model\n",
            "15:22:20 No saved model weights provided. Inferring weights path.\n",
            "15:22:20 No previous stop exists. Not loading weights.\n",
            "15:22:20 Model Summary retured the following error:\n",
            "15:22:20 Traceback (most recent call last):\n",
            "  File \"/content/GLAMOR/src/ednaml/core/EdnaML.py\", line 888, in getModelSummary\n",
            "    self.cfg.TRAIN_TRANSFORMATION.INPUT_SIZE,\n",
            "AttributeError: 'TransformationConfig' object has no attribute 'INPUT_SIZE'\n",
            "\n",
            "15:22:20 1 GPUs available\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NOT saving metadata. saveMetadata() function not set up.\n"
          ]
        }
      ],
      "source": [
        "ed.add(crawler_generator)\n",
        "ed.add(filter_model_deployment)\n",
        "ed.apply()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xkWzzI6XCFjM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33706837-652d-4e07-922c-cbef12c8f9b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "15:22:20 Starting deployment\n",
            "15:22:20 Logging to:\tfnc-filter-v1-offshelf-raw-logger.log\n",
            "15:22:20 Setting up plugin hooks. Plugins will fire during:  always\n",
            "15:22:20 Executing deployment for  1 epochs\n",
            "15:22:20 Starting epoch 0\n",
            "15:22:21 Executing end of epoch steps\n",
            "15:22:21 Completed deployment task.\n"
          ]
        }
      ],
      "source": [
        "ed.deploy()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cleanup"
      ],
      "metadata": {
        "id": "FOwc42Dv5i6H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "if os.path.exists(tweet_file+\".json\"):\n",
        "  os.remove(tweet_file+\".json\")\n",
        "if os.path.exists(tweet_file+\".json.gz\"):\n",
        "  os.remove(tweet_file+\".json.gz\")\n",
        "! rm test-datashard-artifacts/fnc-raw*\n",
        "! rm train-datashard-artifacts/fnc-raw*\n",
        "! rm test-datashard-artifacts/len.txt"
      ],
      "metadata": {
        "id": "1grPg6X_5giI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d7b46c3-8a6f-4259-b70d-c1761b08aaf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'train-datashard-artifacts/fnc-raw*': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dckc897vD9t_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48135a4f-422c-44ad-cb77-9e77f4c565b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17718 tweets-2020-01-22-filtered.json\n"
          ]
        }
      ],
      "source": [
        "! wc -l $tweet_file-filtered.json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! wc -l $tweet_file-unfiltered.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "idvTSx5L4rSV",
        "outputId": "c453a234-8865-4f43-8af8-df18bb0323a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6333 tweets-2020-01-22-unfiltered.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Filtered subset scaling (for class)"
      ],
      "metadata": {
        "id": "bBLksdNI5Ukb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filter_scale = 1    # Notes: NA\n",
        "unfilter_scale = 1  # Notes: NA"
      ],
      "metadata": {
        "id": "Z6wqZBNo5YtY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Scaling"
      ],
      "metadata": {
        "id": "kqSK-TBM5Z9v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "tf_filtered = tweet_file + \"-filtered.json\"\n",
        "tf_unfiltered = tweet_file + \"-unfiltered.json\"\n",
        "# Set reduction scale\n",
        "import random\n",
        "random.seed(34598344)\n",
        "# Reduce filtered.json\n",
        "filt_obj = open(tf_filtered, \"r\")\n",
        "filtout_obj = open(tf_filtered + \"2\", \"w\")\n",
        "for row in filt_obj:\n",
        "    if random.random() <= filter_scale:\n",
        "      filtout_obj.write(row)\n",
        "filtout_obj.close()\n",
        "filt_obj.close()\n",
        "# Reduce unfiltered.json\n",
        "unfilt_obj = open(tf_unfiltered, \"r\")\n",
        "unfiltout_obj = open(tf_unfiltered + \"2\", \"w\")\n",
        "for row in unfilt_obj:\n",
        "    if random.random() <= unfilter_scale:\n",
        "      unfiltout_obj.write(row)\n",
        "unfiltout_obj.close()\n",
        "unfilt_obj.close()\n",
        "# Delete old files\n",
        "os.remove(tf_filtered)\n",
        "os.remove(tf_unfiltered)\n",
        "# Rename to old file name\n",
        "os.rename(tf_filtered+\"2\", tf_filtered)\n",
        "os.rename(tf_unfiltered+\"2\", tf_unfiltered)"
      ],
      "metadata": {
        "id": "kmSTGx8U47rY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e981c4c-5a5f-4095-ea17-fca18ab46cff",
        "id": "NItLF9wU5EID"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17718 tweets-2020-01-22-filtered.json\n"
          ]
        }
      ],
      "source": [
        "! wc -l $tweet_file-filtered.json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! wc -l $tweet_file-unfiltered.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45e15378-74e8-4c12-8124-7516c271e7b6",
        "id": "aIgD01x55EIE"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6333 tweets-2020-01-22-unfiltered.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDG0xKuTCrT5"
      },
      "source": [
        "# 4. Generating FNC-Neighbors from FNC-Filtered and FNC\n",
        "\n",
        "Here, we will take the json files generated from FNC-Filter: `filter.json` and `unfilter.json`.\n",
        "\n",
        "The filter.json content is used to fine-tune a BERT model. This BERT model implements keyword masking, that is, specific keywords are masked\n",
        "\n",
        "Then we use a cluster_estimator plugin to estimate the best number of clusters with KMeans for the training dataset.\n",
        "\n",
        "Then, we insert a high-density estimator plugin with the best number of clusters as proxies\n",
        "\n",
        "Then, we will use a Deployment to iterate through unfilter. For each, we will generate the features, and use the high-density estimator plugin to check if it exists in the high density set of existing clusters. Note that the unfilter data implements the same masking as the training model. Any samples that exist are placed in `extended.json`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUiGLd_6sbPG"
      },
      "source": [
        "## 4.1 Finetuning MLM with keyword masking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vOGkQT_yJPKq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b85955c5-7fdc-4347-e5f6-aac107726814"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'test-datashard-artifacts/fnc-filtermask*': No such file or directory\n",
            "rm: cannot remove 'train-datashard-artifacts/fnc-filtermask*': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "# Cleanup ONLY if starting from scratch, not if already doing 4.1\n",
        "# Also cleanup if switching datasets\n",
        "!rm test-datashard-artifacts/fnc-filtermask*\n",
        "!rm train-datashard-artifacts/fnc-filtermask*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pbr7XsGK_ega",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "987617d1-6cc5-4f0c-d9ed-a6a421131890"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "v38XZXs-_egb",
        "outputId": "19ed92f4-9fdd-4a54-8e26-80177647acb7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.13.1+cu116'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "import torch\n",
        "import ednaml\n",
        "import glob, os\n",
        "from ednaml.core import EdnaDeploy, EdnaML\n",
        "torch.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YKtTKmW__egb"
      },
      "outputs": [],
      "source": [
        "config = \"./GLAMOR/profiles/FNC/extension/config.yml\"\n",
        "crawler = \"./GLAMOR/profiles/FNC/fnc-crawler.py\"\n",
        "filtermask_generator = \"./GLAMOR/profiles/FNC/fnc-filtermasked.py\"\n",
        "extension_model = \"./GLAMOR/profiles/FNC/fnc-extension.py\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9WbCacu9_egb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "847842fa-1cc4-42ad-a742-04eccbfec362"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Injected key-value pair:  SAVE.MODEL_QUALIFIER, tweets-2020-01-22\n",
            "Injected key-value pair:  SAVE.MODEL_VERSION, 1\n",
            "Injected key-value pair:  SAVE.STEP_SAVE_FREQUENCY, 50000\n",
            "Injected key-value pair:  EXECUTION.EPOCHS, 10\n"
          ]
        }
      ],
      "source": [
        "eml = EdnaML(config=config, config_inject=[(\"SAVE.MODEL_QUALIFIER\", tweet_file), (\"SAVE.MODEL_VERSION\", 1), (\"SAVE.STEP_SAVE_FREQUENCY\", 50000), (\"EXECUTION.EPOCHS\", 10)])\n",
        "#eml = EdnaML(config=config, config_inject=[(\"SAVE.MODEL_QUALIFIER\", tweet_file)])\n",
        "eml.cfg.EXECUTION.DATAREADER.CRAWLER_ARGS[\"train_file\"] = \"%s-filtered.json\"%tweet_file\n",
        "eml.cfg.EXECUTION.DATAREADER.CRAWLER_ARGS[\"test_file\"] = \"%s-unfiltered.json\"%tweet_file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "45f849ad6f7f4c57a44b0dc14eb869bf",
            "c26cf79a582042a582ed0ba26b578fdd",
            "1f0a90c525354780a941cb3b04f81051",
            "9d75dd5bb7e4412ea2a2714461e609bf",
            "f93b0416a5a34076b8445983721dbd53",
            "ee145df1cc5f43f5821ab9a9a050982d",
            "26136ec52cf7423db87282048bd2669b",
            "a1aa832a2f044d4c9f2947dc78439b71",
            "91ebd0e201d7493ab8860df0c7a465c9",
            "3e356c6ed0b7449ebfb5b64b145e3c2b",
            "94558b969a4644dd9fef2195b56634fe",
            "0063c60d7e934967941f4d3651317cf1",
            "69d87a39ddaf4806be6bea061ce7bbbb",
            "165307bc2edf4550b20285e529b597a8",
            "b8552a647bf84d3a82282293a25e8e55",
            "98ceeb996fc5476a898d7fbc5c68edcf",
            "3c32349616294ab19a5ad0ed758717d2",
            "c965ec4732434d3c9b171e5311d0c40e",
            "c5c334852d4c4e5e9b80dd8964831011",
            "ad80a24b018b499586b8a140fd7f140f",
            "e19b9981868442c592d429e8842c4b7f",
            "3c2a48b943cb46fd9052e748f764891b",
            "486417de8405440ca7e1b8dcc5ae14e0",
            "efd7b476286740789d793457aeaf2a0d",
            "936d2be8d95f40b78e4230eb98bb1b8a",
            "678ee064df2144bea251d9e9579eaa9a",
            "f28579c6a63143cf93dc1be86592bbf3",
            "0345a480fa6b4874a59949d5d37d80e7",
            "d3b69c76a3474d93bfb684b69aab0c6a",
            "5019f08a2b534b6990dd7a82a79278c1",
            "03b44f76441a4ff48006f34830ac7401",
            "177ec6fbf79047dc8ae2acf8211ed41e",
            "bd0165acaf4c40e5a49b900d194f187f"
          ]
        },
        "id": "_l1QmVo6_egb",
        "outputId": "59b94f10-84c9-4833-a23a-fbdb35cf28b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "15:26:22 Adding a crawler, from /content/GLAMOR/profiles/FNC/fnc-crawler.py, with inferred name FNCCrawler\n",
            "15:26:22 Adding a generator, from /content/GLAMOR/profiles/FNC/fnc-crawler.py, with inferred name FNCRawGenerator\n",
            "15:26:22 Adding a generator, from /content/GLAMOR/profiles/FNC/fnc-filtermasked.py, with inferred name FNCFilterMaskGenerator\n",
            "15:26:22 Adding a model, from /content/GLAMOR/profiles/FNC/fnc-extension.py, with inferred name FNCAlbertModeler\n",
            "15:26:22 Adding a trainer, from /content/GLAMOR/profiles/FNC/fnc-extension.py, with inferred name FNCAlbertModelerTrainer\n",
            "/content/GLAMOR/src/ednaml/core/EdnaML.py:941: UserWarning: keyvalue deployment in REGISTERED_EDNA_COMPONENTS <class './GLAMOR/profiles/FNC/fnc-extension.py.FNCTrainingFeaturesDeploy'> is not available in self.decorator_reference. Not adding.\n",
            "  warnings.warn(\n",
            "15:26:22 ****************************************\n",
            "15:26:22 \n",
            "15:26:22 \n",
            "15:26:22 Using the following configuration:\n",
            "15:26:22 DEPLOYMENT:\n",
            "  DATAREADER:\n",
            "    CRAWLER_ARGS: {}\n",
            "    DATAREADER: DataReader\n",
            "    DATASET_ARGS: {}\n",
            "    GENERATOR: null\n",
            "    GENERATOR_ARGS: {}\n",
            "  DEPLOY: BaseDeploy\n",
            "  DEPLOYMENT_ARGS: {}\n",
            "  EPOCHS: 1\n",
            "  OUTPUT_ARGS: {}\n",
            "  PLUGIN:\n",
            "    HOOKS: always\n",
            "    RESET: false\n",
            "EXECUTION:\n",
            "  DATAREADER:\n",
            "    CRAWLER_ARGS:\n",
            "      azcontainer: edna-covid-raw\n",
            "      azfile: tweets-2020-01-22.json.gz\n",
            "      azstorage: ednadatasets\n",
            "      test_file: tweets-2020-01-22-unfiltered.json\n",
            "      train_file: tweets-2020-01-22-filtered.json\n",
            "    DATAREADER: AlbertReader\n",
            "    DATASET_ARGS:\n",
            "      classificationclass:\n",
            "      - fnews\n",
            "      data_shuffle: true\n",
            "      keyword_mask: true\n",
            "      keywords:\n",
            "      - covid\n",
            "      - corona\n",
            "      - mask\n",
            "      - wuhan\n",
            "      - n95\n",
            "      - sars\n",
            "      - monkey\n",
            "      - pandemic\n",
            "      - social\n",
            "      - quarantin\n",
            "      - virus\n",
            "      - infect\n",
            "      - lock\n",
            "      - ppe\n",
            "      - variant\n",
            "      - vaccine\n",
            "      - travel\n",
            "      - omicron\n",
            "      - ivermectin\n",
            "      - plandemic\n",
            "      - 5g\n",
            "      - gates\n",
            "      - hoax\n",
            "      - bioweapon\n",
            "      - bat\n",
            "      - fauci\n",
            "      masking: false\n",
            "      maxlen: 512\n",
            "      mlm_probability: 0.15\n",
            "      shard_replace: false\n",
            "      shardcache: true\n",
            "      shardname: fnc-filtermask-shard\n",
            "      shardpath: datashard-artifacts\n",
            "      shardsize: 20000\n",
            "      shuffle: true\n",
            "    GENERATOR: null\n",
            "    GENERATOR_ARGS:\n",
            "      from_pretrained: albert-base-v2\n",
            "      tokenizer: HFAutoTokenizer\n",
            "  EPOCHS: 10\n",
            "  FP16: false\n",
            "  MODEL_SERVING: false\n",
            "  OPTIMIZER_BUILDER: ClassificationOptimizer\n",
            "  PLUGIN:\n",
            "    HOOKS: always\n",
            "    RESET: false\n",
            "  SKIPEVAL: false\n",
            "  TEST_FREQUENCY: 1\n",
            "  TRAINER: BaseTrainer\n",
            "  TRAINER_ARGS:\n",
            "    accumulation_steps: 8\n",
            "LOGGING:\n",
            "  INPUT_SIZE:\n",
            "  - 16\n",
            "  - 512\n",
            "  STEP_VERBOSE: 100\n",
            "LOSS:\n",
            "- KWARGS:\n",
            "  - loss_class: CrossEntropyLoss\n",
            "    loss_kwargs:\n",
            "      ignore_index: -1\n",
            "  LABEL: mask_lm\n",
            "  LAMBDAS:\n",
            "  - 1.0\n",
            "  LOSSES:\n",
            "  - TorchLoss\n",
            "  NAME: mask_lm\n",
            "LOSS_OPTIMIZER:\n",
            "- BASE_LR: 0.001\n",
            "  LR_BIAS_FACTOR: 1.0\n",
            "  OPTIMIZER: Adam\n",
            "  OPTIMIZER_KWARGS: {}\n",
            "  OPTIMIZER_NAME: opt-1\n",
            "  WEIGHT_BIAS_FACTOR: 0.0005\n",
            "  WEIGHT_DECAY: 0.0005\n",
            "LOSS_SCHEDULER:\n",
            "- LR_KWARGS:\n",
            "    step_size: 20\n",
            "  LR_SCHEDULER: StepLR\n",
            "  SCHEDULER_NAME: opt-1\n",
            "MODEL:\n",
            "  BUILDER: ednaml_model_builder\n",
            "  MODEL_ARCH: FNCAlbertModeler\n",
            "  MODEL_BASE: Albert\n",
            "  MODEL_KWARGS:\n",
            "    attention_probs_dropout_prob: 0\n",
            "    embedding_size: 128\n",
            "    hidden_act: gelu\n",
            "    hidden_dropout_prob: 0\n",
            "    hidden_size: 768\n",
            "    initializer_range: 0.02\n",
            "    inner_group_num: 1\n",
            "    intermediate_size: 3072\n",
            "    layer_norm_eps: 1.0e-12\n",
            "    max_position_embeddings: 512\n",
            "    num_attention_heads: 12\n",
            "    num_hidden_groups: 1\n",
            "    num_hidden_layers: 12\n",
            "    pooling: pooled\n",
            "    type_vocab_size: 2\n",
            "    vocab_size_or_config_json_file: 30000\n",
            "  MODEL_NORMALIZATION: bn\n",
            "  PARAMETER_GROUPS:\n",
            "  - opt-1\n",
            "MODEL_PLUGIN: {}\n",
            "OPTIMIZER:\n",
            "- BASE_LR: 1.0e-05\n",
            "  LR_BIAS_FACTOR: 1.0\n",
            "  OPTIMIZER: AdamW\n",
            "  OPTIMIZER_KWARGS:\n",
            "    eps: 1.0e-06\n",
            "  OPTIMIZER_NAME: opt-1\n",
            "  WEIGHT_BIAS_FACTOR: 0.0005\n",
            "  WEIGHT_DECAY: 0.0005\n",
            "SAVE:\n",
            "  CHECKPOINT_DIRECTORY: ./drive/MyDrive/Projects/FNC/Models/\n",
            "  DRIVE_BACKUP: true\n",
            "  LOG_BACKUP: false\n",
            "  MODEL_BACKBONE: albert\n",
            "  MODEL_CORE_NAME: fnc-extension\n",
            "  MODEL_QUALIFIER: tweets-2020-01-22\n",
            "  MODEL_VERSION: 1\n",
            "  SAVE_FREQUENCY: 1\n",
            "  STEP_SAVE_FREQUENCY: 50000\n",
            "SCHEDULER:\n",
            "- LR_KWARGS:\n",
            "    gamma: 0.5\n",
            "    step_size: 5\n",
            "  LR_SCHEDULER: StepLR\n",
            "  SCHEDULER_NAME: opt-1\n",
            "STORAGE:\n",
            "  STORAGE_ARGS: {}\n",
            "  TYPE: BaseStorage\n",
            "  URL: ./\n",
            "TEST_TRANSFORMATION:\n",
            "  ARGS: {}\n",
            "  BATCH_SIZE: 16\n",
            "  WORKERS: 2\n",
            "TRAIN_TRANSFORMATION:\n",
            "  ARGS: {}\n",
            "  BATCH_SIZE: 16\n",
            "  WORKERS: 2\n",
            "extensions:\n",
            "- EXECUTION\n",
            "- SAVE\n",
            "- STORAGE\n",
            "- TRANSFORMATION\n",
            "- MODEL\n",
            "- LOSS\n",
            "- OPTIMIZER\n",
            "- SCHEDULER\n",
            "- LOSS_OPTIMIZER\n",
            "- LOSS_SCHEDULER\n",
            "- LOGGING\n",
            "- DEPLOYMENT\n",
            "- MODEL_PLUGIN\n",
            "\n",
            "15:26:22 \n",
            "15:26:22 \n",
            "15:26:22 ****************************************\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Registering a crawler: <class './GLAMOR/profiles/FNC/fnc-crawler.py.FNCCrawler'>, from file: /content/GLAMOR/profiles/FNC/fnc-crawler.py\n",
            "Registering a generator: <class './GLAMOR/profiles/FNC/fnc-crawler.py.FNCRawGenerator'>, from file: /content/GLAMOR/profiles/FNC/fnc-crawler.py\n",
            "Registering a generator: <class './GLAMOR/profiles/FNC/fnc-filtermasked.py.FNCFilterMaskGenerator'>, from file: /content/GLAMOR/profiles/FNC/fnc-filtermasked.py\n",
            "Registering a model: <class './GLAMOR/profiles/FNC/fnc-extension.py.FNCAlbertModeler'>, from file: /content/GLAMOR/profiles/FNC/fnc-extension.py\n",
            "Registering a trainer: <class './GLAMOR/profiles/FNC/fnc-extension.py.FNCAlbertModelerTrainer'>, from file: /content/GLAMOR/profiles/FNC/fnc-extension.py\n",
            "Registering a deployment: <class './GLAMOR/profiles/FNC/fnc-extension.py.FNCTrainingFeaturesDeploy'>, from file: /content/GLAMOR/profiles/FNC/fnc-extension.py\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/GLAMOR/src/ednaml/core/EdnaML.py:249: UserWarning: Model Albert is not available. Please choose one of the following: dict_keys(['resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152', 'resnext50_32x4d', 'resnext101_32x8d', 'wide_resnet50_2', 'wide_resnet101_2', 'resnet18_cbam', 'resnet34_cbam', 'resnet50_cbam', 'resnet101_cbam', 'resnet152_cbam', 'shufflenetv2_small']) if you want to load pretrained weights\n",
            "  warnings.warn(\n",
            "15:26:23 Previous stop detected. Will attempt to resume from epoch 1, step 0\n",
            "15:26:23 Loaded BaseStorage from ednaml.storage to build Storage\n",
            "15:26:23 Reading data with DataReader AlbertReader\n",
            "15:26:23 Default CRAWLER is <class 'ednaml.crawlers.Crawler'>\n",
            "15:26:23 Default DATASET is <class 'ednaml.generators.AlbertGenerator.AlbertDataset'>\n",
            "15:26:23 Default GENERATOR is <class 'ednaml.generators.AlbertGenerator.AlbertGenerator'>\n",
            "15:26:23 Updating GENERATOR to queued class FNCFilterMaskGenerator\n",
            "15:26:23 Updating CRAWLER to FNCCrawler\n",
            "15:26:24 Building Transforms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/684 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "45f849ad6f7f4c57a44b0dc14eb869bf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)ve/main/spiece.model:   0%|          | 0.00/760k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0063c60d7e934967941f4d3651317cf1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.31M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "486417de8405440ca7e1b8dcc5ae14e0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "15:26:39 Building Dataset\n",
            "15:26:39 Generating shards\n",
            "100%|██████████| 1/1 [00:17<00:00, 17.46s/it]\n",
            "15:26:56 Building Dataloader\n",
            "15:26:56 Generated training data generator with 17718 training data points\n",
            "15:26:56 Running classification model with classes: {'fnews': {'classes': 2}}\n",
            "15:26:56 Building Transforms\n",
            "15:27:00 Building Dataset\n",
            "15:27:00 Generating shards\n",
            "100%|██████████| 1/1 [00:05<00:00,  5.85s/it]\n",
            "15:27:06 Building Dataloader\n",
            "15:27:06 Generated test data/query generator\n",
            "15:27:06 Loaded ednaml_model_builder from ednaml.models to build model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading weights file pytorch_model.bin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "15:27:06 Finished instantiating model with FNCAlbertModeler architecture\n",
            "15:27:06 Adding plugins after constructing model\n",
            "15:27:06 No saved model weights provided.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Errors \n",
            "\t {'missing_keys': [], 'unexpected_keys': [], 'error_msgs': []}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "15:27:13 Model Summary retured the following error:\n",
            "15:27:13 Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torchinfo/torchinfo.py\", line 288, in forward_pass\n",
            "    _ = model.to(device)(*x, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1212, in _call_impl\n",
            "    result = forward_call(*input, **kwargs)\n",
            "  File \"/content/GLAMOR/src/ednaml/models/ModelAbstract.py\", line 140, in forward\n",
            "    feature_logits, features, secondary_outputs = self.forward_impl(\n",
            "  File \"/content/./GLAMOR/profiles/FNC/fnc-extension.py\", line 105, in forward_impl\n",
            "    outputs = self.encoder(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1212, in _call_impl\n",
            "    result = forward_call(*input, **kwargs)\n",
            "  File \"/content/GLAMOR/src/ednaml/models/Albert.py\", line 705, in forward\n",
            "    embedding_output = self.embeddings(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1212, in _call_impl\n",
            "    result = forward_call(*input, **kwargs)\n",
            "  File \"/content/GLAMOR/src/ednaml/models/Albert.py\", line 140, in forward\n",
            "    words_embeddings = self.word_embeddings(input_ids)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1212, in _call_impl\n",
            "    result = forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/sparse.py\", line 160, in forward\n",
            "    return F.embedding(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\", line 2210, in embedding\n",
            "    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)\n",
            "RuntimeError: Expected tensor for argument #1 'indices' to have one of the following scalar types: Long, Int; but got torch.cuda.FloatTensor instead (while checking arguments for embedding)\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/GLAMOR/src/ednaml/core/EdnaML.py\", line 892, in getModelSummary\n",
            "    self.model_summary = summary(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torchinfo/torchinfo.py\", line 218, in summary\n",
            "    summary_list = forward_pass(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torchinfo/torchinfo.py\", line 297, in forward_pass\n",
            "    raise RuntimeError(\n",
            "RuntimeError: Failed to run torchinfo. See above stack traces for more details. Executed layers up to: []\n",
            "\n",
            "15:27:13 Loaded ClassificationOptimizer from ednaml.optimizer to build Optimizer model\n",
            "15:27:13 Built optimizer\n",
            "15:27:13 Built scheduler\n",
            "15:27:13 Added TorchLoss with lambda = 1.0 and loss arguments {'loss_class': 'CrossEntropyLoss', 'loss_kwargs': {'ignore_index': -1}}\n",
            "15:27:13 Built loss function\n",
            "15:27:13 Built loss optimizer\n",
            "15:27:13 Built loss scheduler\n",
            "15:27:13 Loaded BaseStorage from ednaml.storage to build Storage\n",
            "15:27:13 1 GPUs available\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INPUT SIZE ====  [16, 512]\n",
            "NOT saving metadata. saveMetadata() function not set up.\n"
          ]
        }
      ],
      "source": [
        "eml.add(crawler)\n",
        "eml.add(filtermask_generator)\n",
        "eml.add(extension_model)\n",
        "eml.apply()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 744
        },
        "id": "hf5tx5mF_egb",
        "outputId": "d613c995-fed7-4916-a053-719e1305bfa1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "15:27:13 Starting training\n",
            "15:27:13 Logging to:\tfnc-extension-v1-albert-tweets-2020-01-22-logger.log\n",
            "15:27:13 Models will be saved to local directory:\tfnc-extension-v1-albert-tweets-2020-01-22\n",
            "15:27:13 Models will be backed up to drive directory:\t./drive/MyDrive/Projects/FNC/Models/fnc-extension-v1-albert-tweets-2020-01-22\n",
            "15:27:13 Models will be saved with base name:\tfnc-extension-v1_epoch[].pth\n",
            "15:27:13 Optimizers will be saved with base name:\tfnc-extension-v1_epoch[]_optimizer.pth\n",
            "15:27:13 Schedulers will be saved with base name:\tfnc-extension-v1_epoch[]_scheduler.pth\n",
            "15:27:13 Resuming training from epoch 2. Loading saved state from 1\n",
            "15:27:13 Loading model, optimizer, and scheduler from drive backup.\n",
            "15:27:13 Loading model, optimizer, and scheduler from drive backup.\n",
            "15:27:15 Finished loading model state_dict from ./drive/MyDrive/Projects/FNC/Models/fnc-extension-v1-albert-tweets-2020-01-22/fnc-extension-v1_epoch1_step0.pth\n",
            "15:27:20 Finished loading optimizer state_dict from ./drive/MyDrive/Projects/FNC/Models/fnc-extension-v1-albert-tweets-2020-01-22/fnc-extension-v1_epoch1_step0_training.pth\n",
            "15:27:20 Finished loading scheduler state_dict from ./drive/MyDrive/Projects/FNC/Models/fnc-extension-v1-albert-tweets-2020-01-22/fnc-extension-v1_epoch1_step0_training.pth\n",
            "15:27:20 Finished loading loss state_dict from ./drive/MyDrive/Projects/FNC/Models/fnc-extension-v1-albert-tweets-2020-01-22/fnc-extension-v1_epoch1_step0_training.pth\n",
            "15:27:20 Performing initial evaluation...\n",
            "15:28:00 \t\tReconstruction\tDomain 0: 0.159\n",
            "15:28:00 \tMasked Prediction\tDomain 0: 0.159\n",
            "15:28:00 \tUnmasked Prediction\tDomain 0: 0.000\n",
            "15:28:00 Starting training from 2\n",
            "15:28:00 Parameter Group `opt-1`: Starting epoch 2 with 1100 steps and learning rate 1.00000E-05\n",
            "15:28:22 Epoch2.99\tMaskedLM: 7.800\tReconstruct: 0.215\tMasked Acc: 0.183\n",
            "15:28:46 Epoch2.199\tMaskedLM: 7.887\tReconstruct: 0.208\tMasked Acc: 0.178\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-278900bcb60f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0meml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/GLAMOR/src/ednaml/core/EdnaML.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontinue_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprevious_stop\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontinue_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprevious_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/GLAMOR/src/ednaml/trainer/BaseTrainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, continue_epoch, continue_step)\u001b[0m\n\u001b[1;32m    425\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mcontinue_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m                 \u001b[0;31m# TODO pre epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m                 \u001b[0;31m# TODO post epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/GLAMOR/src/ednaml/trainer/BaseTrainer.py\u001b[0m in \u001b[0;36mepoch_step\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m    451\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#train == we are tracking all numbers and computation graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmove_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#perform function and returns loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccumulation_steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/./GLAMOR/profiles/FNC/fnc-extension.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m         (\n\u001b[1;32m    182\u001b[0m             \u001b[0mall_input_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/./GLAMOR/profiles/FNC/fnc-extension.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m         (\n\u001b[1;32m    182\u001b[0m             \u001b[0mall_input_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/GLAMOR/src/ednaml/trainer/BaseTrainer.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmove_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "eml.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4iOQfJhKsYZi"
      },
      "outputs": [],
      "source": [
        "eml.trainer.save()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-rfjHQ0Osg5c"
      },
      "outputs": [],
      "source": [
        "eml.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBwOfPCRsuvq"
      },
      "source": [
        "## 4.1.1. Deployment to generate training features\n",
        "Now we will use our trained LLM to generate the training features again.\n",
        "\n",
        "These features will be used to determine the best number of clusters and other hyperparameters. Subsequently, we can use our calculated hyperparameters to build a K-Means Clustering Plugin that includes a High-Density Set estimator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S10EGxFMkQWR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87b61cfa-e1f0-436e-9e03-c49640049f68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove '*.h5*': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "! rm *.h5*\n",
        "! rm train-datashard-artifacts/*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rZBTqabVizdV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "960d8537-f636-421b-f002-e883b2beb232"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iJCi3pnLtDMk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "6693ff24-f60f-4f71-95d1-7738c9ec4704"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.13.1+cu116'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "import torch\n",
        "import ednaml\n",
        "import glob, os\n",
        "from ednaml.core import EdnaDeploy, EdnaML\n",
        "torch.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9T1XbZd0DOrO"
      },
      "outputs": [],
      "source": [
        "config = \"./GLAMOR/profiles/FNC/extension/config.yml\"\n",
        "deploy = \"./GLAMOR/profiles/FNC/extension/training_features.yml\"  # remove masking in data generation process\n",
        "crawler = \"./GLAMOR/profiles/FNC/fnc-crawler.py\"\n",
        "filtermask_generator = \"./GLAMOR/profiles/FNC/fnc-filtermasked.py\"\n",
        "extension_model = \"./GLAMOR/profiles/FNC/fnc-extension.py\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ovIrGkTDtFiu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee812b6e-1afb-44de-ab0f-27c544abbc05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Injected key-value pair:  SAVE.MODEL_QUALIFIER, tweets-2020-01-22\n",
            "Log file exists at fnc-extension-v1-albert-tweets-2020-01-22/fnc-extension-v1-albert-tweets-2020-01-22-logger.log. Will attempt to append there.\n"
          ]
        }
      ],
      "source": [
        "ed = EdnaDeploy(config=config, deploy = deploy, dataloader_mode = \"train\", config_inject=[(\"SAVE.MODEL_QUALIFIER\", tweet_file)])\n",
        "ed.cfg.DEPLOYMENT.OUTPUT_ARGS[\"feature_file\"] = \"%s-filtered-features\"%tweet_file\n",
        "ed.cfg.DEPLOYMENT.DATAREADER.CRAWLER_ARGS[\"train_file\"] = \"%s-filtered.json\"%tweet_file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jM7Ao46ZtFc1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b2bdab2-f378-48d1-bc41-f87293f0446f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "15:29:25 Adding a crawler, from /content/GLAMOR/profiles/FNC/fnc-crawler.py, with inferred name FNCCrawler\n",
            "15:29:25 Adding a generator, from /content/GLAMOR/profiles/FNC/fnc-crawler.py, with inferred name FNCRawGenerator\n",
            "15:29:25 Adding a generator, from /content/GLAMOR/profiles/FNC/fnc-filtermasked.py, with inferred name FNCFilterMaskGenerator\n",
            "15:29:25 Adding a model, from /content/GLAMOR/profiles/FNC/fnc-extension.py, with inferred name FNCAlbertModeler\n",
            "/content/GLAMOR/src/ednaml/core/EdnaML.py:941: UserWarning: keyvalue trainer in REGISTERED_EDNA_COMPONENTS <class './GLAMOR/profiles/FNC/fnc-extension.py.FNCAlbertModelerTrainer'> is not available in self.decorator_reference. Not adding.\n",
            "  warnings.warn(\n",
            "15:29:25 Adding a deployment, from /content/GLAMOR/profiles/FNC/fnc-extension.py, with inferred name FNCTrainingFeaturesDeploy\n",
            "15:29:25 ****************************************\n",
            "15:29:25 \n",
            "15:29:25 \n",
            "15:29:25 Using the following configuration:\n",
            "15:29:25 DEPLOYMENT:\n",
            "  DATAREADER:\n",
            "    CRAWLER_ARGS:\n",
            "      azcontainer: edna-covid-raw\n",
            "      azfile: tweets-2020-01-22.json.gz\n",
            "      azstorage: ednadatasets\n",
            "      train_file: tweets-2020-01-22-filtered.json\n",
            "    DATAREADER: AlbertReader\n",
            "    DATASET_ARGS:\n",
            "      classificationclass:\n",
            "      - fnews\n",
            "      data_shuffle: false\n",
            "      keyword_mask: false\n",
            "      masking: false\n",
            "      maxlen: 512\n",
            "      mlm_probability: 0.15\n",
            "      shard_replace: false\n",
            "      shardcache: true\n",
            "      shardname: fnc-unmasked-shard\n",
            "      shardpath: datashard-artifacts\n",
            "      shardsize: 20000\n",
            "      shuffle: false\n",
            "    GENERATOR: null\n",
            "    GENERATOR_ARGS:\n",
            "      from_pretrained: albert-base-v2\n",
            "      tokenizer: HFAutoTokenizer\n",
            "  DEPLOY: BaseDeploy\n",
            "  DEPLOYMENT_ARGS: {}\n",
            "  EPOCHS: 1\n",
            "  OUTPUT_ARGS:\n",
            "    feature_file: tweets-2020-01-22-filtered-features\n",
            "  PLUGIN:\n",
            "    HOOKS: always\n",
            "    RESET: false\n",
            "EXECUTION:\n",
            "  DATAREADER:\n",
            "    CRAWLER_ARGS:\n",
            "      azcontainer: edna-covid-raw\n",
            "      azfile: tweets-2020-01-22.json.gz\n",
            "      azstorage: ednadatasets\n",
            "    DATAREADER: AlbertReader\n",
            "    DATASET_ARGS:\n",
            "      classificationclass:\n",
            "      - fnews\n",
            "      data_shuffle: true\n",
            "      keyword_mask: true\n",
            "      keywords:\n",
            "      - covid\n",
            "      - corona\n",
            "      - mask\n",
            "      - wuhan\n",
            "      - n95\n",
            "      - sars\n",
            "      - monkey\n",
            "      - pandemic\n",
            "      - social\n",
            "      - quarantin\n",
            "      - virus\n",
            "      - infect\n",
            "      - lock\n",
            "      - ppe\n",
            "      - variant\n",
            "      - vaccine\n",
            "      - travel\n",
            "      - omicron\n",
            "      - ivermectin\n",
            "      - plandemic\n",
            "      - 5g\n",
            "      - gates\n",
            "      - hoax\n",
            "      - bioweapon\n",
            "      - bat\n",
            "      - fauci\n",
            "      masking: false\n",
            "      maxlen: 512\n",
            "      mlm_probability: 0.15\n",
            "      shard_replace: false\n",
            "      shardcache: true\n",
            "      shardname: fnc-filtermask-shard\n",
            "      shardpath: datashard-artifacts\n",
            "      shardsize: 20000\n",
            "      shuffle: true\n",
            "    GENERATOR: null\n",
            "    GENERATOR_ARGS:\n",
            "      from_pretrained: albert-base-v2\n",
            "      tokenizer: HFAutoTokenizer\n",
            "  EPOCHS: 3\n",
            "  FP16: false\n",
            "  MODEL_SERVING: false\n",
            "  OPTIMIZER_BUILDER: ClassificationOptimizer\n",
            "  PLUGIN:\n",
            "    HOOKS: always\n",
            "    RESET: false\n",
            "  SKIPEVAL: false\n",
            "  TEST_FREQUENCY: 1\n",
            "  TRAINER: BaseTrainer\n",
            "  TRAINER_ARGS:\n",
            "    accumulation_steps: 8\n",
            "LOGGING:\n",
            "  INPUT_SIZE:\n",
            "  - 16\n",
            "  - 512\n",
            "  STEP_VERBOSE: 100\n",
            "LOSS:\n",
            "- KWARGS:\n",
            "  - loss_class: CrossEntropyLoss\n",
            "    loss_kwargs:\n",
            "      ignore_index: -1\n",
            "  LABEL: mask_lm\n",
            "  LAMBDAS:\n",
            "  - 1.0\n",
            "  LOSSES:\n",
            "  - TorchLoss\n",
            "  NAME: mask_lm\n",
            "LOSS_OPTIMIZER:\n",
            "- BASE_LR: 0.001\n",
            "  LR_BIAS_FACTOR: 1.0\n",
            "  OPTIMIZER: Adam\n",
            "  OPTIMIZER_KWARGS: {}\n",
            "  OPTIMIZER_NAME: opt-1\n",
            "  WEIGHT_BIAS_FACTOR: 0.0005\n",
            "  WEIGHT_DECAY: 0.0005\n",
            "LOSS_SCHEDULER:\n",
            "- LR_KWARGS:\n",
            "    step_size: 20\n",
            "  LR_SCHEDULER: StepLR\n",
            "  SCHEDULER_NAME: opt-1\n",
            "MODEL:\n",
            "  BUILDER: ednaml_model_builder\n",
            "  MODEL_ARCH: FNCAlbertModeler\n",
            "  MODEL_BASE: Albert\n",
            "  MODEL_KWARGS:\n",
            "    attention_probs_dropout_prob: 0\n",
            "    embedding_size: 128\n",
            "    hidden_act: gelu\n",
            "    hidden_dropout_prob: 0\n",
            "    hidden_size: 768\n",
            "    initializer_range: 0.02\n",
            "    inner_group_num: 1\n",
            "    intermediate_size: 3072\n",
            "    layer_norm_eps: 1.0e-12\n",
            "    max_position_embeddings: 512\n",
            "    num_attention_heads: 12\n",
            "    num_hidden_groups: 1\n",
            "    num_hidden_layers: 12\n",
            "    pooling: pooled\n",
            "    type_vocab_size: 2\n",
            "    vocab_size_or_config_json_file: 30000\n",
            "  MODEL_NORMALIZATION: bn\n",
            "  PARAMETER_GROUPS:\n",
            "  - opt-1\n",
            "MODEL_PLUGIN: {}\n",
            "OPTIMIZER:\n",
            "- BASE_LR: 1.0e-05\n",
            "  LR_BIAS_FACTOR: 1.0\n",
            "  OPTIMIZER: AdamW\n",
            "  OPTIMIZER_KWARGS:\n",
            "    eps: 1.0e-06\n",
            "  OPTIMIZER_NAME: opt-1\n",
            "  WEIGHT_BIAS_FACTOR: 0.0005\n",
            "  WEIGHT_DECAY: 0.0005\n",
            "SAVE:\n",
            "  CHECKPOINT_DIRECTORY: ./drive/MyDrive/Projects/FNC/Models/\n",
            "  DRIVE_BACKUP: true\n",
            "  LOG_BACKUP: false\n",
            "  MODEL_BACKBONE: albert\n",
            "  MODEL_CORE_NAME: fnc-extension\n",
            "  MODEL_QUALIFIER: tweets-2020-01-22\n",
            "  MODEL_VERSION: 1\n",
            "  SAVE_FREQUENCY: 1\n",
            "  STEP_SAVE_FREQUENCY: 0\n",
            "SCHEDULER:\n",
            "- LR_KWARGS:\n",
            "    gamma: 0.5\n",
            "    step_size: 5\n",
            "  LR_SCHEDULER: StepLR\n",
            "  SCHEDULER_NAME: opt-1\n",
            "STORAGE:\n",
            "  STORAGE_ARGS: {}\n",
            "  TYPE: BaseStorage\n",
            "  URL: ./\n",
            "TEST_TRANSFORMATION:\n",
            "  ARGS: {}\n",
            "  BATCH_SIZE: 16\n",
            "  WORKERS: 2\n",
            "TRAIN_TRANSFORMATION:\n",
            "  ARGS: {}\n",
            "  BATCH_SIZE: 16\n",
            "  WORKERS: 2\n",
            "extensions:\n",
            "- EXECUTION\n",
            "- SAVE\n",
            "- STORAGE\n",
            "- TRANSFORMATION\n",
            "- MODEL\n",
            "- LOSS\n",
            "- OPTIMIZER\n",
            "- SCHEDULER\n",
            "- LOSS_OPTIMIZER\n",
            "- LOSS_SCHEDULER\n",
            "- LOGGING\n",
            "- DEPLOYMENT\n",
            "- MODEL_PLUGIN\n",
            "\n",
            "15:29:25 \n",
            "15:29:25 \n",
            "15:29:25 ****************************************\n",
            "/content/GLAMOR/src/ednaml/core/EdnaML.py:222: UserWarning: Mode is `test` but weights is `None`. This will cause issues when EdnaML attempts to load weights\n",
            "  warnings.warn(\n",
            "15:29:25 Previous stop detected. Will attempt to resume from epoch 1, step 0\n",
            "15:29:25 Reading data with DataReader AlbertReader\n",
            "15:29:25 Default CRAWLER is <class 'ednaml.crawlers.Crawler'>\n",
            "15:29:25 Default DATASET is <class 'ednaml.generators.AlbertGenerator.AlbertDataset'>\n",
            "15:29:25 Default GENERATOR is <class 'ednaml.generators.AlbertGenerator.AlbertGenerator'>\n",
            "15:29:25 Updating GENERATOR to queued class FNCFilterMaskGenerator\n",
            "15:29:25 Updating CRAWLER to FNCCrawler\n",
            "15:29:25 Crawling https://ednadatasets.blob.core.windows.net/edna-covid-raw/tweets-2020-01-22.json.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Registering a crawler: <class './GLAMOR/profiles/FNC/fnc-crawler.py.FNCCrawler'>, from file: /content/GLAMOR/profiles/FNC/fnc-crawler.py\n",
            "Registering a generator: <class './GLAMOR/profiles/FNC/fnc-crawler.py.FNCRawGenerator'>, from file: /content/GLAMOR/profiles/FNC/fnc-crawler.py\n",
            "Registering a generator: <class './GLAMOR/profiles/FNC/fnc-filtermasked.py.FNCFilterMaskGenerator'>, from file: /content/GLAMOR/profiles/FNC/fnc-filtermasked.py\n",
            "Registering a model: <class './GLAMOR/profiles/FNC/fnc-extension.py.FNCAlbertModeler'>, from file: /content/GLAMOR/profiles/FNC/fnc-extension.py\n",
            "Registering a trainer: <class './GLAMOR/profiles/FNC/fnc-extension.py.FNCAlbertModelerTrainer'>, from file: /content/GLAMOR/profiles/FNC/fnc-extension.py\n",
            "Registering a deployment: <class './GLAMOR/profiles/FNC/fnc-extension.py.FNCTrainingFeaturesDeploy'>, from file: /content/GLAMOR/profiles/FNC/fnc-extension.py\n",
            "5637377/5637377 bytes [████████████████████████████████████████████████████████████████████████████████████████████████████]\n",
            "Download of tweets-2020-01-22.json.gz to https://ednadatasets.blob.core.windows.net/edna-covid-raw/tweets-2020-01-22.json.gz completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "15:29:30 Generating dataloader `FNCFilterMaskGenerator` with `train` mode\n",
            "15:29:30 Building Transforms\n",
            "15:29:34 Building Dataset\n",
            "15:29:34 Generating shards\n",
            "100%|██████████| 1/1 [00:12<00:00, 12.19s/it]\n",
            "15:29:46 Building Dataloader\n",
            "15:29:46 Generated test data/query generator\n",
            "15:29:46 Loaded ednaml_model_builder from ednaml.models to build model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading weights file pytorch_model.bin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "15:29:47 Finished instantiating model with FNCAlbertModeler architecture\n",
            "15:29:47 Adding plugins after constructing model\n",
            "15:29:47 No saved model weights provided. Inferring weights path.\n",
            "15:29:47 Loading model from drive backup.\n",
            "15:29:47 Using weights from last saved epoch 1, at path None.\n",
            "15:29:47 Model Summary retured the following error:\n",
            "15:29:47 Traceback (most recent call last):\n",
            "  File \"/content/GLAMOR/src/ednaml/core/EdnaML.py\", line 888, in getModelSummary\n",
            "    self.cfg.TRAIN_TRANSFORMATION.INPUT_SIZE,\n",
            "AttributeError: 'TransformationConfig' object has no attribute 'INPUT_SIZE'\n",
            "\n",
            "15:29:47 1 GPUs available\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Errors \n",
            "\t {'missing_keys': [], 'unexpected_keys': [], 'error_msgs': []}\n",
            "NOT saving metadata. saveMetadata() function not set up.\n"
          ]
        }
      ],
      "source": [
        "ed.add(crawler)\n",
        "ed.add(filtermask_generator)\n",
        "ed.add(extension_model)  # With model AND deployment defined\n",
        "ed.apply()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ed.deployment.edna_context.MODEL_HAS_LOADED_WEIGHTS"
      ],
      "metadata": {
        "id": "MlsKtT7NzSEy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37f74d59-b5bd-4602-c236-2faf84c30f85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uLotDqjQtFQg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bfbee0a-ca96-43da-f36a-8fc31c684f16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "15:29:47 Starting deployment\n",
            "15:29:47 Logging to:\tfnc-extension-v1-albert-tweets-2020-01-22-logger.log\n",
            "15:29:47 Loading a model from saved epoch 1, step 0\n",
            "15:29:47 Loading model from drive backup.\n",
            "15:29:47 Finished loading model state_dict from ./drive/MyDrive/Projects/FNC/Models/fnc-extension-v1-albert-tweets-2020-01-22/fnc-extension-v1_epoch1_step0.pth\n",
            "15:29:47 Looking for model plugins from drive backup.\n",
            "15:29:48 No plugin exists for name FastKMP-l2\n",
            "15:29:48 Loaded plugins from ./drive/MyDrive/Projects/FNC/Models/fnc-extension-v1-albert-tweets-2020-01-22/fnc-extension-v1_plugins.pth\n",
            "15:29:48 Setting up plugin hooks. Plugins will fire during:  always\n",
            "15:29:48 Executing deployment for  1 epochs\n",
            "15:29:48 Starting epoch 0\n",
            "15:31:19 Performing save at epoch 1\n",
            "15:31:19 Saving model plugins.\n",
            "15:31:19 No plugins to save\n",
            "15:31:19 Executing end of epoch steps\n",
            "15:31:19 Completed deployment task.\n"
          ]
        }
      ],
      "source": [
        "ed.deploy()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ed.saveMetadata.MODEL_SAVE_FOLDER"
      ],
      "metadata": {
        "id": "gmSTh7jcDRfi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "d204ff4f-e83b-48e1-d6f8-44b670c9ab11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'fnc-extension-v1-albert-tweets-2020-01-22'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PphaBtY5DRdV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bhDlXyQDDRbG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBH_VHmGAqbX"
      },
      "source": [
        "## 4.2 Estimating best number of clusters from the BERT features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oLHxGtD9JPDZ"
      },
      "outputs": [],
      "source": [
        "def cluster_sweep(features_file, batch_size, max_iters, cluster_range):\n",
        "  import h5py, time\n",
        "  from sklearn.cluster import MiniBatchKMeans\n",
        "  inertia = []\n",
        "  data = h5py.File(features_file, 'r')\n",
        "  data_size = data['features'].shape[0]\n",
        "  \n",
        "  for k in cluster_range:\n",
        "    print(\"Starting sweep for k={kval}, with {iters} iterations\".format(kval=k, iters=max_iters))\n",
        "    kmeans = MiniBatchKMeans(n_clusters = k, random_state = 23465356, batch_size = batch_size)\n",
        "    stime = time.time()\n",
        "    for iters in range(max_iters):\n",
        "      for i in range(0, data_size, batch_size):\n",
        "          current_data = data['features'][i:i+batch_size]\n",
        "          kmeans.partial_fit(current_data)\n",
        "      if iters%5 == 0:\n",
        "        etime = round(time.time() - stime, 2)\n",
        "        print(\"\\t[{elapse} s] -- Completed {iters} iterations\".format(iters=iters, elapse = etime))\n",
        "        stime = time.time()\n",
        "    print(\"\\tCompeted MBKM for k={kval}, with inertia: {inertia}\".format(kval=k, inertia = kmeans.inertia_))\n",
        "    inertia.append(kmeans.inertia_)\n",
        "  return inertia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WnHgqBPoJPBB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "317abdc4-a5e4-4fdf-c867-57d957eef077"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting sweep for k=10, with 25 iterations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t[0.77 s] -- Completed 0 iterations\n",
            "\t[2.74 s] -- Completed 5 iterations\n",
            "\t[3.73 s] -- Completed 10 iterations\n",
            "\t[3.2 s] -- Completed 15 iterations\n",
            "\t[2.73 s] -- Completed 20 iterations\n",
            "\tCompeted MBKM for k=10, with inertia: 91.81343078613281\n",
            "Starting sweep for k=20, with 25 iterations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t[0.63 s] -- Completed 0 iterations\n",
            "\t[2.87 s] -- Completed 5 iterations\n",
            "\t[3.84 s] -- Completed 10 iterations\n",
            "\t[3.13 s] -- Completed 15 iterations\n",
            "\t[2.82 s] -- Completed 20 iterations\n",
            "\tCompeted MBKM for k=20, with inertia: 78.97384643554688\n",
            "Starting sweep for k=50, with 25 iterations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t[0.66 s] -- Completed 0 iterations\n",
            "\t[3.07 s] -- Completed 5 iterations\n",
            "\t[3.97 s] -- Completed 10 iterations\n",
            "\t[2.91 s] -- Completed 15 iterations\n",
            "\t[2.83 s] -- Completed 20 iterations\n",
            "\tCompeted MBKM for k=50, with inertia: 47.5069694519043\n",
            "Starting sweep for k=100, with 25 iterations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t[0.8 s] -- Completed 0 iterations\n",
            "\t[3.76 s] -- Completed 5 iterations\n",
            "\t[3.73 s] -- Completed 10 iterations\n",
            "\t[3.01 s] -- Completed 15 iterations\n",
            "\t[3.02 s] -- Completed 20 iterations\n",
            "\tCompeted MBKM for k=100, with inertia: 39.43856430053711\n"
          ]
        }
      ],
      "source": [
        "cluster_range = [10,20,50,100]\n",
        "inertia = cluster_sweep(\n",
        "    features_file = \"%s-filtered-features.h5\"%tweet_file,\n",
        "    batch_size=256,\n",
        "    max_iters = 25,\n",
        "    cluster_range = cluster_range\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xYUA2w_dI7fd"
      },
      "outputs": [],
      "source": [
        "# In case of interruptions or crashes...\n",
        "#inertia2 = [1660, 5510, 3100, 2290] + inertia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0CArQNFjZRzT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "outputId": "bb5b8e0a-54cf-4c55-93e1-880e916a177d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Text(0.5, 1.0, 'Elbow Plot for KMeans')]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "sns.set_theme(style=\"darkgrid\")\n",
        "sns.lineplot(x=\"cluster_range\", y=\"inertia\", data=pd.DataFrame(list(zip(inertia, cluster_range)), columns=[\"inertia\", \"cluster_range\"]), \n",
        "             palette=\"tab10\", linewidth=2.5, marker=\"o\", markersize=10). \\\n",
        "              set(title=\"Elbow Plot for KMeans\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3fIovF-rCHb"
      },
      "source": [
        "So, we find here that for FNC Jan 2020 that **40 PROXIES** fits the elbow visual test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ngojQFRWcf9"
      },
      "outputs": [],
      "source": [
        "proxy = 40"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EU53fUFKuFEb"
      },
      "source": [
        "## 4.3 Generate Plugins \n",
        "\n",
        "Using k=20 proxies, we will now generate the FastKMeans Plugin for our LLM for this FNC window. "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf -- train-datashard-artifacts/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bqinEpfXHCD7",
        "outputId": "b6ca8ca2-d23c-4670-cc5d-ded5301672ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'train-datashard-artifacts/': Is a directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tc1Iz_XU84Ia",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebb494ca-ae2a-42ee-898f-7aa6d4d6ed50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GDroKNDP84Ia",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "97b6a2e2-311d-44a3-a8e1-7425cf8c4ed3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.12.1+cu113'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "import torch\n",
        "import ednaml\n",
        "import glob, os\n",
        "from ednaml.core import EdnaDeploy, EdnaML\n",
        "torch.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k3kmromk84Ib"
      },
      "outputs": [],
      "source": [
        "config = \"./GLAMOR/profiles/FNC/extension/config.yml\"\n",
        "deploy = \"./GLAMOR/profiles/FNC/extension/fastkmeans.yml\" #basically, set up plugin info, and remove masking\n",
        "crawler = \"./GLAMOR/profiles/FNC/fnc-crawler.py\"\n",
        "filtermask_generator = \"./GLAMOR/profiles/FNC/fnc-filtermasked.py\"\n",
        "extension_model = \"./GLAMOR/profiles/FNC/fnc-extension.py\"\n",
        "fastkmeans = \"./GLAMOR/profiles/FNC/fnc-fastkmeans.py\"  # contains plugin and deployment for the plugin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D5vnq4uJ84Ib",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0c16c9c-5fe2-418e-9374-dda0d6782800"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Injected key-value pair:  SAVE.MODEL_QUALIFIER, tweets-2020-01-22\n",
            "Injected key-value pair:  SAVE.SAVE_FREQUENCY, 1\n",
            "Log file exists at fnc-extension-v1-albert-tweets-2020-01-22/fnc-extension-v1-albert-tweets-2020-01-22-logger.log. Will attempt to append there.\n"
          ]
        }
      ],
      "source": [
        "ed = EdnaDeploy(config=config, deploy = deploy, dataloader_mode = \"train\", config_inject=[(\"SAVE.MODEL_QUALIFIER\", tweet_file), (\"SAVE.SAVE_FREQUENCY\", 1)])\n",
        "ed.cfg.DEPLOYMENT.DATAREADER.CRAWLER_ARGS[\"train_file\"] = \"%s-filtered.json\"%tweet_file\n",
        "ed.cfg.MODEL_PLUGIN[\"FastKMP-l2\"].PLUGIN_KWARGS[\"proxies\"] = proxy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bmlZV-sy84Ib",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd9cbc2d-cdfb-4dc3-b10a-2c0d874542f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "19:58:35 Adding a crawler, from /content/GLAMOR/profiles/FNC/fnc-crawler.py, with inferred name FNCCrawler\n",
            "19:58:35 Adding a generator, from /content/GLAMOR/profiles/FNC/fnc-crawler.py, with inferred name FNCRawGenerator\n",
            "19:58:35 Adding a generator, from /content/GLAMOR/profiles/FNC/fnc-filtermasked.py, with inferred name FNCFilterMaskGenerator\n",
            "19:58:35 Adding a model, from /content/GLAMOR/profiles/FNC/fnc-extension.py, with inferred name FNCAlbertModeler\n",
            "/content/GLAMOR/src/ednaml/core/EdnaML.py:942: UserWarning: keyvalue trainer in REGISTERED_EDNA_COMPONENTS <class './GLAMOR/profiles/FNC/fnc-extension.py.FNCAlbertModelerTrainer'> is not available in self.decorator_reference. Not adding.\n",
            "  str(ednaml.core.decorators.REGISTERED_EDNA_COMPONENTS[lookup_path][keyvalue]))\n",
            "19:58:35 Adding a deployment, from /content/GLAMOR/profiles/FNC/fnc-extension.py, with inferred name FNCTrainingFeaturesDeploy\n",
            "19:58:35 Adding a model_plugin, from /content/GLAMOR/profiles/FNC/fnc-fastkmeans.py, with inferred name FastKMP\n",
            "19:58:35 Adding a model_plugin, from /content/GLAMOR/profiles/FNC/fnc-fastkmeans.py, with inferred name FastKMP\n",
            "19:58:35 Adding a deployment, from /content/GLAMOR/profiles/FNC/fnc-fastkmeans.py, with inferred name FNCPluginDeployment\n",
            "19:58:35 ****************************************\n",
            "19:58:35 \n",
            "19:58:35 \n",
            "19:58:35 Using the following configuration:\n",
            "19:58:35 DEPLOYMENT:\n",
            "  DATAREADER:\n",
            "    CRAWLER_ARGS:\n",
            "      azcontainer: edna-covid-raw\n",
            "      azfile: tweets-2020-01-22.json.gz\n",
            "      azstorage: ednadatasets\n",
            "      train_file: tweets-2020-01-22-filtered.json\n",
            "    DATAREADER: AlbertReader\n",
            "    DATASET_ARGS:\n",
            "      classificationclass:\n",
            "      - fnews\n",
            "      data_shuffle: false\n",
            "      keyword_mask: false\n",
            "      masking: false\n",
            "      maxlen: 512\n",
            "      mlm_probability: 0.15\n",
            "      shard_replace: false\n",
            "      shardcache: true\n",
            "      shardname: fnc-unmasked-shard\n",
            "      shardpath: datashard-artifacts\n",
            "      shardsize: 20000\n",
            "      shuffle: false\n",
            "    GENERATOR: null\n",
            "    GENERATOR_ARGS:\n",
            "      from_pretrained: albert-base-v2\n",
            "      tokenizer: HFAutoTokenizer\n",
            "  DEPLOY: BaseDeploy\n",
            "  DEPLOYMENT_ARGS: {}\n",
            "  EPOCHS: 1\n",
            "  OUTPUT_ARGS: {}\n",
            "  PLUGIN:\n",
            "    HOOKS: warmup\n",
            "    RESET: true\n",
            "EXECUTION:\n",
            "  DATAREADER:\n",
            "    CRAWLER_ARGS:\n",
            "      azcontainer: edna-covid-raw\n",
            "      azfile: tweets-2020-01-22.json.gz\n",
            "      azstorage: ednadatasets\n",
            "    DATAREADER: AlbertReader\n",
            "    DATASET_ARGS:\n",
            "      classificationclass:\n",
            "      - fnews\n",
            "      data_shuffle: true\n",
            "      keyword_mask: true\n",
            "      keywords:\n",
            "      - covid\n",
            "      - corona\n",
            "      - mask\n",
            "      - wuhan\n",
            "      - n95\n",
            "      - sars\n",
            "      - monkey\n",
            "      - pandemic\n",
            "      - social\n",
            "      - quarantin\n",
            "      - virus\n",
            "      - infect\n",
            "      - lock\n",
            "      - ppe\n",
            "      - variant\n",
            "      - vaccine\n",
            "      - travel\n",
            "      - omicron\n",
            "      - ivermectin\n",
            "      - plandemic\n",
            "      - 5g\n",
            "      - gates\n",
            "      - hoax\n",
            "      - bioweapon\n",
            "      - bat\n",
            "      - fauci\n",
            "      masking: false\n",
            "      maxlen: 512\n",
            "      mlm_probability: 0.15\n",
            "      shard_replace: false\n",
            "      shardcache: true\n",
            "      shardname: fnc-filtermask-shard\n",
            "      shardpath: datashard-artifacts\n",
            "      shardsize: 20000\n",
            "      shuffle: true\n",
            "    GENERATOR: null\n",
            "    GENERATOR_ARGS:\n",
            "      from_pretrained: albert-base-v2\n",
            "      tokenizer: HFAutoTokenizer\n",
            "  EPOCHS: 3\n",
            "  FP16: false\n",
            "  MODEL_SERVING: false\n",
            "  OPTIMIZER_BUILDER: ClassificationOptimizer\n",
            "  PLUGIN:\n",
            "    HOOKS: always\n",
            "    RESET: false\n",
            "  SKIPEVAL: false\n",
            "  TEST_FREQUENCY: 1\n",
            "  TRAINER: BaseTrainer\n",
            "  TRAINER_ARGS:\n",
            "    accumulation_steps: 8\n",
            "LOGGING:\n",
            "  INPUT_SIZE:\n",
            "  - 16\n",
            "  - 512\n",
            "  STEP_VERBOSE: 100\n",
            "LOSS:\n",
            "- KWARGS:\n",
            "  - loss_class: CrossEntropyLoss\n",
            "    loss_kwargs:\n",
            "      ignore_index: -1\n",
            "  LABEL: mask_lm\n",
            "  LAMBDAS:\n",
            "  - 1.0\n",
            "  LOSSES:\n",
            "  - TorchLoss\n",
            "  NAME: mask_lm\n",
            "LOSS_OPTIMIZER:\n",
            "- BASE_LR: 0.001\n",
            "  LR_BIAS_FACTOR: 1.0\n",
            "  OPTIMIZER: Adam\n",
            "  OPTIMIZER_KWARGS: {}\n",
            "  OPTIMIZER_NAME: opt-1\n",
            "  WEIGHT_BIAS_FACTOR: 0.0005\n",
            "  WEIGHT_DECAY: 0.0005\n",
            "LOSS_SCHEDULER:\n",
            "- LR_KWARGS:\n",
            "    step_size: 20\n",
            "  LR_SCHEDULER: StepLR\n",
            "  SCHEDULER_NAME: opt-1\n",
            "MODEL:\n",
            "  BUILDER: ednaml_model_builder\n",
            "  MODEL_ARCH: FNCAlbertModeler\n",
            "  MODEL_BASE: Albert\n",
            "  MODEL_KWARGS:\n",
            "    attention_probs_dropout_prob: 0\n",
            "    embedding_size: 128\n",
            "    hidden_act: gelu\n",
            "    hidden_dropout_prob: 0\n",
            "    hidden_size: 768\n",
            "    initializer_range: 0.02\n",
            "    inner_group_num: 1\n",
            "    intermediate_size: 3072\n",
            "    layer_norm_eps: 1.0e-12\n",
            "    max_position_embeddings: 512\n",
            "    num_attention_heads: 12\n",
            "    num_hidden_groups: 1\n",
            "    num_hidden_layers: 12\n",
            "    pooling: pooled\n",
            "    type_vocab_size: 2\n",
            "    vocab_size_or_config_json_file: 30000\n",
            "  MODEL_NORMALIZATION: bn\n",
            "  PARAMETER_GROUPS:\n",
            "  - opt-1\n",
            "MODEL_PLUGIN:\n",
            "  FastKMP-l2:\n",
            "    PLUGIN: FastKMP\n",
            "    PLUGIN_KWARGS:\n",
            "      alpha: 0.5\n",
            "      batch_size: 256\n",
            "      dimensions: 768\n",
            "      dist: euclidean\n",
            "      iterations: 30\n",
            "      proxies: 40\n",
            "    PLUGIN_NAME: FastKMP-l2\n",
            "OPTIMIZER:\n",
            "- BASE_LR: 1.0e-05\n",
            "  LR_BIAS_FACTOR: 1.0\n",
            "  OPTIMIZER: AdamW\n",
            "  OPTIMIZER_KWARGS:\n",
            "    eps: 1.0e-06\n",
            "  OPTIMIZER_NAME: opt-1\n",
            "  WEIGHT_BIAS_FACTOR: 0.0005\n",
            "  WEIGHT_DECAY: 0.0005\n",
            "SAVE:\n",
            "  CHECKPOINT_DIRECTORY: ./drive/MyDrive/Projects/FNC/Models/\n",
            "  DRIVE_BACKUP: true\n",
            "  LOG_BACKUP: false\n",
            "  MODEL_BACKBONE: albert\n",
            "  MODEL_CORE_NAME: fnc-extension\n",
            "  MODEL_QUALIFIER: tweets-2020-01-22\n",
            "  MODEL_VERSION: 1\n",
            "  SAVE_FREQUENCY: 1\n",
            "  STEP_SAVE_FREQUENCY: 0\n",
            "SCHEDULER:\n",
            "- LR_KWARGS:\n",
            "    gamma: 0.5\n",
            "    step_size: 5\n",
            "  LR_SCHEDULER: StepLR\n",
            "  SCHEDULER_NAME: opt-1\n",
            "STORAGE:\n",
            "  STORAGE_ARGS: {}\n",
            "  TYPE: BaseStorage\n",
            "  URL: ./\n",
            "TEST_TRANSFORMATION:\n",
            "  ARGS: {}\n",
            "  BATCH_SIZE: 16\n",
            "  WORKERS: 2\n",
            "TRAIN_TRANSFORMATION:\n",
            "  ARGS: {}\n",
            "  BATCH_SIZE: 16\n",
            "  WORKERS: 2\n",
            "extensions:\n",
            "- EXECUTION\n",
            "- SAVE\n",
            "- STORAGE\n",
            "- TRANSFORMATION\n",
            "- MODEL\n",
            "- LOSS\n",
            "- OPTIMIZER\n",
            "- SCHEDULER\n",
            "- LOSS_OPTIMIZER\n",
            "- LOSS_SCHEDULER\n",
            "- LOGGING\n",
            "- DEPLOYMENT\n",
            "- MODEL_PLUGIN\n",
            "\n",
            "19:58:35 \n",
            "19:58:35 \n",
            "19:58:35 ****************************************\n",
            "/content/GLAMOR/src/ednaml/core/EdnaML.py:223: UserWarning: Mode is `test` but weights is `None`. This will cause issues when EdnaML attempts to load weights\n",
            "  \"Mode is `test` but weights is `None`. This will cause\"\n",
            "19:58:35 Previous stop detected. Will attempt to resume from epoch 0, step 0\n",
            "19:58:35 Reading data with DataReader AlbertReader\n",
            "19:58:35 Default CRAWLER is <class 'ednaml.crawlers.Crawler'>\n",
            "19:58:35 Default DATASET is <class 'ednaml.generators.AlbertGenerator.AlbertDataset'>\n",
            "19:58:35 Default GENERATOR is <class 'ednaml.generators.AlbertGenerator.AlbertGenerator'>\n",
            "19:58:35 Updating GENERATOR to queued class FNCFilterMaskGenerator\n",
            "19:58:35 Updating CRAWLER to FNCCrawler\n",
            "19:58:35 Crawling https://ednadatasets.blob.core.windows.net/edna-covid-raw/tweets-2020-01-22.json.gz\n",
            "19:58:35 https://ednadatasets.blob.core.windows.net/edna-covid-raw/tweets-2020-01-22.json.gz already exists at tweets-2020-01-22.json.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Registering a crawler: <class './GLAMOR/profiles/FNC/fnc-crawler.py.FNCCrawler'>, from file: /content/GLAMOR/profiles/FNC/fnc-crawler.py\n",
            "Registering a generator: <class './GLAMOR/profiles/FNC/fnc-crawler.py.FNCRawGenerator'>, from file: /content/GLAMOR/profiles/FNC/fnc-crawler.py\n",
            "Registering a generator: <class './GLAMOR/profiles/FNC/fnc-filtermasked.py.FNCFilterMaskGenerator'>, from file: /content/GLAMOR/profiles/FNC/fnc-filtermasked.py\n",
            "Registering a model: <class './GLAMOR/profiles/FNC/fnc-extension.py.FNCAlbertModeler'>, from file: /content/GLAMOR/profiles/FNC/fnc-extension.py\n",
            "Registering a trainer: <class './GLAMOR/profiles/FNC/fnc-extension.py.FNCAlbertModelerTrainer'>, from file: /content/GLAMOR/profiles/FNC/fnc-extension.py\n",
            "Registering a deployment: <class './GLAMOR/profiles/FNC/fnc-extension.py.FNCTrainingFeaturesDeploy'>, from file: /content/GLAMOR/profiles/FNC/fnc-extension.py\n",
            "Registering a model_plugin: <class './GLAMOR/profiles/FNC/fnc-fastkmeans.py.FastKMP'>, from file: /content/GLAMOR/profiles/FNC/fnc-fastkmeans.py\n",
            "Registering a deployment: <class './GLAMOR/profiles/FNC/fnc-fastkmeans.py.FNCPluginDeployment'>, from file: /content/GLAMOR/profiles/FNC/fnc-fastkmeans.py\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "19:58:35 Generating dataloader `FNCFilterMaskGenerator` with `train` mode\n",
            "19:58:35 Building Transforms\n",
            "19:58:36 Building Dataset\n",
            "19:58:36 Generating shards\n",
            "100%|██████████| 1/1 [00:08<00:00,  8.93s/it]\n",
            "19:58:45 Building Dataloader\n",
            "19:58:45 Generated test data/query generator\n",
            "19:58:45 Loaded ednaml_model_builder from ednaml.models to build model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading weights file pytorch_model.bin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "19:58:45 Finished instantiating model with FNCAlbertModeler architecture\n",
            "19:58:45 Adding plugins after constructing model\n",
            "19:58:45 Added plugin FastKMP-l2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Errors \n",
            "\t {'missing_keys': [], 'unexpected_keys': [], 'error_msgs': []}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "19:58:45 No saved model weights provided. Inferring weights path.\n",
            "19:58:45 Loading model from drive backup.\n",
            "19:58:45 Using weights from last saved epoch 0, at path ./drive/MyDrive/Projects/FNC/Models/fnc-extension-v1-albert-tweets-2020-01-22/fnc-extension-v1_epoch0.pth.\n",
            "19:58:48 Model Summary retured the following error:\n",
            "19:58:48 Traceback (most recent call last):\n",
            "  File \"/content/GLAMOR/src/ednaml/core/EdnaML.py\", line 887, in getModelSummary\n",
            "    self.cfg.TRAIN_TRANSFORMATION.INPUT_SIZE,\n",
            "AttributeError: 'TransformationConfig' object has no attribute 'INPUT_SIZE'\n",
            "\n",
            "19:58:48 1 GPUs available\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NOT saving metadata. saveMetadata() function not set up.\n"
          ]
        }
      ],
      "source": [
        "ed.add(crawler)\n",
        "ed.add(filtermask_generator)\n",
        "ed.add(extension_model)  # With model AND deployment defined\n",
        "ed.add(fastkmeans)  # # With plugin AND deployment defined; deployment replaces prior\n",
        "ed.apply()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UD7rmlAG84Ib",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c968bccd-280f-45ef-ec14-934ee831f399"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "19:58:48 Starting deployment\n",
            "19:58:48 Logging to:\tfnc-extension-v1-albert-tweets-2020-01-22-logger.log\n",
            "19:58:48 Loading a model from saved epoch 0, step 0\n",
            "19:58:48 Could not find model or training path at fnc-extension-v1_epoch0_step0.pth. Defaulting to not using step parameter.\n",
            "19:58:48 Loading model from drive backup.\n",
            "19:58:48 Finished loading model state_dict from ./drive/MyDrive/Projects/FNC/Models/fnc-extension-v1-albert-tweets-2020-01-22/fnc-extension-v1_epoch0.pth\n",
            "19:58:48 Looking for model plugins from drive backup.\n",
            "19:58:48 No plugins found at ./drive/MyDrive/Projects/FNC/Models/fnc-extension-v1-albert-tweets-2020-01-22/fnc-extension-v1_plugins.pth\n",
            "19:58:48 Setting up plugin hooks. Plugins will fire during:  warmup\n",
            "19:58:48 Executing deployment for  1 epochs\n",
            "19:58:48 Starting epoch 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting KMeans for k=40, with 30 iterations\n",
            "\t[0.71 s] -- Completed 0 iterations\n",
            "\t[2.67 s] -- Completed 5 iterations\n",
            "\t[2.59 s] -- Completed 10 iterations\n",
            "\t[2.57 s] -- Completed 15 iterations\n",
            "\t[2.65 s] -- Completed 20 iterations\n",
            "\t[2.54 s] -- Completed 25 iterations\n",
            "\tCompeted MBKM for k=40, with inertia: 92.95216369628906\n",
            "Starting High Density estimation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "20:00:32 Performing save at epoch 1\n",
            "20:00:32 Saving model plugins.\n",
            "20:00:32 Saved plugins: dict_keys(['FastKMP-l2'])\n",
            "20:00:32 Performing drive backup of model plugins\n",
            "20:00:32 Executing end of epoch steps\n",
            "20:00:32 Completed deployment task.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed High Density threshold estimation\n"
          ]
        }
      ],
      "source": [
        "ed.deploy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WETqeAOTuoGl"
      },
      "source": [
        "## 4.4 Apply Plugin to Generate Neighbors\n",
        "\n",
        "Now we will use our generated plugin to determine which members of fns-unfiltered should belong in fnc-filtered because they are neighbors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dw555d1N90KW"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Df3g-6C590KX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8848fa3f-9295-43ac-a923-5397e6ba25b6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.12.1+cu113'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import torch\n",
        "import ednaml\n",
        "import glob, os\n",
        "from ednaml.core import EdnaDeploy, EdnaML\n",
        "torch.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Ax2DiUM90KX"
      },
      "outputs": [],
      "source": [
        "config = \"./GLAMOR/profiles/FNC/extension/config.yml\"\n",
        "deploy = \"./GLAMOR/profiles/FNC/extension/neighbors.yml\" #basically, set up plugin info, and remove masking\n",
        "crawler = \"./GLAMOR/profiles/FNC/fnc-crawler.py\"\n",
        "filtermask_generator = \"./GLAMOR/profiles/FNC/fnc-filtermasked.py\"\n",
        "extension_model = \"./GLAMOR/profiles/FNC/fnc-extension.py\"\n",
        "fastkmeans = \"./GLAMOR/profiles/FNC/fnc-fastkmeans.py\"  # contains plugin and deployment for the plugin\n",
        "neighbors = \"./GLAMOR/profiles/FNC/fnc-neighbors.py\"  # contains deployment for neighbors generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aWGSD2pG90KX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "fdea0d89-3406-4ffc-b2d3-e254a1e3aa38"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-9bb157fea76f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0med\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEdnaDeploy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeploy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeploy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig_inject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"SAVE.MODEL_QUALIFIER\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtweet_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"SAVE.DRIVE_BACKUP\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0med\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEPLOYMENT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOUTPUT_ARGS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"basename\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"%s\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mtweet_file\u001b[0m  \u001b[0;31m# deployment will generate twt-neighbors.json\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0med\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEPLOYMENT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDATAREADER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCRAWLER_ARGS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"test_file\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"%s-unfiltered.json\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mtweet_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0med\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMODEL_PLUGIN\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"FastKMP-l2\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPLUGIN_KWARGS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"proxies\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproxy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tweet_file' is not defined"
          ]
        }
      ],
      "source": [
        "ed = EdnaDeploy(config=config, deploy = deploy, config_inject=[(\"SAVE.MODEL_QUALIFIER\", tweet_file), (\"SAVE.DRIVE_BACKUP\", True)])\n",
        "ed.cfg.DEPLOYMENT.OUTPUT_ARGS[\"basename\"] = \"%s\"%tweet_file  # deployment will generate twt-neighbors.json\n",
        "ed.cfg.DEPLOYMENT.DATAREADER.CRAWLER_ARGS[\"test_file\"] = \"%s-unfiltered.json\"%tweet_file\n",
        "ed.cfg.MODEL_PLUGIN[\"FastKMP-l2\"].PLUGIN_KWARGS[\"proxies\"] = proxy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UGVhF39190KX"
      },
      "outputs": [],
      "source": [
        "ed.add(crawler)\n",
        "ed.add(filtermask_generator)\n",
        "ed.add(extension_model)  # With model AND deployment defined\n",
        "ed.add(fastkmeans)  # # With plugin AND deployment defined; deployment replaces prior\n",
        "ed.add(neighbors)\n",
        "ed.apply()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mnu-Q77o90KX"
      },
      "outputs": [],
      "source": [
        "ed.deploy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rmrRbkmCzBW"
      },
      "source": [
        "## 4.5. Generating FNC-Extended = FNC-Filtered + FNC-Neighbors\n",
        "\n",
        "Here, we combine fnc-filtered.json and fnc-neighbors.json to create fnc-extended.json. Then we upload this to our azure blob for this month!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C6duv7zdvBR5"
      },
      "outputs": [],
      "source": [
        "original = sum(1 for line in open(\"%s.json\"%tweet_file))\n",
        "filtered = sum(1 for line in open(\"%s-filtered.json\"%tweet_file))\n",
        "unfiltered = sum(1 for line in open(\"%s-unfiltered.json\"%tweet_file))\n",
        "neighbor = sum(1 for line in open(\"%s-neighbor.json\"%tweet_file))\n",
        "extension = 100 * neighbor / filtered\n",
        "lift = 100 * neighbor / unfiltered\n",
        "print(\n",
        "\"\"\"\n",
        "-------- STATISTICS ------------\n",
        "\n",
        "ORIGINAL    {original}\n",
        "FILTERED    {filtered}\n",
        "UNFILTERED  {unfiltered}\n",
        "NEIGHBORS   {neighbor}\n",
        "\n",
        "EXTENSION   {extension}%\n",
        "LIFT        {lift}%\n",
        "\"\"\".format(original=original, filtered=filtered, unfiltered=unfiltered, neighbor=neighbor, extension=round(extension,2), lift=round(lift,2)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nTCXrZ8ZBDYA"
      },
      "outputs": [],
      "source": [
        "cat \"$tweet_file-filtered.json\" \"$tweet_file-neighbor.json\" >> \"$tweet_file-extended.json\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMcmognzvBq2"
      },
      "source": [
        "## 4.6. Generate FNC-Extended-Oracle-Unlabeled, and upload\n",
        "\n",
        "Here, we will randomly select ~500 points to perform manual labeling. We will try to select these points from each cluster of our FNC LLM Model.\n",
        "\n",
        "Specifically, we will first use our existing plugin to compute the distances of each point in the extension to its cluster center, as well as its cluster index (the index itself is not semantic). \n",
        "\n",
        "After the deployment is complete, we will sweep across the data to find, for each cluster, the closest point, as well as some points further away to generate a more complete representation. That is, since we have 20 clusters (in FNC Jan), and require 500 points, for each cluster we can bin  into 24 regions + closest, and from the 24 regions, select one point at random."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ipXmrO-NEmVj"
      },
      "outputs": [],
      "source": [
        "#!wget https://ednadatasets.blob.core.windows.net/edna-covid-extended/$tweet_file-extended.json.gz\n",
        "#!gunzip $tweet_file-extended.json.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dj8EL-WQNMLk"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6mgUBMCkNMLl"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import ednaml\n",
        "import glob, os\n",
        "from ednaml.core import EdnaDeploy, EdnaML\n",
        "torch.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rfoqPP8ONMLl"
      },
      "outputs": [],
      "source": [
        "config = \"./GLAMOR/profiles/FNC/extension/config.yml\"\n",
        "deploy = \"./GLAMOR/profiles/FNC/extension/oracle.yml\" #basically, set up plugin info, and remove masking; shuffle, and set up the inputs for oracle file generation\n",
        "crawler = \"./GLAMOR/profiles/FNC/fnc-crawler.py\"\n",
        "filtermask_generator = \"./GLAMOR/profiles/FNC/fnc-filtermasked.py\"\n",
        "extension_model = \"./GLAMOR/profiles/FNC/fnc-extension.py\"\n",
        "fastkmeans = \"./GLAMOR/profiles/FNC/fnc-fastkmeans.py\"  # contains plugin and deployment for the plugin\n",
        "oracle = \"./GLAMOR/profiles/FNC/fnc-oracle.py\"  # contains deployment for oracle selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9RNyuhBVNMLl"
      },
      "outputs": [],
      "source": [
        "ed = EdnaDeploy(config=config, deploy = deploy, config_inject=[(\"SAVE.MODEL_QUALIFIER\", tweet_file), (\"SAVE.DRIVE_BACKUP\", True)])\n",
        "ed.cfg.DEPLOYMENT.OUTPUT_ARGS[\"basename\"] = \"%s\"%tweet_file  \n",
        "ed.cfg.DEPLOYMENT.DATAREADER.CRAWLER_ARGS[\"test_file\"] = \"%s-extended.json\"%tweet_file\n",
        "ed.cfg.MODEL_PLUGIN[\"FastKMP-l2\"].PLUGIN_KWARGS[\"proxies\"] = proxy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FjJqrMnZNMLl"
      },
      "outputs": [],
      "source": [
        "ed.add(crawler)\n",
        "ed.add(filtermask_generator)\n",
        "ed.add(extension_model)  # With model AND deployment defined\n",
        "ed.add(fastkmeans)  # # With plugin AND deployment defined; deployment replaces prior\n",
        "ed.add(oracle)\n",
        "ed.apply()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RmtVr6ljwF6-"
      },
      "outputs": [],
      "source": [
        "ed.deploy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5ADOWKGvn4Y"
      },
      "source": [
        "## 4.7 Upload to azure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bPh8p_h31nz"
      },
      "source": [
        "https://docs.microsoft.com/en-us/azure/storage/blobs/storage-quickstart-blobs-python?tabs=environment-variable-windows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aou8Ri3YQ-Tb"
      },
      "outputs": [],
      "source": [
        "!gzip $tweet_file-oracle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FzltNT_GoiWh"
      },
      "outputs": [],
      "source": [
        "!gunzip $tweet_file-extended.json.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0DEardAhSiAW"
      },
      "outputs": [],
      "source": [
        "!gzip $tweet_file-extended.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QFjGRDua2SSJ"
      },
      "outputs": [],
      "source": [
        "!pip install azure-storage-blob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dJ29pqNr3Edi"
      },
      "outputs": [],
      "source": [
        "import os, uuid\n",
        "from azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient, __version__\n",
        "\n",
        "print(\"Azure Blob Storage v\" + __version__ + \" - Python quickstart sample\")\n",
        "connect_str = \"DefaultEndpointsProtocol=https;AccountName=ednadatasets;AccountKey=7pZKgsFLvckW3933BSOIzRvarSisKeDSCT5E/dXNs7vlfEEHG5MworeL2VoyA14pcZXoCaHNIR5r+AStqZQGaQ==;EndpointSuffix=core.windows.net\"\n",
        "# Create the BlobServiceClient object which will be used to create a container client\n",
        "blob_service_client = BlobServiceClient.from_connection_string(connect_str)\n",
        "\n",
        "extended_file = \"%s-extended.json.gz\"%tweet_file\n",
        "oracle_file = \"%s-oracle.json.gz\"%tweet_file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S6eYqvpq5fKD"
      },
      "outputs": [],
      "source": [
        "# Create a unique name for the container\n",
        "container_name = \"edna-covid-extended\"\n",
        "blob_client = blob_service_client.get_blob_client(container=container_name, blob=extended_file)\n",
        "with open(extended_file, \"rb\") as data:\n",
        "    blob_client.upload_blob(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RZ1GG6he5cuf"
      },
      "outputs": [],
      "source": [
        "# Create a unique name for the container\n",
        "container_name = \"edna-covid-extended-oracle\"\n",
        "blob_client = blob_service_client.get_blob_client(container=container_name, blob=oracle_file)\n",
        "with open(oracle_file, \"rb\") as data:\n",
        "    blob_client.upload_blob(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Generate Labels from Experts\n",
        "\n",
        "Here, we will label FNC-Extended for a month with models from ENFD, Fakeddit, and NELA's Bert-variant models. For now, we will use the Albert-Base-v2 models only.\n",
        "\n",
        "The labels are generated with weak supervision using a combination of off-the-shelf expert models, with labels integrated with Snorkel, WeaSEL, or MiDAS, or a combination of the above. \n",
        "\n",
        "For each classifier, we will generate a text file with labels for each entry. Since there is no data shuffling, labels across text files will sync up. We will then upload these saved files to our Drive location for ease of access and future integration.\n",
        "\n",
        "We need the following outputs in each text file:\n",
        "  - **Predicted label.** 0 for True news, 1 for Fake news.\n",
        "  - **Distance-to-proxy (l2)**. Raw distance in embedding space to the nearest proxy.\n",
        "  - **Distance-to-proxy (cos)**. Cosine distance\n",
        "  - **High density set**. 0 or 1. Whether sample is in the high density set.\n",
        "  - **High density label**. The ground truth label of the corresponding high-density set cluster. This is the same as the proxy label, or nearest proxy label.\n",
        "  - **L-Score**. Smoothness score for the input using perturbations. Probably take the longest time.\n",
        "  - **L-Threshold**. The threshold for the nearest proxy / high density set.\n",
        "  - **Logit-confidence**. The raw logit probability of the predicted class.\n",
        "  - **Logit-average**. The average logit probability of the predicted class."
      ],
      "metadata": {
        "id": "I45khl9Bum_Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Iav_55EjkC4"
      },
      "outputs": [],
      "source": [
        "# See FNC Experts (And Masking!) notebook\n",
        "tweet_file = \"tweets-2020-01-22\"\n",
        "\n",
        "# efnd | nela | fakeddit\n",
        "dataset = \"nela\"    \n",
        "\n",
        "# (ONLY FOR efnd; OTHERS YOU CAN IGNORE) \n",
        "# cmu_miscov19 | kagglefn_short | kagglefn_long | cov19_fn_title | cov19_fn_text | coaid_news | cov_rumor | covid_fn | covid_cq\n",
        "subdataset = \"nela\"\n",
        "\n",
        "# nomask | rtm | rwm | ktm_tfidf | kwm_tfidf | ktm_att | kwm_att | ktrtm_tfidf | kwrwm_tfidf | ktrtm_att | kwrwm_att\n",
        "masking = \"nomask\"  \n",
        "\n",
        "# albert-base-v2\n",
        "model = \"albert-base-v2\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Applying"
      ],
      "metadata": {
        "id": "v0rKQQ1_5AHa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KfNxLlMNYNFU"
      },
      "outputs": [],
      "source": [
        "\n",
        "#Select the correct model-file!\n",
        "model_variant = \"./GLAMOR/profiles/FNC/experts/configs/model-bertvariant.yml\" \n",
        "\n",
        "# plugin deploy file and proxies\n",
        "plugin_deploy_generation_file = \"./GLAMOR/profiles/FNC/experts/plugin_generation.py\" \n",
        "plugin_proxies = {\"efnd-cmu_miscov19\": 20, \"efnd-kagglefn_short\": 40, \"efnd-kagglefn_long\": 20,\n",
        "                  \"efnd-cov19_fn_title\": 30, \"efnd-cov19_fn_text\": 35, \"efnd-coaid_news\": 50,\n",
        "                  \"efnd-cov_rumor\": 30, \"efnd-covid_fn\": 30, \"efnd-covid_cq\": 50, \n",
        "                  \"nela\": 40, \"fakeddit\": 30}\n",
        "if dataset == \"efnd\":\n",
        "  proxy = plugin_proxies[dataset + \"-\" + subdataset]\n",
        "else:\n",
        "  proxy = plugin_proxies[dataset]\n",
        "\n",
        "if dataset == \"efnd\":\n",
        "  #----------------------------- EFND ------------------------------------\n",
        "  dataset_args = {\n",
        "      \"data_folder\" : \"Data\",\n",
        "      \"include\": [subdataset]\n",
        "  }\n",
        "  model_qualifier = subdataset\n",
        "elif dataset == \"nela\":\n",
        "  #----------------------------- NELA ------------------------------------\n",
        "  dataset_args = {\n",
        "      \"data_folder\" : \"Data\",\n",
        "      \"sub_folder\" : \"nela-covid-2020\"\n",
        "  }\n",
        "  model_qualifier = \"nela_covid_2020\"\n",
        "elif dataset == \"fakeddit\":\n",
        "  #----------------------------- FAKEDDIT ------------------------------------\n",
        "  dataset_args = {\n",
        "      \"data_folder\" : \"Data\"\n",
        "  }\n",
        "  model_qualifier = \"fakeddit\"\n",
        "else:\n",
        "  raise NotImplementedError()\n",
        "\n",
        "# nomask | rtm | rwm | ktm_tfidf | kwm_tfidf | ktm_att | kwm_att | ktrtm_tfidf | kwrwm_tfidf | ktrtm_att | kwrwm_att\n",
        "mask_overall = True;tm = False;wm = False;ktm=False;kwm=False;\n",
        "if masking == \"nomask\":\n",
        "  mask_overall = False\n",
        "if masking == \"rtm\" or masking == \"ktrtm_tfidf\" or masking == \"ktrtm_att\":\n",
        "  tm = True\n",
        "if masking == \"rwm\" or masking == \"kwrwm_tfidf\" or masking == \"kwrwm_att\":\n",
        "  wm = True\n",
        "if masking == \"ktm_tfidf\" or masking == \"ktm_att\" or masking == \"ktrtm_att\":\n",
        "  ktm = True\n",
        "if masking == \"kwm_tfidf\" or masking == \"kwm_att\" or masking == \"kwrwm_att\":\n",
        "  kwm = True\n",
        "\n",
        "# Other options\n",
        "model_core_name = \"-\".join([\"fnc\",\"expert\",dataset, masking])\n",
        "model_backbone = model\n",
        "model_base = model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3K40ykXsESB3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9881423-2db2-424f-ac01-33c609a7e02c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ednaml, torch\n",
        "from ednaml.core import EdnaDeploy"
      ],
      "metadata": {
        "id": "N2TvORAG_25Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ednaml.deploy.HFDeploy import HFDeploy\n",
        "import os\n",
        "\n",
        "class LabelingDeployment(HFDeploy):\n",
        "  def output_setup(self, **kwargs):\n",
        "    self.ofile = kwargs.get(\"label_file_name\")\n",
        "    if self.ofile == \"None\":\n",
        "      raise ValueError(\"No filename provided\")\n",
        "    self.oobj = open(self.ofile, \"w\")\n",
        "    self.oobj.write(\",\".join([\n",
        "      \"predicted_label\",\n",
        "      \"l2_dist\",\n",
        "      \"l2_hdthreshold\",\n",
        "      \"l2_proxylabels\",\n",
        "      \"cos_dist\",\n",
        "      \"cos_hdthreshold\",\n",
        "      \"cos_proxylabels\",\n",
        "      \"l_score\",\n",
        "      \"smooth_l_score\",\n",
        "      \"l_threshold\",\n",
        "      \"smooth_l_threshold\",\n",
        "      \"l_proxylabel\",\n",
        "      \"logit_raw\",\n",
        "      \"logit_threshold\"\n",
        "      ])+\"\\n\")\n",
        "\n",
        "  def output_step(self, logits, features, secondary):\n",
        "    predicted_label = torch.argmax(torch.nn.functional.softmax(logits.cpu(), dim=1), dim=1).tolist()\n",
        "    l2_dist = secondary[2][\"FastKMP-l2\"][\"distance\"].to(torch.float32).tolist()\n",
        "    l2_hdthreshold = secondary[2][\"FastKMP-l2\"][\"threshold\"].to(torch.float32).tolist()\n",
        "    l2_proxylabels = secondary[2][\"FastKMP-l2\"][\"proxy_labels\"].to(torch.float32).tolist()\n",
        "    \n",
        "    cos_dist = secondary[2][\"FastKMP-cos\"][\"distance\"].to(torch.float32).tolist()\n",
        "    cos_hdthreshold = secondary[2][\"FastKMP-cos\"][\"threshold\"].to(torch.float32).tolist()\n",
        "    cos_proxylabels = secondary[2][\"FastKMP-cos\"][\"proxy_labels\"].to(torch.float32).tolist()\n",
        "\n",
        "    l_score = secondary[2][\"FRL-midas\"][\"l_score\"]\n",
        "    smooth_l_score = secondary[2][\"FRL-midas\"][\"smooth_l_score\"]\n",
        "    l_threshold = secondary[2][\"FRL-midas\"][\"l_threshold\"]\n",
        "    smooth_l_threshold = secondary[2][\"FRL-midas\"][\"smooth_l_threshold\"]\n",
        "    l_proxylabel = secondary[2][\"FRL-midas\"][\"proxy_label\"].to(torch.float32).tolist()\n",
        "\n",
        "    logit_raw = secondary[2][\"logit-confidence\"][\"logit\"].to(torch.float32).tolist()\n",
        "    logit_threshold = secondary[2][\"logit-confidence\"][\"logit_threshold\"].to(torch.float32).tolist()\n",
        "\n",
        "    output_list = [\",\".join(map(str,item)) for item in zip(\n",
        "      predicted_label,\n",
        "      l2_dist,\n",
        "      l2_hdthreshold,\n",
        "      l2_proxylabels,\n",
        "      cos_dist,\n",
        "      cos_hdthreshold,\n",
        "      cos_proxylabels,\n",
        "      l_score,\n",
        "      smooth_l_score,\n",
        "      l_threshold,\n",
        "      smooth_l_threshold,\n",
        "      l_proxylabel,\n",
        "      logit_raw,\n",
        "      logit_threshold\n",
        "      )]\n",
        "    self.oobj.write(\"\\n\".join(output_list)+\"\\n\")\n",
        "  def end_of_deployment(self):\n",
        "      self.oobj.close()"
      ],
      "metadata": {
        "id": "MLOF-jQ-KIbw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ed = EdnaDeploy(config=[\"./GLAMOR/profiles/FNC/labeling/config_base.yml\",  # logging, deployment, crawler\n",
        "                          model_variant,\n",
        "                        \"./GLAMOR/profiles/FNC/experts/configs/plugin_base.yml\"],\n",
        "                config_inject = [\n",
        "                    (\"SAVE.MODEL_CORE_NAME\", model_core_name),\n",
        "                    (\"SAVE.MODEL_BACKBONE\", model_backbone),\n",
        "                    (\"SAVE.MODEL_QUALIFIER\", model_qualifier),\n",
        "                    (\"SAVE.DRIVE_BACKUP\", True),\n",
        "                    (\"SAVE.LOG_BACKUP\", False),\n",
        "                    (\"MODEL.MODEL_BASE\", model_backbone),\n",
        "                    (\"SAVE.SAVE_FREQUENCY\", 5), # To ensure nothing actually gets saved, since we only run for 1 epoch\n",
        "                    (\"DEPLOYMENT.EPOCHS\", 1)\n",
        "                ],\n",
        "                weights=\"fnc-expert-nela-elections-nomask-v2_epoch3.pth\")\n",
        "\n",
        "ed.cfg.DEPLOYMENT.OUTPUT_ARGS[\"label_file_name\"] = tweet_file + \"-\" + ed.saveMetadata.MODEL_SAVE_FOLDER+\".csv\"\n",
        "ed.cfg.DEPLOYMENT.DATAREADER.CRAWLER_ARGS[\"azfile\"] = \"%s-extended.json.gz\"%tweet_file\n",
        "# No masking for everything, so we will not edit it here. \n",
        "\n",
        "\n",
        "ed.add(\"./GLAMOR/profiles/FNC/fnc-extended-labeling-crawler.py\")\n",
        "ed.addDeploymentClass(LabelingDeployment)"
      ],
      "metadata": {
        "id": "Y4cCp18M_22i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d967ea5-1d1d-4247-d057-faaa4a73e647"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "15:05:12 Adding a crawler, from /content/GLAMOR/profiles/FNC/fnc-extended-labeling-crawler.py, with inferred name FNCCrawler\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Injected key-value pair:  SAVE.MODEL_CORE_NAME, fnc-expert-nela-nomask\n",
            "Injected key-value pair:  SAVE.MODEL_BACKBONE, albert-base-v2\n",
            "Injected key-value pair:  SAVE.MODEL_QUALIFIER, nela_covid_2020\n",
            "Injected key-value pair:  SAVE.DRIVE_BACKUP, True\n",
            "Injected key-value pair:  SAVE.LOG_BACKUP, False\n",
            "Injected key-value pair:  MODEL.MODEL_BASE, albert-base-v2\n",
            "Injected key-value pair:  SAVE.SAVE_FREQUENCY, 5\n",
            "Injected key-value pair:  DEPLOYMENT.EPOCHS, 1\n",
            "Log file exists at fnc-expert-nela-nomask-v2-albert-base-v2-nela_covid_2020/fnc-expert-nela-nomask-v2-albert-base-v2-nela_covid_2020-logger.log. Will attempt to append there.\n",
            "Registering a crawler: <class './GLAMOR/profiles/FNC/fnc-extended-labeling-crawler.py.FNCCrawler'>, from file: /content/GLAMOR/profiles/FNC/fnc-extended-labeling-crawler.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ed.apply()"
      ],
      "metadata": {
        "id": "k6nKa_ixKEOT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "42ef5320-818b-4ec4-dd65-0228d25d804a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "15:05:16 ****************************************\n",
            "15:05:16 \n",
            "15:05:16 \n",
            "15:05:16 Using the following configuration:\n",
            "15:05:16 DEPLOYMENT:\n",
            "  DATAREADER:\n",
            "    CRAWLER_ARGS:\n",
            "      azcontainer: edna-covid-extended\n",
            "      azfile: tweets-2020-01-22-extended.json.gz\n",
            "      azstorage: ednadatasets\n",
            "    DATAREADER: HFReader\n",
            "    DATASET_ARGS:\n",
            "      annotation_idxs:\n",
            "      - 1\n",
            "      - 2\n",
            "      classificationclass:\n",
            "      - fnews\n",
            "      data_shuffle: false\n",
            "      keyword_mask: true\n",
            "      keywords: []\n",
            "      label_idxs:\n",
            "      - 3\n",
            "      masking: false\n",
            "      maxlen: 512\n",
            "      mlm_probability: 0.15\n",
            "      shard_replace: false\n",
            "      shardcache: true\n",
            "      shardname: fnc-extended-shard\n",
            "      shardpath: datashard-artifacts\n",
            "      shardsize: 20000\n",
            "      shuffle: false\n",
            "    GENERATOR: null\n",
            "    GENERATOR_ARGS:\n",
            "      from_pretrained: albert-base-v2\n",
            "      tokenizer: HFAutoTokenizer\n",
            "  DEPLOY: HFDeploy\n",
            "  DEPLOYMENT_ARGS: {}\n",
            "  EPOCHS: 1\n",
            "  OUTPUT_ARGS:\n",
            "    label_file_name: tweets-2020-01-22-fnc-expert-nela-nomask-v2-albert-base-v2-nela_covid_2020.csv\n",
            "  PLUGIN:\n",
            "    HOOKS: activated\n",
            "    RESET: false\n",
            "EXECUTION:\n",
            "  DATAREADER:\n",
            "    CRAWLER_ARGS: {}\n",
            "    DATAREADER: DataReader\n",
            "    DATASET_ARGS: {}\n",
            "    GENERATOR: null\n",
            "    GENERATOR_ARGS:\n",
            "      from_pretrained: albert-base-v2\n",
            "      tokenizer: HFAutoTokenizer\n",
            "  EPOCHS: 10\n",
            "  FP16: false\n",
            "  MODEL_SERVING: false\n",
            "  OPTIMIZER_BUILDER: ClassificationOptimizer\n",
            "  PLUGIN:\n",
            "    HOOKS: always\n",
            "    RESET: false\n",
            "  SKIPEVAL: false\n",
            "  TEST_FREQUENCY: 1\n",
            "  TRAINER: BaseTrainer\n",
            "  TRAINER_ARGS:\n",
            "    accumulation_steps: 1\n",
            "LOGGING:\n",
            "  INPUT_SIZE:\n",
            "  - 16\n",
            "  - 512\n",
            "  STEP_VERBOSE: 100\n",
            "LOSS: []\n",
            "LOSS_OPTIMIZER:\n",
            "- BASE_LR: 0.001\n",
            "  LR_BIAS_FACTOR: 1.0\n",
            "  OPTIMIZER: Adam\n",
            "  OPTIMIZER_KWARGS: {}\n",
            "  OPTIMIZER_NAME: opt-1\n",
            "  WEIGHT_BIAS_FACTOR: 0.0005\n",
            "  WEIGHT_DECAY: 0.0005\n",
            "LOSS_SCHEDULER:\n",
            "- LR_KWARGS:\n",
            "    step_size: 20\n",
            "  LR_SCHEDULER: StepLR\n",
            "  SCHEDULER_NAME: opt-1\n",
            "MODEL:\n",
            "  BUILDER: ednaml_model_builder\n",
            "  MODEL_ARCH: HFAutoModel\n",
            "  MODEL_BASE: albert-base-v2\n",
            "  MODEL_KWARGS:\n",
            "    auto_class: AutoModelForSequenceClassification\n",
            "    hidden_act: gelu\n",
            "    pooling: pooled\n",
            "  MODEL_NORMALIZATION: bn\n",
            "  PARAMETER_GROUPS:\n",
            "  - opt-1\n",
            "MODEL_PLUGIN:\n",
            "  FRL-midas:\n",
            "    PLUGIN: FastRandomizedLipschitz\n",
            "    PLUGIN_KWARGS:\n",
            "      alpha: 0.6\n",
            "      batch_size: 256\n",
            "      classifier_access: encoder.classifier\n",
            "      dimensions: 768\n",
            "      dist: euclidean\n",
            "      iterations: 30\n",
            "      proxies: 15\n",
            "      proxy_epochs: 1\n",
            "    PLUGIN_NAME: FRL-midas\n",
            "  FastKMP-cos:\n",
            "    PLUGIN: FastKMeansProxy\n",
            "    PLUGIN_KWARGS:\n",
            "      alpha: 0.6\n",
            "      batch_size: 256\n",
            "      classifier_access: encoder.classifier\n",
            "      dimensions: 768\n",
            "      dist: cosine\n",
            "      iterations: 30\n",
            "      proxies: 20\n",
            "    PLUGIN_NAME: FastKMP-cos\n",
            "  FastKMP-l2:\n",
            "    PLUGIN: FastKMeansProxy\n",
            "    PLUGIN_KWARGS:\n",
            "      alpha: 0.6\n",
            "      batch_size: 256\n",
            "      classifier_access: encoder.classifier\n",
            "      dimensions: 768\n",
            "      dist: euclidean\n",
            "      iterations: 30\n",
            "      proxies: 20\n",
            "    PLUGIN_NAME: FastKMP-l2\n",
            "  logit-confidence:\n",
            "    PLUGIN: LogitConfidence\n",
            "    PLUGIN_KWARGS:\n",
            "      num_classes: 2\n",
            "    PLUGIN_NAME: logit-confidence\n",
            "OPTIMIZER:\n",
            "- BASE_LR: 0.001\n",
            "  LR_BIAS_FACTOR: 1.0\n",
            "  OPTIMIZER: Adam\n",
            "  OPTIMIZER_KWARGS: {}\n",
            "  OPTIMIZER_NAME: opt-1\n",
            "  WEIGHT_BIAS_FACTOR: 0.0005\n",
            "  WEIGHT_DECAY: 0.0005\n",
            "SAVE:\n",
            "  CHECKPOINT_DIRECTORY: ./drive/MyDrive/Projects/FNC/Models/\n",
            "  DRIVE_BACKUP: true\n",
            "  LOG_BACKUP: false\n",
            "  MODEL_BACKBONE: albert-base-v2\n",
            "  MODEL_CORE_NAME: fnc-expert-nela-nomask\n",
            "  MODEL_QUALIFIER: nela_covid_2020\n",
            "  MODEL_VERSION: 2\n",
            "  SAVE_FREQUENCY: 5\n",
            "  STEP_SAVE_FREQUENCY: 0\n",
            "SCHEDULER:\n",
            "- LR_KWARGS:\n",
            "    step_size: 20\n",
            "  LR_SCHEDULER: StepLR\n",
            "  SCHEDULER_NAME: opt-1\n",
            "STORAGE:\n",
            "  STORAGE_ARGS: {}\n",
            "  TYPE: BaseStorage\n",
            "  URL: ./\n",
            "TEST_TRANSFORMATION:\n",
            "  ARGS: {}\n",
            "  BATCH_SIZE: 16\n",
            "  WORKERS: 1\n",
            "TRAIN_TRANSFORMATION:\n",
            "  ARGS: {}\n",
            "  BATCH_SIZE: 16\n",
            "  WORKERS: 1\n",
            "extensions:\n",
            "- EXECUTION\n",
            "- SAVE\n",
            "- STORAGE\n",
            "- TRANSFORMATION\n",
            "- MODEL\n",
            "- LOSS\n",
            "- OPTIMIZER\n",
            "- SCHEDULER\n",
            "- LOSS_OPTIMIZER\n",
            "- LOSS_SCHEDULER\n",
            "- LOGGING\n",
            "- DEPLOYMENT\n",
            "- MODEL_PLUGIN\n",
            "\n",
            "15:05:16 \n",
            "15:05:16 \n",
            "15:05:16 ****************************************\n",
            "15:05:16 Not downloading weights. Weights path already provided.\n",
            "15:05:16 No previous stop detected. Will start from epoch 0\n",
            "15:05:16 Reading data with DataReader HFReader\n",
            "15:05:16 Default CRAWLER is <class 'ednaml.crawlers.Crawler'>\n",
            "15:05:16 Default DATASET is <class 'ednaml.generators.HFGenerator.HFDataset'>\n",
            "15:05:16 Default GENERATOR is <class 'ednaml.generators.HFGenerator.HFGenerator'>\n",
            "15:05:16 Updating CRAWLER to FNCCrawler\n",
            "15:05:16 Crawling https://ednadatasets.blob.core.windows.net/edna-covid-extended/tweets-2020-01-22-extended.json.gz\n",
            "15:05:16 https://ednadatasets.blob.core.windows.net/edna-covid-extended/tweets-2020-01-22-extended.json.gz already exists at tweets-2020-01-22-extended.json.gz\n",
            "15:05:16 Generating dataloader `HFGenerator` with `test` mode\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building Transforms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "15:05:17 [Mode `test`] Will look in path [test-datashard-artifacts] for shards `fnc-extended-shard-[e].pt`\n",
            "15:05:17 Shards already exist and `shard_replace` is False\n",
            "15:05:17 Creating shardpath test-datashard-artifacts\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building Dataset\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-e9a191311393>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0med\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/GLAMOR/src/ednaml/core/EdnaDeploy.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetPreviousStop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuildDataloaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuildModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/GLAMOR/src/ednaml/core/EdnaDeploy.py\u001b[0m in \u001b[0;36mbuildDataloaders\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;31m# Only need test dataloader...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuildTestDataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_reader_instance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrawler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     def buildTestDataloader(\n",
            "\u001b[0;32m/content/GLAMOR/src/ednaml/core/EdnaDeploy.py\u001b[0m in \u001b[0;36mbuildTestDataloader\u001b[0;34m(self, data_reader, crawler_instance)\u001b[0m\n\u001b[1;32m    114\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEPLOYMENT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDATAREADER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGENERATOR_ARGS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             )\n\u001b[0;32m--> 116\u001b[0;31m             self.test_generator.build( \n\u001b[0m\u001b[1;32m    117\u001b[0m                 \u001b[0mcrawler_instance\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                 \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTEST_TRANSFORMATION\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/GLAMOR/src/ednaml/generators/__init__.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, datacrawler, batch_size, workers, **kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mworkers\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         self.dataset = self.buildDataset(\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mdatacrawler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         )\n",
            "\u001b[0;32m/content/GLAMOR/src/ednaml/generators/HFGenerator.py\u001b[0m in \u001b[0;36mbuildDataset\u001b[0;34m(self, crawler, mode, transform, **kwargs)\u001b[0m\n\u001b[1;32m    591\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbuildDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrawler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#<-- dataset args:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Building Dataset\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mHFDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrawler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"crawl\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# needs maxlen, memcache, mlm_probability\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbuildDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/GLAMOR/src/ednaml/generators/HFGenerator.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, logger, dataset, mode, transform, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshardsaveindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_shardpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"*.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshardsaveindex\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"`shardsaveindex` is {val}, which is less than permissible minimum value of 1\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshardsaveindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Obtained %i shards\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshardsaveindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshard_load_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m   \u001b[0;31m# self.shardsaveindex is the maximum number of shards\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: `shardsaveindex` is 0, which is less than permissible minimum value of 1"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ed.deploy()"
      ],
      "metadata": {
        "id": "cZhe3AohKFJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ed.model.plugins[\"FastKMP-l2\"].proxies"
      ],
      "metadata": {
        "id": "Z-FHK2N8ebDm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv(\"tweets-2020-01-22-fnc-expert-efnd-nomask-v1-albert-base-v2-kagglefn_short.csv\")"
      ],
      "metadata": {
        "id": "OU0F_yBBffb6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "E7zQy8x4fkbK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploring"
      ],
      "metadata": {
        "id": "6xm3Kuc-NDKa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Generate FNC-AlBERT\n",
        "\n",
        "Now, we generate an LLM specific for a window. We have several choices for windows, controlled by the first few cells:\n",
        "\n",
        "1. Daily window: Given a specific date, we will use the FNC-extended dataset for that day\n",
        "2. Monthly window: We aggregate all daily window FNC-extended datasets\n",
        "3. Sampled monthy/date range: Given a range of dates, we first aggregate the daily FNC-extended. Then, we sample from this aggregate ~100M data points. \n",
        "\n",
        "The LLM naming convention is: `FNC-AlBERT-<Month>-<Date>-<Year>-<Sampled>`. Here, `<Month>` is the named month (e.g. January, February); `<Date>` is only present for daily window; `<Year>` is the, well, year for the source data, and `<Sampled>` is only present if the source data is a sampled set. If it is a sampled set, then `<Sample>` is one of `MonthSample`, `Week<#>Sample`, `DaySample`. (`Week<#>Sample` is if the range is one week. We'll record the week number of the date range here.) Other sample ranges are not covered for conciseness.\n",
        "\n",
        "Our LLM Generation step, given a dataset, is as follows:\n",
        "\n",
        "1. Preprocess the data samples as: extract raw text, lowercase, discard retweet, word tokenize, record first 5 words in dict to discard duplicates; tokenize usernames (begins with @) with `[user]`, tokenize urls (begins with http) with [url], convert emojis to `:emojitext:` using emoji library; rejoin the word tokenized array to create the processed text. We write each text item to a like separated file.\n",
        "\n",
        "2. Shuffle the file. Then generate a pretraining file. Each document is line-separated. We don't care about NSP or SOP.\n",
        "\n",
        "3. Use the HFPretrainingGenerator to shard the data. Each sample has sentence. During data loading, random trigrams are masked (simpler than word masking). NSP unneeded, so only use MLM Head!!\n",
        "\n",
        "4. Use HFPretrainer to perform pretraining of AlBERTForPretraining. Generate a batch, and ignore NSP loss where not available.\n",
        "\n",
        "5. Train, and save every 30k epochs. Given batch size of 32 (tweet length...), we need to train for 3.2M steps!!! Note: we will use a aggregator of 32 as well.\n",
        "\n",
        "6. MultiGPU setup, when possible."
      ],
      "metadata": {
        "id": "oZR5rjAnK_fx"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdDVnQvLkaAi"
      },
      "source": [
        "# ------------------------   Extras   -----------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxY59vsPkb49"
      },
      "source": [
        "# Generating plugins"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfXWZ4FNmzGx"
      },
      "source": [
        "### CHECKLIST:\n",
        "\n",
        "- is the `model_config` correct?\n",
        "- is the `deploy_config` correct?\n",
        "- is the `model_plugins` correct? This should not need to change for any of them.\n",
        "\n",
        "- is the `model_functions` correct? Cross-reference to `model_config`!\n",
        "\n",
        "- is the `dataloader_mode` correct?\n",
        "- is the `batch_size` correct?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wnunIsv5hGVf"
      },
      "outputs": [],
      "source": [
        "GENERATING_PLUGINS = True\n",
        "model_config = \"./GLAMOR/profiles/MiDAS/expert-experiments/midas-cmumiscov-2.yml\"\n",
        "deploy_config = \"./GLAMOR/profiles/NELA/nela-covid-deploy.yml\"\n",
        "model_plugins = \"./GLAMOR/profiles/NELA/plugins.yml\"\n",
        "model_functions = [\"./GLAMOR/profiles/MiDAS/midas-dataset.py\",\n",
        "                    \"./GLAMOR/profiles/MiDAS/midas-expert.py\"]\n",
        "                    \n",
        "dataloader_mode = \"train\" # CHANGE THIS IF DEBUGGING\n",
        "batch_size = 128          # CHANGE THIS IF TOO SLOW OR CRASHING\n",
        "# EXTRAS\n",
        "deployment_functions = \"./GLAMOR/profiles/NELA/deploy-plugin-usage.py\"  # use generation.py is generating plugins\n",
        "epochs = 1                # CHANGE THIS IF GENERATING PLUGINS ----> 6       ELSE, use 1 epoch\n",
        "ignore_plugins = []       # CHANGE THIS IF PLUGINS NEED RESETTING ----> [\"KMP-l2\", \"KMP-cos\", \"RL-midas\"]\n",
        "if GENERATING_PLUGINS:\n",
        "  ignore_plugins = [\"KMP-l2\", \"KMP-cos\", \"RL-midas\"]\n",
        "  epochs = 6\n",
        "  deployment_functions =  \"./GLAMOR/profiles/NELA/deploy-plugin-generation.py\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HeB0G6csm9CW"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h3lKPAzOm8_v"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import ednaml\n",
        "from ednaml.core import EdnaDeploy\n",
        "from ednaml.plugins.KMeansProxy import KMeansProxy\n",
        "torch.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oGWP-Lzl5K86"
      },
      "outputs": [],
      "source": [
        "ed = EdnaDeploy(config=model_config, deploy=[deploy_config, model_plugins] , dataloader_mode = dataloader_mode)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zH2jXma3xhc3"
      },
      "source": [
        "We make sure we have the correct `DATAREADER`. Here we use the one from `EXECUTION`, because it comes from the model we are loading, ensuring we are working with the model's training/testing data. \n",
        "\n",
        "We can also manually set `EPOCHS` here, for debugging or fast deployment editing purposes. Since deployments are ephemeral and not logged (for the time being), this is sufficient."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sj2MR0k-XHOm"
      },
      "outputs": [],
      "source": [
        "ed.cfg.DEPLOYMENT.DATAREADER = ed.cfg.EXECUTION.DATAREADER\n",
        "#\n",
        "ed.cfg.DEPLOYMENT.DATAREADER.DATAREADER = \"AlbertReader\"\n",
        "ed.cfg.TEST_TRANSFORMATION.BATCH_SIZE = batch_size\n",
        "ed.cfg.DEPLOYMENT.EPOCHS = epochs\n",
        "ed.cfg.DEPLOYMENT.PLUGIN.HOOKS = 'warmup'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lG-X0lN3x5pa"
      },
      "source": [
        "If needed, go into the files and make sure the correct functions are registered with EdnaML, specifically the correct deployment plugin.\n",
        "\n",
        "There is one deployment plugin for writing to an output, and one for not writing to an output (for generating the plugins and doing nothing with the actual returns.\n",
        "\n",
        "**`NOTE: potential bug. midas-dataset also contains MiDASGenerator now, but this part NEEDS to use AlBERTReader. Solution. Deregister MiDASGenerator from midas-datasert. Solution: integrated MiDASGenerator and AlbertReader with datalabels.`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L1wIwei15S04"
      },
      "outputs": [],
      "source": [
        "ed.add(model_functions)\n",
        "ed.add(deployment_functions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HWfgOo9M3KGX"
      },
      "outputs": [],
      "source": [
        "ed.apply()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NQSP4Otj3UsV"
      },
      "outputs": [],
      "source": [
        "ed.deploy(ignore_plugins = ignore_plugins)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3gUSjVY8ao8C"
      },
      "outputs": [],
      "source": [
        "ed.model.plugins['RL-midas'].save()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DArM05AeVeir"
      },
      "outputs": [],
      "source": [
        "ed.model.plugins['RL-midas'].save()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51AtEjJFl97w"
      },
      "source": [
        "# Cross Validation Experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4xHDwXl-3OTA"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import ednaml\n",
        "import glob, os\n",
        "from ednaml.core import EdnaDeploy, EdnaML\n",
        "torch.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WsZv09uPwHKb"
      },
      "source": [
        "## Testing NELA/Fakeddit on MiDAS Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yer5K3o9_Njq"
      },
      "outputs": [],
      "source": [
        "# NELA\n",
        "cfg = \"./GLAMOR/profiles/NELA/nela-covid-v1.yml\"\n",
        "model_file = \"./GLAMOR/profiles/NELA/nela.py\"\n",
        "# Fakeddit\n",
        "#cfg = \"./GLAMOR/profiles/Fakeddit/fakeddit-v3.yml\"\n",
        "#model_file = \"./GLAMOR/profiles/Fakeddit/fakeddit.py\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NZ1znkUPwJ5z"
      },
      "outputs": [],
      "source": [
        "data_folder = \"Data\"\n",
        "datasets_folders = glob.glob(os.path.join(data_folder, \"*\"))\n",
        "datasets_folders = [os.path.basename(item) for item in datasets_folders if os.path.basename(item) not in [\"coaid_tweets\", \"recov\", \"nela-elections-2020\", \"all_train.tsv\", \"all_test_public.tsv\", \"nela-covid-2020\", \"nela-gt-2020\", \"all_validate.tsv\"]]\n",
        "datasets_folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SFbzthaa2KI4"
      },
      "outputs": [],
      "source": [
        "# set up the model\n",
        "eml = EdnaML(config=cfg, mode=\"test\", test_only = True, logger_save_name=\"cd-eval\")\n",
        "eml2 = EdnaML(config=\"./GLAMOR/profiles/MiDAS/encoder-experiments/midas-tsne.yml\", \n",
        "                mode=\"test\", test_only = True, logger_save_name=\"cd-eval\")  # weights path should be automatically inferred!!! :)\n",
        "\n",
        "eml.cfg.EXECUTION.DATAREADER = eml2.cfg.EXECUTION.DATAREADER\n",
        "eml.cfg.EXECUTION.DATAREADER.DATAREADER = \"AlbertReader\"\n",
        "eml.cfg.EXECUTION.DATAREADER.CRAWLER_ARGS[\"include\"] = datasets_folders\n",
        "# So we have model loaded with correct parameters\n",
        "\n",
        "eml.add(model_file) #add model\n",
        "eml.add(\"./GLAMOR/profiles/MiDAS/midas-dataset.py\") # replace crawler\n",
        "eml.add(\"./GLAMOR/profiles/MiDAS/midas-trainer.py\") # replace trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0vRzS3rI2KGY"
      },
      "outputs": [],
      "source": [
        "eml.apply()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZNDv_rL-TnG"
      },
      "outputs": [],
      "source": [
        "preds, labels, classes, logits = eml.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "my3xebM87AcV"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "import numpy as np\n",
        "\n",
        "print (\"Domain accuracies for %s\"%str(eml.cfg.SAVE.MODEL_QUALIFIER))\n",
        "for idx, dlabel in enumerate(range(max(labels[1]).item()+1)):\n",
        "  acc = torch.mean((preds[labels[1]==dlabel] == labels[0][labels[1]==dlabel]).float())\n",
        "  micro_fscore = np.mean(f1_score(labels[0][labels[1]==dlabel], preds[labels[1]==dlabel], average=\"micro\"))\n",
        "  weighted_fscore = np.mean(f1_score(labels[0][labels[1]==dlabel], preds[labels[1]==dlabel], average=\"weighted\"))\n",
        "  print (\"\\t Domain {0}\\t {1:0.3f} \\t{2:0.3f} \\t{3:0.3f}\\t\\t{4}\".format(datasets_folders[idx], acc, micro_fscore, weighted_fscore, torch.sum(labels[1]==dlabel).item()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f--DYZ6S_dls"
      },
      "source": [
        "## Testing MIDAS Models on NELA/Fakeddit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KZbcIvgDWf31"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import ednaml\n",
        "import glob, os\n",
        "from ednaml.core import EdnaDeploy, EdnaML\n",
        "torch.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFozzqfkAjb6"
      },
      "outputs": [],
      "source": [
        "expert_config = \"./GLAMOR/profiles/MiDAS/expert-experiments/midas-covrumor-1.yml\"\n",
        "\"\"\"\n",
        "\"./GLAMOR/profiles/MiDAS/expert-experiments/midas-kagglefnlong-1.yml\"\n",
        "\"./GLAMOR/profiles/MiDAS/expert-experiments/midas-covrumor-1.yml\"\n",
        "\"./GLAMOR/profiles/MiDAS/expert-experiments/midas-covidfn-1.yml\"\n",
        "\"./GLAMOR/profiles/MiDAS/expert-experiments/midas-covid_cq-1.yml\"\n",
        "\"./GLAMOR/profiles/MiDAS/expert-experiments/midas-cov19fntitle-1.yml\"\n",
        "\"./GLAMOR/profiles/MiDAS/expert-experiments/midas-cov19fntext-1.yml\"\n",
        "\"./GLAMOR/profiles/MiDAS/expert-experiments/midas-coaid_news-1.yml\"\n",
        "\"./GLAMOR/profiles/MiDAS/expert-experiments/midas-cmumiscov-2.yml\"\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DHFm8FJa_tB-"
      },
      "outputs": [],
      "source": [
        "# NELA\n",
        "#cfg = \"./GLAMOR/profiles/NELA/nela-covid-v1.yml\"\n",
        "#crawler_file = \"./GLAMOR/profiles/NELA/nela.py\"\n",
        "# Fakeddit\n",
        "cfg = \"./GLAMOR/profiles/Fakeddit/fakeddit-v3.yml\"\n",
        "crawler_file = \"./GLAMOR/profiles/Fakeddit/fakeddit.py\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_msnPJpywL4z"
      },
      "outputs": [],
      "source": [
        "# set up the model\n",
        "eml = EdnaML(config=expert_config, mode=\"test\", test_only = True, logger_save_name=\"cd-eval\")\n",
        "eml2 = EdnaML(config=cfg, \n",
        "                mode=\"test\", test_only = True, logger_save_name=\"cd-eval\")  # weights path should be automatically inferred!!! :)\n",
        "\n",
        "eml.cfg.EXECUTION.DATAREADER = eml2.cfg.EXECUTION.DATAREADER\n",
        "# So we have model loaded with correct parameters\n",
        "\n",
        "eml.add(crawler_file) # add crawler/trainer\n",
        "eml.add(\"./GLAMOR/profiles/MiDAS/midas-expert.py\") #replace model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QPa5Rg9yACYX"
      },
      "outputs": [],
      "source": [
        "eml.apply()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tTbhbcjUADOP"
      },
      "outputs": [],
      "source": [
        "preds, labels, classes, logits = eml.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1tM_2VaBCWva"
      },
      "outputs": [],
      "source": [
        "labels[labels!=0] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w_CSFxjPCWva"
      },
      "outputs": [],
      "source": [
        "accuracy = (preds != labels).sum().float() / float(labels.size(0))\n",
        "print(\"\\tAccuracy: {:.3%}\".format(accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMjNkF9q9Ihz"
      },
      "source": [
        "## NELA <-> Fakeddit cross validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08DGKH029K4S"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import ednaml\n",
        "import glob, os\n",
        "from ednaml.core import EdnaDeploy, EdnaML\n",
        "torch.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ECXQSK4W9N6X"
      },
      "outputs": [],
      "source": [
        "# NELA\n",
        "b_cfg = \"./GLAMOR/profiles/NELA/nela-covid-v1.yml\"\n",
        "b_crawlerfile = \"./GLAMOR/profiles/NELA/nela.py\"\n",
        "# Fakeddit\n",
        "cfg = \"./GLAMOR/profiles/Fakeddit/fakeddit-v3.yml\"\n",
        "model_file = \"./GLAMOR/profiles/Fakeddit/fakeddit.py\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xcQT02459UZW"
      },
      "outputs": [],
      "source": [
        "# set up the model\n",
        "eml = EdnaML(config=cfg, mode=\"test\", test_only = True, logger_save_name=\"cd-eval\")\n",
        "eml2 = EdnaML(config=b_cfg, \n",
        "                mode=\"test\", test_only = True, logger_save_name=\"cd-eval\")  # weights path should be automatically inferred!!! :)\n",
        "\n",
        "eml.cfg.EXECUTION.DATAREADER = eml2.cfg.EXECUTION.DATAREADER\n",
        "# So we have model loaded with correct parameters\n",
        "\n",
        "eml.add(b_crawlerfile) #add crawler/trainer\n",
        "eml.add(model_file) # replace model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bHxhTQcW-E86"
      },
      "outputs": [],
      "source": [
        "eml.apply()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dkk2B45j-EtK"
      },
      "outputs": [],
      "source": [
        "preds, labels, classes, logits = eml.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2YFkjvcgDFx"
      },
      "source": [
        "#### Converting the fakeddit true labels to other 1/0 versions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hGsJx4o-BsRM"
      },
      "outputs": [],
      "source": [
        "labels[labels!=0] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nM35mp48CEW-"
      },
      "outputs": [],
      "source": [
        "accuracy = (preds == labels).sum().float() / float(labels.size(0))\n",
        "print(\"\\tAccuracy: {:.3%}\".format(accuracy))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m_zzDtRf-oRj"
      },
      "outputs": [],
      "source": [
        "!rm -rf -- test-datashard-artifacts/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4t8TuXCxgGLe"
      },
      "source": [
        "#### Converting the Fakeddit predictions to other versions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pKmXAGnP-qo3"
      },
      "outputs": [],
      "source": [
        "preds[preds!=0] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qTv3_9DH_il5"
      },
      "outputs": [],
      "source": [
        "accuracy = (preds == labels).sum().float() / float(labels.size(0))\n",
        "print(\"\\tAccuracy: {:.3%}\".format(accuracy))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_MGRfew7gMw0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "OJQ1vkUS-4hv",
        "OUETMOy3gGvu",
        "y4h8JjeAfpDo",
        "TqJoyEW1f_a1",
        "d5j3WfN0fpIT",
        "NQCbxSJDf7Ix",
        "0KjvT_ZJovGY",
        "uqCdOF7tCj8N",
        "FOwc42Dv5i6H",
        "bBLksdNI5Ukb",
        "kqSK-TBM5Z9v",
        "vUiGLd_6sbPG",
        "EU53fUFKuFEb",
        "WETqeAOTuoGl",
        "5rmrRbkmCzBW",
        "kMcmognzvBq2",
        "-5ADOWKGvn4Y",
        "I45khl9Bum_Y",
        "UdDVnQvLkaAi",
        "uxY59vsPkb49",
        "PfXWZ4FNmzGx",
        "51AtEjJFl97w",
        "f--DYZ6S_dls"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "45f849ad6f7f4c57a44b0dc14eb869bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c26cf79a582042a582ed0ba26b578fdd",
              "IPY_MODEL_1f0a90c525354780a941cb3b04f81051",
              "IPY_MODEL_9d75dd5bb7e4412ea2a2714461e609bf"
            ],
            "layout": "IPY_MODEL_f93b0416a5a34076b8445983721dbd53"
          }
        },
        "c26cf79a582042a582ed0ba26b578fdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee145df1cc5f43f5821ab9a9a050982d",
            "placeholder": "​",
            "style": "IPY_MODEL_26136ec52cf7423db87282048bd2669b",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "1f0a90c525354780a941cb3b04f81051": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1aa832a2f044d4c9f2947dc78439b71",
            "max": 684,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_91ebd0e201d7493ab8860df0c7a465c9",
            "value": 684
          }
        },
        "9d75dd5bb7e4412ea2a2714461e609bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e356c6ed0b7449ebfb5b64b145e3c2b",
            "placeholder": "​",
            "style": "IPY_MODEL_94558b969a4644dd9fef2195b56634fe",
            "value": " 684/684 [00:00&lt;00:00, 25.0kB/s]"
          }
        },
        "f93b0416a5a34076b8445983721dbd53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee145df1cc5f43f5821ab9a9a050982d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26136ec52cf7423db87282048bd2669b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a1aa832a2f044d4c9f2947dc78439b71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91ebd0e201d7493ab8860df0c7a465c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3e356c6ed0b7449ebfb5b64b145e3c2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94558b969a4644dd9fef2195b56634fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0063c60d7e934967941f4d3651317cf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_69d87a39ddaf4806be6bea061ce7bbbb",
              "IPY_MODEL_165307bc2edf4550b20285e529b597a8",
              "IPY_MODEL_b8552a647bf84d3a82282293a25e8e55"
            ],
            "layout": "IPY_MODEL_98ceeb996fc5476a898d7fbc5c68edcf"
          }
        },
        "69d87a39ddaf4806be6bea061ce7bbbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c32349616294ab19a5ad0ed758717d2",
            "placeholder": "​",
            "style": "IPY_MODEL_c965ec4732434d3c9b171e5311d0c40e",
            "value": "Downloading (…)ve/main/spiece.model: 100%"
          }
        },
        "165307bc2edf4550b20285e529b597a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5c334852d4c4e5e9b80dd8964831011",
            "max": 760289,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ad80a24b018b499586b8a140fd7f140f",
            "value": 760289
          }
        },
        "b8552a647bf84d3a82282293a25e8e55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e19b9981868442c592d429e8842c4b7f",
            "placeholder": "​",
            "style": "IPY_MODEL_3c2a48b943cb46fd9052e748f764891b",
            "value": " 760k/760k [00:01&lt;00:00, 685kB/s]"
          }
        },
        "98ceeb996fc5476a898d7fbc5c68edcf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c32349616294ab19a5ad0ed758717d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c965ec4732434d3c9b171e5311d0c40e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c5c334852d4c4e5e9b80dd8964831011": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad80a24b018b499586b8a140fd7f140f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e19b9981868442c592d429e8842c4b7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c2a48b943cb46fd9052e748f764891b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "486417de8405440ca7e1b8dcc5ae14e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_efd7b476286740789d793457aeaf2a0d",
              "IPY_MODEL_936d2be8d95f40b78e4230eb98bb1b8a",
              "IPY_MODEL_678ee064df2144bea251d9e9579eaa9a"
            ],
            "layout": "IPY_MODEL_f28579c6a63143cf93dc1be86592bbf3"
          }
        },
        "efd7b476286740789d793457aeaf2a0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0345a480fa6b4874a59949d5d37d80e7",
            "placeholder": "​",
            "style": "IPY_MODEL_d3b69c76a3474d93bfb684b69aab0c6a",
            "value": "Downloading (…)/main/tokenizer.json: 100%"
          }
        },
        "936d2be8d95f40b78e4230eb98bb1b8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5019f08a2b534b6990dd7a82a79278c1",
            "max": 1312669,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_03b44f76441a4ff48006f34830ac7401",
            "value": 1312669
          }
        },
        "678ee064df2144bea251d9e9579eaa9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_177ec6fbf79047dc8ae2acf8211ed41e",
            "placeholder": "​",
            "style": "IPY_MODEL_bd0165acaf4c40e5a49b900d194f187f",
            "value": " 1.31M/1.31M [00:01&lt;00:00, 1.19MB/s]"
          }
        },
        "f28579c6a63143cf93dc1be86592bbf3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0345a480fa6b4874a59949d5d37d80e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3b69c76a3474d93bfb684b69aab0c6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5019f08a2b534b6990dd7a82a79278c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03b44f76441a4ff48006f34830ac7401": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "177ec6fbf79047dc8ae2acf8211ed41e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd0165acaf4c40e5a49b900d194f187f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}