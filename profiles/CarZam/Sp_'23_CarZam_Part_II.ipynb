{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "IIvMmyor1zCa",
        "_mtMC8V8r43T",
        "oisq4kE8IMHi",
        "d5j3WfN0fpIT",
        "9PfHu-KZsQ9x",
        "_GzkE8ymuUj7",
        "XScfC4oALNFe",
        "fOEDZklBdwYu",
        "STAXYyAi6_58",
        "lzUnXtOsdffC",
        "2RJMxoSR7TJr",
        "AsUQYXSm_DkY"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Downloading the data\n",
        "\n",
        "Note: you should fill in `source_name` and `source_path` based on the correct name and URL for the larger dataset(s). `original_tool_image.zip` is done for you."
      ],
      "metadata": {
        "id": "IIvMmyor1zCa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "source_name = \"coupe_images.zip\"\n",
        "source_path = \"\""
      ],
      "metadata": {
        "id": "SklaW9LpKAke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X2MfjyJ2rHy2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59dcb880-b4d4-4284-f611-512556ae1c1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-01 15:38:45--  https://www.dropbox.com/s/l77u0mahlfyzi1r/original_tool_images.zip?dl=0\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.1.18, 2620:100:6016:18::a27d:112\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.1.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /s/raw/l77u0mahlfyzi1r/original_tool_images.zip [following]\n",
            "--2023-03-01 15:38:45--  https://www.dropbox.com/s/raw/l77u0mahlfyzi1r/original_tool_images.zip\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc7e3189eb2565101ec9e89a2185.dl.dropboxusercontent.com/cd/0/inline/B3bQgLixRq7lja6K3t9fV6C0Tig9XnSCKWVgqIAMVzyoP7g-ZMQ7fVlWWzU632CB_4QrUsfuFEPVOfSuLq5nDHRK2ei3c8dHA4Zr9AfrvtgNQEcnXGPFUnm4_3WA-4mEjhE_-wFeTf0tsAkh644RTGvBwj7ldZjfjh7r3yRfmemo2g/file# [following]\n",
            "--2023-03-01 15:38:46--  https://uc7e3189eb2565101ec9e89a2185.dl.dropboxusercontent.com/cd/0/inline/B3bQgLixRq7lja6K3t9fV6C0Tig9XnSCKWVgqIAMVzyoP7g-ZMQ7fVlWWzU632CB_4QrUsfuFEPVOfSuLq5nDHRK2ei3c8dHA4Zr9AfrvtgNQEcnXGPFUnm4_3WA-4mEjhE_-wFeTf0tsAkh644RTGvBwj7ldZjfjh7r3yRfmemo2g/file\n",
            "Resolving uc7e3189eb2565101ec9e89a2185.dl.dropboxusercontent.com (uc7e3189eb2565101ec9e89a2185.dl.dropboxusercontent.com)... 162.125.1.15, 2620:100:6016:15::a27d:10f\n",
            "Connecting to uc7e3189eb2565101ec9e89a2185.dl.dropboxusercontent.com (uc7e3189eb2565101ec9e89a2185.dl.dropboxusercontent.com)|162.125.1.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/B3YxwLfs_E3tvqgcGRyxFWq4Yy7hJYypC3G3QAvI09mojTdptjQo3KArMnOw2OM-kfbzvZnzrwV2XV7BalrlMCwtoeaZFHD-ahd0YQdygxh8ZBJayyZHmdB1qoMkGJWV5JersMcnnHyMn-AfkwnjgSvtvreWwSAZncc5eguthZp4tkOPIaSJ_dj9RFUn8f_6AoQF63tpNCvLjTkdNQmu60JzWexwS0-BW1t18mDLehIHMZ7qd2f-MYLukg4IB3Jusae49zG8CfcVWWMJ6Gka-MtsEQkgKvtx5fZarQYLjqs5vQQApKIDogrQ61lC4IuBBGx9rjrTRkQW4Nis9b6wR78jqLQeEM4lNhS7_7rJ2fGF1bNtKufcLYfrMddQ5U5x9CZGj-79RFJXoIkUjplAs6XBMH5EasMM748BUb6MfBWGjg/file [following]\n",
            "--2023-03-01 15:38:46--  https://uc7e3189eb2565101ec9e89a2185.dl.dropboxusercontent.com/cd/0/inline2/B3YxwLfs_E3tvqgcGRyxFWq4Yy7hJYypC3G3QAvI09mojTdptjQo3KArMnOw2OM-kfbzvZnzrwV2XV7BalrlMCwtoeaZFHD-ahd0YQdygxh8ZBJayyZHmdB1qoMkGJWV5JersMcnnHyMn-AfkwnjgSvtvreWwSAZncc5eguthZp4tkOPIaSJ_dj9RFUn8f_6AoQF63tpNCvLjTkdNQmu60JzWexwS0-BW1t18mDLehIHMZ7qd2f-MYLukg4IB3Jusae49zG8CfcVWWMJ6Gka-MtsEQkgKvtx5fZarQYLjqs5vQQApKIDogrQ61lC4IuBBGx9rjrTRkQW4Nis9b6wR78jqLQeEM4lNhS7_7rJ2fGF1bNtKufcLYfrMddQ5U5x9CZGj-79RFJXoIkUjplAs6XBMH5EasMM748BUb6MfBWGjg/file\n",
            "Reusing existing connection to uc7e3189eb2565101ec9e89a2185.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87282712 (83M) [application/zip]\n",
            "Saving to: ‘original_tool_image.zip’\n",
            "\n",
            "original_tool_image 100%[===================>]  83.24M  65.8MB/s    in 1.3s    \n",
            "\n",
            "2023-03-01 15:38:48 (65.8 MB/s) - ‘original_tool_image.zip’ saved [87282712/87282712]\n",
            "\n",
            "wget: missing URL\n",
            "Usage: wget [OPTION]... [URL]...\n",
            "\n",
            "Try `wget --help' for more options.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "if not os.path.exists('./original_tool_image.zip'):\n",
        "  ! wget -O original_tool_image.zip https://www.dropbox.com/s/l77u0mahlfyzi1r/original_tool_images.zip?dl=0\n",
        "if not os.path.exists(source_name):\n",
        "  ! wget -O $source_name $source_path"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0. Setup"
      ],
      "metadata": {
        "id": "_mtMC8V8r43T"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqJoyEW1f_a1"
      },
      "source": [
        "## Git Clone"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oisq4kE8IMHi"
      },
      "source": [
        "### From Source"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bJfycQTLVkEj"
      },
      "outputs": [],
      "source": [
        "! rm -rf -- GLAMOR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "goBMKUmagBIx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ab3a963-79b3-482e-9f0b-aac4be60c020"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'GLAMOR'...\n",
            "remote: Enumerating objects: 9540, done.\u001b[K\n",
            "remote: Counting objects: 100% (1443/1443), done.\u001b[K\n",
            "remote: Compressing objects: 100% (468/468), done.\u001b[K\n",
            "remote: Total 9540 (delta 893), reused 1373 (delta 828), pack-reused 8097\n",
            "Receiving objects: 100% (9540/9540), 2.53 MiB | 5.39 MiB/s, done.\n",
            "Resolving deltas: 100% (6284/6284), done.\n"
          ]
        }
      ],
      "source": [
        "! git clone -b master https://github.com/asuprem/GLAMOR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T80AC-kx4v4Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a10bd7ad-97ae-4a6d-8f4b-6fa02ed1c726"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Obtaining file:///content/GLAMOR\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.8/dist-packages (from ednaml==0.1.5) (1.0.2)\n",
            "Requirement already satisfied: torch>=1.10.* in /usr/local/lib/python3.8/dist-packages (from ednaml==0.1.5) (1.13.1+cu116)\n",
            "Collecting torchinfo>=1.6.5\n",
            "  Downloading torchinfo-1.7.2-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: torchvision>=0.11.* in /usr/local/lib/python3.8/dist-packages (from ednaml==0.1.5) (0.14.1+cu116)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.8/dist-packages (from ednaml==0.1.5) (8.4.0)\n",
            "Requirement already satisfied: tqdm>=4.63.* in /usr/local/lib/python3.8/dist-packages (from ednaml==0.1.5) (4.64.1)\n",
            "Collecting sentencepiece>=0.1.96\n",
            "  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sortedcontainers>=2.4.0 in /usr/local/lib/python3.8/dist-packages (from ednaml==0.1.5) (2.4.0)\n",
            "Requirement already satisfied: pyyaml>=6.0 in /usr/local/lib/python3.8/dist-packages (from ednaml==0.1.5) (6.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.2->ednaml==0.1.5) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.2->ednaml==0.1.5) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.2->ednaml==0.1.5) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.2->ednaml==0.1.5) (1.22.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.*->ednaml==0.1.5) (4.5.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision>=0.11.*->ednaml==0.1.5) (2.25.1)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision>=0.11.*->ednaml==0.1.5) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision>=0.11.*->ednaml==0.1.5) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision>=0.11.*->ednaml==0.1.5) (1.26.14)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision>=0.11.*->ednaml==0.1.5) (2.10)\n",
            "Installing collected packages: sentencepiece, torchinfo, ednaml\n",
            "  Running setup.py develop for ednaml\n",
            "Successfully installed ednaml-0.1.5 sentencepiece-0.1.97 torchinfo-1.7.2\n"
          ]
        }
      ],
      "source": [
        "!pip install -e GLAMOR/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5j3WfN0fpIT"
      },
      "source": [
        "###  From PyPi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7dkOhZi08dU"
      },
      "outputs": [],
      "source": [
        "#! python -V"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FwqgjiZ331ik"
      },
      "outputs": [],
      "source": [
        "#! pip3 install --pre ednaml==0.1.4"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ----------- Restart Notebook to Finish EdnaML Installation ----------------"
      ],
      "metadata": {
        "id": "84c7mTxBr7Sz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1 Building the Crawler"
      ],
      "metadata": {
        "id": "j6-WuaR3sX5m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "metadata": {
        "id": "rW5_Xxhvr7IT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import ednaml\n",
        "import glob, os\n",
        "#from ednaml.core import EdnaDeploy, EdnaML\n",
        "torch.__version__"
      ],
      "metadata": {
        "id": "zXxdpMEtr7GG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "8de83682-98e7-400e-dafa-a93be96e72a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.13.1+cu116'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 Crawler class definition"
      ],
      "metadata": {
        "id": "9PfHu-KZsQ9x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Here we define our custom model class\n",
        "from ednaml.crawlers import Crawler\n",
        "from zipfile import ZipFile # might be useful in unzipping!\n",
        "import glob\n",
        "\n",
        "class CarZamCrawler(Crawler):\n",
        "  def __init__(self, logger, file_name = \"original_tool_images.zip\", **kwargs): # Add your own arguments if needed!\n",
        "    self.classes = {}\n",
        "    self.metadata = {}\n",
        "    self.metadata[\"train\"] = {}\n",
        "    self.metadata[\"test\"] = {}\n",
        "    self.metadata[\"val\"] = {}\n",
        "    self.metadata[\"train\"][\"crawl\"] = []  # <------ THIS NEEDS TO BE POPULATED\n",
        "    self.metadata[\"test\"][\"crawl\"] = []   # <------ THIS NEEDS TO BE POPULATED\n",
        "    self.metadata[\"val\"][\"crawl\"] = []    # <------ THIS NEEDS TO BE POPULATED\n",
        "\n",
        "    # YOUR CODE HERE ------ POPULATE self.classes and self.metadata's empty lists ---\n",
        "    fdest = \"otool\"\n",
        "    if not os.path.exists(fdest):\n",
        "      with ZipFile(file_name, 'r') as zip: \n",
        "          # extract all files to another directory\n",
        "          zip.extractall(fdest)\n",
        "\n",
        "    fllist = glob.glob(os.path.join(fdest, \"original_tool_images/*.jpg\"))\n",
        "    tokeep = [\"Convertible\", \"Coupe\", \"Crossover\" \"Diesel\", \"Hybrid\", \"Sedan\", \"SUV\"]\n",
        "\n",
        "    tuple_prelim = [self.getinittuple(item) for item in fllist]\n",
        "    tuple_filtered = [item for item in tuple_prelim if item[0][0] in tokeep]  # keeps our limited set of makes\n",
        "    tuple_expanded = [self.expand(item) for item in tuple_filtered]\n",
        "\n",
        "    import random\n",
        "    random.seed(3456)\n",
        "    random.shuffle(tuple_expanded)\n",
        "\n",
        "    splits = 0.8\n",
        "    train_sets = int(len(tuple_expanded)*0.8)\n",
        "    val_sets = int(len(tuple_expanded)*0.1)\n",
        "\n",
        "    \n",
        "\n",
        "    # structure:  (path, type, color, year, make)\n",
        "    # idx           0     1     2     3     4\n",
        "    types = list(set([item[1] for item in tuple_expanded]))\n",
        "    colors = list(set([item[2] for item in tuple_expanded]))\n",
        "    years = list(set([item[3] for item in tuple_expanded]))\n",
        "    makes = list(set([item[4] for item in tuple_expanded]))\n",
        "\n",
        "    self.classes[\"vtype\"] = len(types)\n",
        "    self.classes[\"color\"] = len(colors)\n",
        "    self.classes[\"year\"] = len(years)\n",
        "    self.classes[\"make\"] = len(makes)\n",
        "\n",
        "    self.type_lookup = {item:idx for idx,item in enumerate(types)}\n",
        "    self.color_lookup = {item:idx for idx,item in enumerate(colors)}\n",
        "    self.year_lookup = {item:idx for idx,item in enumerate(years)}\n",
        "    self.make_lookup = {item:idx for idx,item in enumerate(makes)}\n",
        "\n",
        "    tuple_expanded = [(item[0], self.type_lookup[item[1]], self.color_lookup[item[2]], self.year_lookup[item[3]], self.make_lookup[item[4]]) for item in tuple_expanded]\n",
        "\n",
        "    self.metadata[\"train\"][\"crawl\"] = tuple_expanded[:train_sets]\n",
        "    self.metadata[\"val\"][\"crawl\"] = tuple_expanded[train_sets:val_sets]\n",
        "    self.metadata[\"test\"][\"crawl\"] = tuple_expanded[train_sets+val_sets:]\n",
        "\n",
        "    # structure:  (path, vtype, color, year, make)\n",
        "    # idx           0     1     2     3     4\n",
        "    # -------------------------------------------------------------------------------\n",
        "\n",
        "    self.metadata[\"train\"][\"classes\"] = self.classes\n",
        "    self.metadata[\"test\"][\"classes\"] = self.classes\n",
        "    self.metadata[\"val\"][\"classes\"] = self.classes\n",
        "\n",
        "  def getinittuple(self, item):\n",
        "    return (os.path.splitext(os.path.basename(item))[0].split(\" \"), item)\n",
        "\n",
        "  def expand(self, item): # item is a tuple: ([\"make\",\"color\", etc...], \"path\")\n",
        "    return tuple([item[1]]+item[0])\n",
        "    \n"
      ],
      "metadata": {
        "id": "-2z_FeuUsSr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 Testing the Crawler"
      ],
      "metadata": {
        "id": "_GzkE8ymuUj7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kwargs = {\n",
        "    \"logger\" : None,\n",
        "    \"file_name\" : \"original_tool_image.zip\",\n",
        "    # add any other kwargs here...\n",
        "}"
      ],
      "metadata": {
        "id": "x0GIxddZuarz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "crawler = CarZamCrawler(**kwargs)"
      ],
      "metadata": {
        "id": "BIGL8tGzuWs7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "crawler.classes # You should get the classes here"
      ],
      "metadata": {
        "id": "bf3QLBgWuouh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d7e9e01-fdc0-4fdd-d8d7-aa8e7afbabbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'vtype': 5, 'color': 13, 'year': 13, 'make': 34}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(crawler.metadata[\"train\"][\"crawl\"][:5])  # You should get the list of tuples here"
      ],
      "metadata": {
        "id": "Aud7dfjGunhE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d306a2f-a7f4-41f1-84b2-c598368c28d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('otool/original_tool_images/SUV Black 2014 Ford Expedition EL.jpg', 1, 1, 10, 7), ('otool/original_tool_images/Coupe White 2015 Chevrolet Camaro.jpg', 2, 8, 12, 28), ('otool/original_tool_images/SUV Gray 2018 Toyota 4Runner.jpg', 1, 11, 9, 10), ('otool/original_tool_images/SUV White 2014 Honda CR-V.jpg', 1, 8, 10, 6), ('otool/original_tool_images/Sedan Black 2019 Chevrolet Cruze.jpg', 4, 1, 3, 28)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2 Statistics\n",
        "\n",
        "Here, you can add your code to explore the data and obtain whatever plots you need. If you already have the code somewhere else, then you can keep it as is, and leave this blank. If you want everything in one place, feel free to use this section!"
      ],
      "metadata": {
        "id": "l6_TufwByRmh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "dO9dJ0R-1Io0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write code to collect info on # makes, models, year, type"
      ],
      "metadata": {
        "id": "7yRF6u3MySi2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3 Building a simple, single classification model for `original_tool_images.zip`\n",
        "\n",
        "Here, we will built a simple model to classify a subset of original_tool_images.zip. Then we will expand to multiple labels. Finally, we will tackle the larger-scale datasets problem."
      ],
      "metadata": {
        "id": "fqAy4iLxK0Z8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 Single classification (Vehicle Type)\n",
        "\n",
        "We will try with the vehicle type classifier first. Our architecture looks like:\n",
        "\n",
        "\n",
        "[<img src=\"https://i.redd.it/cvjvsdlq4yx91.png\" width=\"550\"/>]"
      ],
      "metadata": {
        "id": "XScfC4oALNFe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_name = \"vtype\"  # Make sure to change this to whatever name you used for type in your `original_tool_images` crawler\n",
        "class_idx = 1         # Make sure to change this to whetever index `type` is in your Crawler's tuple!\n",
        "path_idx = 0          # Change this to whichever index in tuple has path\n",
        "crawler_args = {\"file_name\" : \"original_tool_image.zip\"}"
      ],
      "metadata": {
        "id": "lqoXW_VoK0LC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "metadata": {
        "id": "f3KHo9SZQ07r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b54ac6e0-21d6-4bce-aff5-25400a3be5bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ednaml.core import EdnaML\n",
        "from ednaml.generators import ClassificationGenerator\n",
        "\n",
        "eml = EdnaML(config = \"./GLAMOR/profiles/CarZam/base_config.yml\", config_inject=[\n",
        "    (\"SAVE.MODEL_QUALIFIER\", class_name)\n",
        "])\n",
        "\n",
        "eml.cfg.EXECUTION.DATAREADER.CRAWLER_ARGS = crawler_args\n",
        "eml.cfg.EXECUTION.DATAREADER.DATASET_ARGS[\"pathidx\"] = path_idx\n",
        "eml.cfg.EXECUTION.DATAREADER.DATASET_ARGS[\"annotationidx\"] = class_idx\n",
        "eml.cfg.EXECUTION.DATAREADER.DATASET_ARGS[\"classificationclass\"] = class_name\n",
        "\n",
        "eml.addGeneratorClass(ClassificationGenerator)\n",
        "eml.addCrawlerClass(CarZamCrawler)"
      ],
      "metadata": {
        "id": "RYAiLHiGQ4Sj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9386179-6fb9-421b-d7df-4d5fa64933fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Injected key-value pair:  SAVE.MODEL_QUALIFIER, vtype\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eml.apply()"
      ],
      "metadata": {
        "id": "RBYrjfZNSjdo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "666cabe8-71b9-4b36-f107-0c31871487b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "15:39:08 ****************************************\n",
            "15:39:08 \n",
            "15:39:08 \n",
            "15:39:08 Using the following configuration:\n",
            "15:39:08 DEPLOYMENT:\n",
            "  DATAREADER:\n",
            "    CRAWLER_ARGS: {}\n",
            "    DATAREADER: DataReader\n",
            "    DATASET_ARGS: {}\n",
            "    GENERATOR: null\n",
            "    GENERATOR_ARGS: {}\n",
            "  DEPLOY: BaseDeploy\n",
            "  DEPLOYMENT_ARGS: {}\n",
            "  EPOCHS: 1\n",
            "  OUTPUT_ARGS: {}\n",
            "  PLUGIN:\n",
            "    HOOKS: always\n",
            "    RESET: false\n",
            "EXECUTION:\n",
            "  DATAREADER:\n",
            "    CRAWLER_ARGS:\n",
            "      file_name: original_tool_image.zip\n",
            "    DATAREADER: DataReader\n",
            "    DATASET_ARGS:\n",
            "      annotationidx: 1\n",
            "      classificationclass: vtype\n",
            "      pathidx: 0\n",
            "    GENERATOR: null\n",
            "    GENERATOR_ARGS: {}\n",
            "  EPOCHS: 10\n",
            "  FP16: false\n",
            "  MODEL_SERVING: Unused\n",
            "  OPTIMIZER_BUILDER: ClassificationOptimizer\n",
            "  PLUGIN:\n",
            "    HOOKS: always\n",
            "    RESET: false\n",
            "  SKIPEVAL: false\n",
            "  TEST_FREQUENCY: 1\n",
            "  TRAINER: ClassificationTrainer\n",
            "  TRAINER_ARGS:\n",
            "    accumulation_steps: 4\n",
            "LOGGING:\n",
            "  INPUT_SIZE: null\n",
            "  STEP_VERBOSE: 100\n",
            "LOSS:\n",
            "- KWARGS:\n",
            "  - {}\n",
            "  LABEL: ''\n",
            "  LAMBDAS:\n",
            "  - 1.0\n",
            "  LOSSES:\n",
            "  - SoftmaxLogitsLoss\n",
            "  NAME: out1\n",
            "LOSS_OPTIMIZER:\n",
            "- BASE_LR: 0.001\n",
            "  LR_BIAS_FACTOR: 1.0\n",
            "  OPTIMIZER: Adam\n",
            "  OPTIMIZER_KWARGS: {}\n",
            "  OPTIMIZER_NAME: opt-1\n",
            "  WEIGHT_BIAS_FACTOR: 0.0005\n",
            "  WEIGHT_DECAY: 0.0005\n",
            "LOSS_SCHEDULER:\n",
            "- LR_KWARGS:\n",
            "    step_size: 20\n",
            "  LR_SCHEDULER: StepLR\n",
            "  SCHEDULER_NAME: opt-1\n",
            "MODEL:\n",
            "  BUILDER: classification_model_builder\n",
            "  MODEL_ARCH: ClassificationResnet\n",
            "  MODEL_BASE: resnet18\n",
            "  MODEL_KWARGS: {}\n",
            "  MODEL_NORMALIZATION: bn\n",
            "  PARAMETER_GROUPS:\n",
            "  - opt-1\n",
            "MODEL_PLUGIN: {}\n",
            "OPTIMIZER:\n",
            "- BASE_LR: 1.0e-05\n",
            "  LR_BIAS_FACTOR: 1.0\n",
            "  OPTIMIZER: Adam\n",
            "  OPTIMIZER_KWARGS: {}\n",
            "  OPTIMIZER_NAME: opt-1\n",
            "  WEIGHT_BIAS_FACTOR: 0.0005\n",
            "  WEIGHT_DECAY: 0.0005\n",
            "SAVE:\n",
            "  CHECKPOINT_DIRECTORY: checkpoint\n",
            "  DRIVE_BACKUP: false\n",
            "  LOG_BACKUP: false\n",
            "  MODEL_BACKBONE: singleclass\n",
            "  MODEL_CORE_NAME: origtoolimgs\n",
            "  MODEL_QUALIFIER: vtype\n",
            "  MODEL_VERSION: 1\n",
            "  SAVE_FREQUENCY: 1\n",
            "  STEP_SAVE_FREQUENCY: 0\n",
            "SCHEDULER:\n",
            "- LR_KWARGS:\n",
            "    gamma: 0.1\n",
            "    step_size: 20\n",
            "  LR_SCHEDULER: StepLR\n",
            "  SCHEDULER_NAME: opt-1\n",
            "STORAGE:\n",
            "  STORAGE_ARGS: {}\n",
            "  TYPE: BaseStorage\n",
            "  URL: ./\n",
            "TEST_TRANSFORMATION:\n",
            "  ARGS:\n",
            "    channels: 3\n",
            "    i_shape:\n",
            "    - 200\n",
            "    - 200\n",
            "    normalization_mean: 0.5\n",
            "    normalization_scale: 0.5\n",
            "    normalization_std: 0.5\n",
            "  BATCH_SIZE: 32\n",
            "  WORKERS: 2\n",
            "TRAIN_TRANSFORMATION:\n",
            "  ARGS:\n",
            "    channels: 3\n",
            "    h_flip: 0.5\n",
            "    i_shape:\n",
            "    - 200\n",
            "    - 200\n",
            "    normalization_mean: 0.5\n",
            "    normalization_scale: 0.5\n",
            "    normalization_std: 0.5\n",
            "    random_erase: true\n",
            "    random_erase_value: 0.3\n",
            "    t_crop: true\n",
            "  BATCH_SIZE: 32\n",
            "  WORKERS: 2\n",
            "extensions:\n",
            "- EXECUTION\n",
            "- SAVE\n",
            "- STORAGE\n",
            "- TRANSFORMATION\n",
            "- MODEL\n",
            "- LOSS\n",
            "- OPTIMIZER\n",
            "- SCHEDULER\n",
            "- LOSS_OPTIMIZER\n",
            "- LOSS_SCHEDULER\n",
            "- LOGGING\n",
            "- DEPLOYMENT\n",
            "- MODEL_PLUGIN\n",
            "\n",
            "15:39:08 \n",
            "15:39:08 \n",
            "15:39:08 ****************************************\n",
            "15:39:08 Model weights file resnet18-5c106cde.pth does not exist. Downloading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "46827520/46827520 bytes [████████████████████████████████████████████████████████████████████████████████████████████████████]\n",
            "Download of resnet18-5c106cde.pth to https://download.pytorch.org/models/resnet18-5c106cde.pth completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "15:39:08 No previous stop detected. Will start from epoch 0\n",
            "15:39:08 Loaded BaseStorage from ednaml.storage to build Storage\n",
            "15:39:08 Reading data with DataReader DataReader\n",
            "15:39:08 Default CRAWLER is <class 'ednaml.crawlers.Crawler'>\n",
            "15:39:08 Default DATASET is <class 'torch.utils.data.dataset.Dataset'>\n",
            "15:39:08 Default GENERATOR is <class 'ednaml.generators.ImageGenerator.ImageGenerator'>\n",
            "15:39:08 Updating GENERATOR to queued class ClassificationGenerator\n",
            "15:39:08 Updating CRAWLER to CarZamCrawler\n",
            "15:39:09 Generated training data generator with 648 training data points\n",
            "15:39:09 Running classification model with classes: {'vtype': {'classes': 5}}\n",
            "15:39:09 Generated test data/query generator\n",
            "15:39:09 Loaded classification_model_builder from ednaml.models to build model\n",
            "15:39:09 Finished instantiating model with ClassificationResnet architecture\n",
            "15:39:09 Adding plugins after constructing model\n",
            "15:39:09 No saved model weights provided.\n",
            "15:39:14 Model Summary retured the following error:\n",
            "15:39:14 Traceback (most recent call last):\n",
            "  File \"/content/GLAMOR/src/ednaml/core/EdnaML.py\", line 888, in getModelSummary\n",
            "    self.cfg.TRAIN_TRANSFORMATION.INPUT_SIZE,\n",
            "AttributeError: 'TransformationConfig' object has no attribute 'INPUT_SIZE'\n",
            "\n",
            "15:39:14 Loaded ClassificationOptimizer from ednaml.optimizer to build Optimizer model\n",
            "15:39:14 Built optimizer\n",
            "15:39:14 Built scheduler\n",
            "15:39:14 Added SoftmaxLogitsLoss with lambda = 1.0 and loss arguments {}\n",
            "15:39:14 Built loss function\n",
            "15:39:14 Built loss optimizer\n",
            "15:39:14 Built loss scheduler\n",
            "15:39:14 Loaded BaseStorage from ednaml.storage to build Storage\n",
            "15:39:14 Loaded ClassificationTrainer from ednaml.trainer to build Trainer\n",
            "15:39:14 Saving model metadata\n",
            "15:39:14 Backing up metadata\n",
            "15:39:14 Finished metadata backup\n",
            "15:39:14 1 GPUs available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eml.train()"
      ],
      "metadata": {
        "id": "Tq72FT1WSkRN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6244102c-8fc3-40cc-8c37-b33d4847eeb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "15:39:14 Starting training\n",
            "15:39:14 Logging to:\torigtoolimgs-v1-singleclass-vtype-logger.log\n",
            "15:39:14 Models will be saved to local directory:\torigtoolimgs-v1-singleclass-vtype\n",
            "15:39:14 Models will be saved with base name:\torigtoolimgs-v1_epoch[].pth\n",
            "15:39:14 Optimizers will be saved with base name:\torigtoolimgs-v1_epoch[]_optimizer.pth\n",
            "15:39:14 Schedulers will be saved with base name:\torigtoolimgs-v1_epoch[]_scheduler.pth\n",
            "15:39:14 Performing initial evaluation...\n",
            "15:39:21 Obtained features, validation in progress\n",
            "15:39:21 Accuracy: 22.222%\n",
            "15:39:21 Micro F-score: 0.222\n",
            "15:39:21 Weighted F-score: 0.086\n",
            "15:39:21 Starting training from 0\n",
            "15:39:22 Parameter Group `opt-1`: Starting epoch 0 with 20 steps and learning rate 1.00000E-05\n",
            "15:39:28 ********** Completed epoch 0 **********\n",
            "15:39:28 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "15:39:28 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "15:39:29 Parameter Group `opt-1`: Starting epoch 1 with 20 steps and learning rate 1.00000E-05\n",
            "15:39:30 Evaluating model at test-frequency\n",
            "15:39:31 Obtained features, validation in progress\n",
            "15:39:31 Accuracy: 39.506%\n",
            "15:39:31 Micro F-score: 0.395\n",
            "15:39:31 Weighted F-score: 0.418\n",
            "15:39:31 Saving model at save-frequency, at epoch 0, step 0\n",
            "15:39:31 Saving model, optimizer, and scheduler.\n",
            "15:39:36 ********** Completed epoch 1 **********\n",
            "15:39:36 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "15:39:36 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "15:39:37 Parameter Group `opt-1`: Starting epoch 2 with 20 steps and learning rate 1.00000E-05\n",
            "15:39:37 Evaluating model at test-frequency\n",
            "15:39:39 Obtained features, validation in progress\n",
            "15:39:39 Accuracy: 58.025%\n",
            "15:39:39 Micro F-score: 0.580\n",
            "15:39:39 Weighted F-score: 0.569\n",
            "15:39:39 Saving model at save-frequency, at epoch 1, step 0\n",
            "15:39:39 Saving model, optimizer, and scheduler.\n",
            "15:39:44 ********** Completed epoch 2 **********\n",
            "15:39:44 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "15:39:44 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "15:39:44 Parameter Group `opt-1`: Starting epoch 3 with 20 steps and learning rate 1.00000E-05\n",
            "15:39:44 Evaluating model at test-frequency\n",
            "15:39:46 Obtained features, validation in progress\n",
            "15:39:46 Accuracy: 62.963%\n",
            "15:39:46 Micro F-score: 0.630\n",
            "15:39:46 Weighted F-score: 0.615\n",
            "15:39:46 Saving model at save-frequency, at epoch 2, step 0\n",
            "15:39:46 Saving model, optimizer, and scheduler.\n",
            "15:39:52 ********** Completed epoch 3 **********\n",
            "15:39:52 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "15:39:52 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "15:39:53 Parameter Group `opt-1`: Starting epoch 4 with 20 steps and learning rate 1.00000E-05\n",
            "15:39:53 Evaluating model at test-frequency\n",
            "15:39:55 Obtained features, validation in progress\n",
            "15:39:55 Accuracy: 64.198%\n",
            "15:39:55 Micro F-score: 0.642\n",
            "15:39:55 Weighted F-score: 0.634\n",
            "15:39:55 Saving model at save-frequency, at epoch 3, step 0\n",
            "15:39:55 Saving model, optimizer, and scheduler.\n",
            "15:39:59 ********** Completed epoch 4 **********\n",
            "15:39:59 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "15:39:59 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "15:40:00 Parameter Group `opt-1`: Starting epoch 5 with 20 steps and learning rate 1.00000E-05\n",
            "15:40:00 Evaluating model at test-frequency\n",
            "15:40:03 Obtained features, validation in progress\n",
            "15:40:03 Accuracy: 65.432%\n",
            "15:40:03 Micro F-score: 0.654\n",
            "15:40:03 Weighted F-score: 0.640\n",
            "15:40:03 Saving model at save-frequency, at epoch 4, step 0\n",
            "15:40:03 Saving model, optimizer, and scheduler.\n",
            "15:40:08 ********** Completed epoch 5 **********\n",
            "15:40:08 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "15:40:08 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "15:40:08 Parameter Group `opt-1`: Starting epoch 6 with 20 steps and learning rate 1.00000E-05\n",
            "15:40:08 Evaluating model at test-frequency\n",
            "15:40:10 Obtained features, validation in progress\n",
            "15:40:10 Accuracy: 69.136%\n",
            "15:40:10 Micro F-score: 0.691\n",
            "15:40:10 Weighted F-score: 0.672\n",
            "15:40:10 Saving model at save-frequency, at epoch 5, step 0\n",
            "15:40:10 Saving model, optimizer, and scheduler.\n",
            "15:40:15 ********** Completed epoch 6 **********\n",
            "15:40:15 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "15:40:15 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "15:40:16 Parameter Group `opt-1`: Starting epoch 7 with 20 steps and learning rate 1.00000E-05\n",
            "15:40:16 Evaluating model at test-frequency\n",
            "15:40:18 Obtained features, validation in progress\n",
            "15:40:18 Accuracy: 67.901%\n",
            "15:40:18 Micro F-score: 0.679\n",
            "15:40:18 Weighted F-score: 0.658\n",
            "15:40:18 Saving model at save-frequency, at epoch 6, step 0\n",
            "15:40:18 Saving model, optimizer, and scheduler.\n",
            "15:40:23 ********** Completed epoch 7 **********\n",
            "15:40:23 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "15:40:23 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "15:40:24 Parameter Group `opt-1`: Starting epoch 8 with 20 steps and learning rate 1.00000E-05\n",
            "15:40:24 Evaluating model at test-frequency\n",
            "15:40:26 Obtained features, validation in progress\n",
            "15:40:26 Accuracy: 67.901%\n",
            "15:40:26 Micro F-score: 0.679\n",
            "15:40:26 Weighted F-score: 0.652\n",
            "15:40:26 Saving model at save-frequency, at epoch 7, step 0\n",
            "15:40:26 Saving model, optimizer, and scheduler.\n",
            "15:40:31 ********** Completed epoch 8 **********\n",
            "15:40:31 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "15:40:31 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "15:40:32 Parameter Group `opt-1`: Starting epoch 9 with 20 steps and learning rate 1.00000E-05\n",
            "15:40:32 Evaluating model at test-frequency\n",
            "15:40:34 Obtained features, validation in progress\n",
            "15:40:34 Accuracy: 69.136%\n",
            "15:40:34 Micro F-score: 0.691\n",
            "15:40:34 Weighted F-score: 0.663\n",
            "15:40:34 Saving model at save-frequency, at epoch 8, step 0\n",
            "15:40:34 Saving model, optimizer, and scheduler.\n",
            "15:40:38 ********** Completed epoch 9 **********\n",
            "15:40:38 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "15:40:38 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "15:40:39 Parameter Group `opt-1`: Starting epoch 10 with 20 steps and learning rate 1.00000E-05\n",
            "15:40:39 Evaluating model at test-frequency\n",
            "15:40:41 Obtained features, validation in progress\n",
            "15:40:41 Accuracy: 67.901%\n",
            "15:40:41 Micro F-score: 0.679\n",
            "15:40:41 Weighted F-score: 0.641\n",
            "15:40:41 Saving model at save-frequency, at epoch 9, step 0\n",
            "15:40:41 Saving model, optimizer, and scheduler.\n",
            "15:40:47 ********** Completed epoch 10 **********\n",
            "15:40:47 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "15:40:47 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "15:40:47 Final: Evaluating model at test-frequency\n",
            "15:40:48 Obtained features, validation in progress\n",
            "15:40:48 Accuracy: 67.901%\n",
            "15:40:48 Micro F-score: 0.679\n",
            "15:40:48 Weighted F-score: 0.625\n",
            "15:40:48 Final: Saving model at save-frequency\n",
            "15:40:48 Saving model, optimizer, and scheduler.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resp = eml.eval()"
      ],
      "metadata": {
        "id": "mn8MWacMdFAj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77a3d723-c0e4-4362-9085-4b110a6e9e0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "15:40:49 Obtained features, validation in progress\n",
            "15:40:49 Accuracy: 67.901%\n",
            "15:40:49 Micro F-score: 0.679\n",
            "15:40:49 Weighted F-score: 0.625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 Single classification (Vehicle Color)\n",
        "\n",
        "Next, let's do vehicle color. Architecture remains the same, but we now focus on color features."
      ],
      "metadata": {
        "id": "fOEDZklBdwYu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_name = \"color\"   # Make sure to change this to whatever name you used for make in your `original_tool_images` crawler\n",
        "class_idx = 2         # Make sure to change this to whetever index `color` is in your Crawler's tuple!\n",
        "path_idx = 0          # Change this to whichever index in tuple has path\n",
        "crawler_args = {\"file_name\" : \"original_tool_image.zip\"}"
      ],
      "metadata": {
        "id": "F4jU3B9PdwYz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "metadata": {
        "id": "UAl5Q_f2dwYz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e052d76d-3786-4945-d4b4-0fa65aa7f4b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ednaml.core import EdnaML\n",
        "from ednaml.generators import ClassificationGenerator\n",
        "\n",
        "eml = EdnaML(config = \"./GLAMOR/profiles/CarZam/base_config.yml\", config_inject=[\n",
        "    (\"SAVE.MODEL_QUALIFIER\", class_name)\n",
        "])\n",
        "\n",
        "eml.cfg.EXECUTION.DATAREADER.CRAWLER_ARGS = crawler_args\n",
        "eml.cfg.EXECUTION.DATAREADER.DATASET_ARGS[\"pathidx\"] = path_idx\n",
        "eml.cfg.EXECUTION.DATAREADER.DATASET_ARGS[\"annotationidx\"] = class_idx\n",
        "eml.cfg.EXECUTION.DATAREADER.DATASET_ARGS[\"classificationclass\"] = class_name\n",
        "\n",
        "eml.addGeneratorClass(ClassificationGenerator)\n",
        "eml.addCrawlerClass(CarZamCrawler)"
      ],
      "metadata": {
        "id": "MbNKQ0YXdwYz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a94323ab-a6c5-4b45-d670-defc40d0734d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Injected key-value pair:  SAVE.MODEL_QUALIFIER, color\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eml.apply()"
      ],
      "metadata": {
        "id": "-29Pv8stdwYz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c1038a6-5e2b-456f-8d68-d2655d75b01c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "15:51:45 ****************************************\n",
            "15:51:45 \n",
            "15:51:45 \n",
            "15:51:45 Using the following configuration:\n",
            "15:51:45 DEPLOYMENT:\n",
            "  DATAREADER:\n",
            "    CRAWLER_ARGS: {}\n",
            "    DATAREADER: DataReader\n",
            "    DATASET_ARGS: {}\n",
            "    GENERATOR: null\n",
            "    GENERATOR_ARGS: {}\n",
            "  DEPLOY: BaseDeploy\n",
            "  DEPLOYMENT_ARGS: {}\n",
            "  EPOCHS: 1\n",
            "  OUTPUT_ARGS: {}\n",
            "  PLUGIN:\n",
            "    HOOKS: always\n",
            "    RESET: false\n",
            "EXECUTION:\n",
            "  DATAREADER:\n",
            "    CRAWLER_ARGS:\n",
            "      file_name: original_tool_image.zip\n",
            "    DATAREADER: DataReader\n",
            "    DATASET_ARGS:\n",
            "      annotationidx: 2\n",
            "      classificationclass: color\n",
            "      pathidx: 0\n",
            "    GENERATOR: null\n",
            "    GENERATOR_ARGS: {}\n",
            "  EPOCHS: 10\n",
            "  FP16: false\n",
            "  MODEL_SERVING: Unused\n",
            "  OPTIMIZER_BUILDER: ClassificationOptimizer\n",
            "  PLUGIN:\n",
            "    HOOKS: always\n",
            "    RESET: false\n",
            "  SKIPEVAL: false\n",
            "  TEST_FREQUENCY: 1\n",
            "  TRAINER: ClassificationTrainer\n",
            "  TRAINER_ARGS:\n",
            "    accumulation_steps: 4\n",
            "LOGGING:\n",
            "  INPUT_SIZE: null\n",
            "  STEP_VERBOSE: 100\n",
            "LOSS:\n",
            "- KWARGS:\n",
            "  - {}\n",
            "  LABEL: ''\n",
            "  LAMBDAS:\n",
            "  - 1.0\n",
            "  LOSSES:\n",
            "  - SoftmaxLogitsLoss\n",
            "  NAME: out1\n",
            "LOSS_OPTIMIZER:\n",
            "- BASE_LR: 0.001\n",
            "  LR_BIAS_FACTOR: 1.0\n",
            "  OPTIMIZER: Adam\n",
            "  OPTIMIZER_KWARGS: {}\n",
            "  OPTIMIZER_NAME: opt-1\n",
            "  WEIGHT_BIAS_FACTOR: 0.0005\n",
            "  WEIGHT_DECAY: 0.0005\n",
            "LOSS_SCHEDULER:\n",
            "- LR_KWARGS:\n",
            "    step_size: 20\n",
            "  LR_SCHEDULER: StepLR\n",
            "  SCHEDULER_NAME: opt-1\n",
            "MODEL:\n",
            "  BUILDER: classification_model_builder\n",
            "  MODEL_ARCH: ClassificationResnet\n",
            "  MODEL_BASE: resnet18\n",
            "  MODEL_KWARGS: {}\n",
            "  MODEL_NORMALIZATION: bn\n",
            "  PARAMETER_GROUPS:\n",
            "  - opt-1\n",
            "MODEL_PLUGIN: {}\n",
            "OPTIMIZER:\n",
            "- BASE_LR: 1.0e-05\n",
            "  LR_BIAS_FACTOR: 1.0\n",
            "  OPTIMIZER: Adam\n",
            "  OPTIMIZER_KWARGS: {}\n",
            "  OPTIMIZER_NAME: opt-1\n",
            "  WEIGHT_BIAS_FACTOR: 0.0005\n",
            "  WEIGHT_DECAY: 0.0005\n",
            "SAVE:\n",
            "  CHECKPOINT_DIRECTORY: checkpoint\n",
            "  DRIVE_BACKUP: false\n",
            "  LOG_BACKUP: false\n",
            "  MODEL_BACKBONE: singleclass\n",
            "  MODEL_CORE_NAME: origtoolimgs\n",
            "  MODEL_QUALIFIER: color\n",
            "  MODEL_VERSION: 1\n",
            "  SAVE_FREQUENCY: 1\n",
            "  STEP_SAVE_FREQUENCY: 0\n",
            "SCHEDULER:\n",
            "- LR_KWARGS:\n",
            "    gamma: 0.1\n",
            "    step_size: 20\n",
            "  LR_SCHEDULER: StepLR\n",
            "  SCHEDULER_NAME: opt-1\n",
            "STORAGE:\n",
            "  STORAGE_ARGS: {}\n",
            "  TYPE: BaseStorage\n",
            "  URL: ./\n",
            "TEST_TRANSFORMATION:\n",
            "  ARGS:\n",
            "    channels: 3\n",
            "    i_shape:\n",
            "    - 200\n",
            "    - 200\n",
            "    normalization_mean: 0.5\n",
            "    normalization_scale: 0.5\n",
            "    normalization_std: 0.5\n",
            "  BATCH_SIZE: 32\n",
            "  WORKERS: 2\n",
            "TRAIN_TRANSFORMATION:\n",
            "  ARGS:\n",
            "    channels: 3\n",
            "    h_flip: 0.5\n",
            "    i_shape:\n",
            "    - 200\n",
            "    - 200\n",
            "    normalization_mean: 0.5\n",
            "    normalization_scale: 0.5\n",
            "    normalization_std: 0.5\n",
            "    random_erase: true\n",
            "    random_erase_value: 0.3\n",
            "    t_crop: true\n",
            "  BATCH_SIZE: 32\n",
            "  WORKERS: 2\n",
            "extensions:\n",
            "- EXECUTION\n",
            "- SAVE\n",
            "- STORAGE\n",
            "- TRANSFORMATION\n",
            "- MODEL\n",
            "- LOSS\n",
            "- OPTIMIZER\n",
            "- SCHEDULER\n",
            "- LOSS_OPTIMIZER\n",
            "- LOSS_SCHEDULER\n",
            "- LOGGING\n",
            "- DEPLOYMENT\n",
            "- MODEL_PLUGIN\n",
            "\n",
            "15:51:45 \n",
            "15:51:45 \n",
            "15:51:45 ****************************************\n",
            "15:51:45 No previous stop detected. Will start from epoch 0\n",
            "15:51:45 Loaded BaseStorage from ednaml.storage to build Storage\n",
            "15:51:45 Reading data with DataReader DataReader\n",
            "15:51:45 Default CRAWLER is <class 'ednaml.crawlers.Crawler'>\n",
            "15:51:45 Default DATASET is <class 'torch.utils.data.dataset.Dataset'>\n",
            "15:51:45 Default GENERATOR is <class 'ednaml.generators.ImageGenerator.ImageGenerator'>\n",
            "15:51:45 Updating GENERATOR to queued class ClassificationGenerator\n",
            "15:51:45 Updating CRAWLER to CarZamCrawler\n",
            "15:51:45 Generated training data generator with 648 training data points\n",
            "15:51:45 Running classification model with classes: {'color': {'classes': 13}}\n",
            "15:51:45 Generated test data/query generator\n",
            "15:51:45 Loaded classification_model_builder from ednaml.models to build model\n",
            "15:51:46 Finished instantiating model with ClassificationResnet architecture\n",
            "15:51:46 Adding plugins after constructing model\n",
            "15:51:46 No saved model weights provided.\n",
            "15:51:46 Model Summary retured the following error:\n",
            "15:51:46 Traceback (most recent call last):\n",
            "  File \"/content/GLAMOR/src/ednaml/core/EdnaML.py\", line 888, in getModelSummary\n",
            "    self.cfg.TRAIN_TRANSFORMATION.INPUT_SIZE,\n",
            "AttributeError: 'TransformationConfig' object has no attribute 'INPUT_SIZE'\n",
            "\n",
            "15:51:46 Loaded ClassificationOptimizer from ednaml.optimizer to build Optimizer model\n",
            "15:51:46 Built optimizer\n",
            "15:51:46 Built scheduler\n",
            "15:51:46 Added SoftmaxLogitsLoss with lambda = 1.0 and loss arguments {}\n",
            "15:51:46 Built loss function\n",
            "15:51:46 Built loss optimizer\n",
            "15:51:46 Built loss scheduler\n",
            "15:51:46 Loaded BaseStorage from ednaml.storage to build Storage\n",
            "15:51:46 Loaded ClassificationTrainer from ednaml.trainer to build Trainer\n",
            "15:51:46 Saving model metadata\n",
            "15:51:46 Backing up metadata\n",
            "15:51:46 Finished metadata backup\n",
            "15:51:46 1 GPUs available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eml.train()"
      ],
      "metadata": {
        "id": "Mc44W4fndwY0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31405154-6bc2-437b-9493-9b50ef895545"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "15:51:46 Starting training\n",
            "15:51:46 Logging to:\torigtoolimgs-v1-singleclass-color-logger.log\n",
            "15:51:46 Models will be saved to local directory:\torigtoolimgs-v1-singleclass-color\n",
            "15:51:46 Models will be saved with base name:\torigtoolimgs-v1_epoch[].pth\n",
            "15:51:46 Optimizers will be saved with base name:\torigtoolimgs-v1_epoch[]_optimizer.pth\n",
            "15:51:46 Schedulers will be saved with base name:\torigtoolimgs-v1_epoch[]_scheduler.pth\n",
            "15:51:46 Performing initial evaluation...\n",
            "15:51:47 Obtained features, validation in progress\n",
            "15:51:47 Accuracy: 2.469%\n",
            "15:51:47 Micro F-score: 0.025\n",
            "15:51:47 Weighted F-score: 0.033\n",
            "15:51:47 Starting training from 0\n",
            "15:51:47 Parameter Group `opt-1`: Starting epoch 0 with 20 steps and learning rate 1.00000E-05\n",
            "15:51:54 ********** Completed epoch 0 **********\n",
            "15:51:54 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "15:51:54 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "15:51:55 Parameter Group `opt-1`: Starting epoch 1 with 20 steps and learning rate 1.00000E-05\n",
            "15:51:55 Evaluating model at test-frequency\n",
            "15:51:57 Obtained features, validation in progress\n",
            "15:51:57 Accuracy: 24.691%\n",
            "15:51:57 Micro F-score: 0.247\n",
            "15:51:57 Weighted F-score: 0.298\n",
            "15:51:57 Saving model at save-frequency, at epoch 0, step 0\n",
            "15:51:57 Saving model, optimizer, and scheduler.\n",
            "15:52:02 ********** Completed epoch 1 **********\n",
            "15:52:02 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "15:52:02 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "15:52:03 Parameter Group `opt-1`: Starting epoch 2 with 20 steps and learning rate 1.00000E-05\n",
            "15:52:03 Evaluating model at test-frequency\n",
            "15:52:05 Obtained features, validation in progress\n",
            "15:52:05 Accuracy: 50.617%\n",
            "15:52:05 Micro F-score: 0.506\n",
            "15:52:05 Weighted F-score: 0.539\n",
            "15:52:05 Saving model at save-frequency, at epoch 1, step 0\n",
            "15:52:05 Saving model, optimizer, and scheduler.\n",
            "15:52:10 ********** Completed epoch 2 **********\n",
            "15:52:10 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "15:52:10 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "15:52:11 Parameter Group `opt-1`: Starting epoch 3 with 20 steps and learning rate 1.00000E-05\n",
            "15:52:11 Evaluating model at test-frequency\n",
            "15:52:12 Obtained features, validation in progress\n",
            "15:52:12 Accuracy: 60.494%\n",
            "15:52:12 Micro F-score: 0.605\n",
            "15:52:12 Weighted F-score: 0.630\n",
            "15:52:12 Saving model at save-frequency, at epoch 2, step 0\n",
            "15:52:12 Saving model, optimizer, and scheduler.\n",
            "15:52:18 ********** Completed epoch 3 **********\n",
            "15:52:18 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "15:52:18 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "15:52:19 Parameter Group `opt-1`: Starting epoch 4 with 20 steps and learning rate 1.00000E-05\n",
            "15:52:20 Evaluating model at test-frequency\n",
            "15:52:21 Obtained features, validation in progress\n",
            "15:52:21 Accuracy: 71.605%\n",
            "15:52:21 Micro F-score: 0.716\n",
            "15:52:21 Weighted F-score: 0.717\n",
            "15:52:21 Saving model at save-frequency, at epoch 3, step 0\n",
            "15:52:21 Saving model, optimizer, and scheduler.\n",
            "15:52:25 ********** Completed epoch 4 **********\n",
            "15:52:25 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "15:52:25 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "15:52:26 Parameter Group `opt-1`: Starting epoch 5 with 20 steps and learning rate 1.00000E-05\n",
            "15:52:27 Evaluating model at test-frequency\n",
            "15:52:29 Obtained features, validation in progress\n",
            "15:52:29 Accuracy: 76.543%\n",
            "15:52:29 Micro F-score: 0.765\n",
            "15:52:29 Weighted F-score: 0.746\n",
            "15:52:29 Saving model at save-frequency, at epoch 4, step 0\n",
            "15:52:29 Saving model, optimizer, and scheduler.\n",
            "15:52:34 ********** Completed epoch 5 **********\n",
            "15:52:34 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "15:52:34 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "15:52:35 Parameter Group `opt-1`: Starting epoch 6 with 20 steps and learning rate 1.00000E-05\n",
            "15:52:35 Evaluating model at test-frequency\n",
            "15:52:36 Obtained features, validation in progress\n",
            "15:52:36 Accuracy: 77.778%\n",
            "15:52:36 Micro F-score: 0.778\n",
            "15:52:36 Weighted F-score: 0.761\n",
            "15:52:36 Saving model at save-frequency, at epoch 5, step 0\n",
            "15:52:36 Saving model, optimizer, and scheduler.\n",
            "15:52:42 ********** Completed epoch 6 **********\n",
            "15:52:42 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "15:52:42 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "15:52:43 Parameter Group `opt-1`: Starting epoch 7 with 20 steps and learning rate 1.00000E-05\n",
            "15:52:43 Evaluating model at test-frequency\n",
            "15:52:45 Obtained features, validation in progress\n",
            "15:52:45 Accuracy: 80.247%\n",
            "15:52:45 Micro F-score: 0.802\n",
            "15:52:45 Weighted F-score: 0.788\n",
            "15:52:45 Saving model at save-frequency, at epoch 6, step 0\n",
            "15:52:45 Saving model, optimizer, and scheduler.\n",
            "15:52:49 ********** Completed epoch 7 **********\n",
            "15:52:49 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "15:52:49 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "15:52:50 Parameter Group `opt-1`: Starting epoch 8 with 20 steps and learning rate 1.00000E-05\n",
            "15:52:51 Evaluating model at test-frequency\n",
            "15:52:53 Obtained features, validation in progress\n",
            "15:52:53 Accuracy: 80.247%\n",
            "15:52:53 Micro F-score: 0.802\n",
            "15:52:53 Weighted F-score: 0.785\n",
            "15:52:53 Saving model at save-frequency, at epoch 7, step 0\n",
            "15:52:53 Saving model, optimizer, and scheduler.\n",
            "15:52:58 ********** Completed epoch 8 **********\n",
            "15:52:58 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "15:52:58 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "15:52:59 Parameter Group `opt-1`: Starting epoch 9 with 20 steps and learning rate 1.00000E-05\n",
            "15:52:59 Evaluating model at test-frequency\n",
            "15:53:01 Obtained features, validation in progress\n",
            "15:53:01 Accuracy: 80.247%\n",
            "15:53:01 Micro F-score: 0.802\n",
            "15:53:01 Weighted F-score: 0.785\n",
            "15:53:01 Saving model at save-frequency, at epoch 8, step 0\n",
            "15:53:01 Saving model, optimizer, and scheduler.\n",
            "15:53:05 ********** Completed epoch 9 **********\n",
            "15:53:05 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "15:53:05 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "15:53:06 Parameter Group `opt-1`: Starting epoch 10 with 20 steps and learning rate 1.00000E-05\n",
            "15:53:06 Evaluating model at test-frequency\n",
            "15:53:09 Obtained features, validation in progress\n",
            "15:53:09 Accuracy: 81.481%\n",
            "15:53:09 Micro F-score: 0.815\n",
            "15:53:09 Weighted F-score: 0.796\n",
            "15:53:09 Saving model at save-frequency, at epoch 9, step 0\n",
            "15:53:09 Saving model, optimizer, and scheduler.\n",
            "15:53:14 ********** Completed epoch 10 **********\n",
            "15:53:14 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "15:53:14 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "15:53:14 Final: Evaluating model at test-frequency\n",
            "15:53:15 Obtained features, validation in progress\n",
            "15:53:15 Accuracy: 81.481%\n",
            "15:53:15 Micro F-score: 0.815\n",
            "15:53:15 Weighted F-score: 0.796\n",
            "15:53:15 Final: Saving model at save-frequency\n",
            "15:53:15 Saving model, optimizer, and scheduler.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resp = eml.eval()"
      ],
      "metadata": {
        "id": "cRvm2rq1OLMO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48f1b3fb-9fd9-427e-9009-1fd26b9f95c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "15:53:16 Obtained features, validation in progress\n",
            "15:53:16 Accuracy: 81.481%\n",
            "15:53:16 Micro F-score: 0.815\n",
            "15:53:16 Weighted F-score: 0.796\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.3 Single classification (Vehicle Make)\n",
        "\n",
        "And finally, a make classifier"
      ],
      "metadata": {
        "id": "STAXYyAi6_58"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_name = \"make\"   # Make sure to change this to whatever name you used for make in your `original_tool_images` crawler\n",
        "class_idx = 4         # Make sure to change this to whetever index `make` is in your Crawler's tuple!\n",
        "path_idx = 0          # Change this to whichever index in tuple has path\n",
        "crawler_args = {\"file_name\" : \"original_tool_image.zip\"}"
      ],
      "metadata": {
        "id": "FnQGcJf96_58"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "metadata": {
        "id": "THXrRvUm6_58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4f7c543-8fb8-4ff4-a4f8-5821095383c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ednaml.core import EdnaML\n",
        "from ednaml.generators import ClassificationGenerator\n",
        "\n",
        "eml = EdnaML(config = \"./GLAMOR/profiles/CarZam/base_config.yml\", config_inject=[\n",
        "    (\"SAVE.MODEL_QUALIFIER\", class_name)\n",
        "])\n",
        "\n",
        "eml.cfg.EXECUTION.DATAREADER.CRAWLER_ARGS = crawler_args\n",
        "eml.cfg.EXECUTION.DATAREADER.DATASET_ARGS[\"pathidx\"] = path_idx\n",
        "eml.cfg.EXECUTION.DATAREADER.DATASET_ARGS[\"annotationidx\"] = class_idx\n",
        "eml.cfg.EXECUTION.DATAREADER.DATASET_ARGS[\"classificationclass\"] = class_name\n",
        "\n",
        "eml.addGeneratorClass(ClassificationGenerator)\n",
        "eml.addCrawlerClass(CarZamCrawler)"
      ],
      "metadata": {
        "id": "Jpn_wdIv6_58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06ae4d0c-9157-4090-bd75-f21363c97f23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Injected key-value pair:  SAVE.MODEL_QUALIFIER, make\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eml.apply()"
      ],
      "metadata": {
        "id": "r4fIyr3K6_59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54954854-9f69-403e-98d2-c1a485dcf617"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "15:53:16 ****************************************\n",
            "15:53:16 \n",
            "15:53:16 \n",
            "15:53:16 Using the following configuration:\n",
            "15:53:16 DEPLOYMENT:\n",
            "  DATAREADER:\n",
            "    CRAWLER_ARGS: {}\n",
            "    DATAREADER: DataReader\n",
            "    DATASET_ARGS: {}\n",
            "    GENERATOR: null\n",
            "    GENERATOR_ARGS: {}\n",
            "  DEPLOY: BaseDeploy\n",
            "  DEPLOYMENT_ARGS: {}\n",
            "  EPOCHS: 1\n",
            "  OUTPUT_ARGS: {}\n",
            "  PLUGIN:\n",
            "    HOOKS: always\n",
            "    RESET: false\n",
            "EXECUTION:\n",
            "  DATAREADER:\n",
            "    CRAWLER_ARGS:\n",
            "      file_name: original_tool_image.zip\n",
            "    DATAREADER: DataReader\n",
            "    DATASET_ARGS:\n",
            "      annotationidx: 4\n",
            "      classificationclass: make\n",
            "      pathidx: 0\n",
            "    GENERATOR: null\n",
            "    GENERATOR_ARGS: {}\n",
            "  EPOCHS: 10\n",
            "  FP16: false\n",
            "  MODEL_SERVING: Unused\n",
            "  OPTIMIZER_BUILDER: ClassificationOptimizer\n",
            "  PLUGIN:\n",
            "    HOOKS: always\n",
            "    RESET: false\n",
            "  SKIPEVAL: false\n",
            "  TEST_FREQUENCY: 1\n",
            "  TRAINER: ClassificationTrainer\n",
            "  TRAINER_ARGS:\n",
            "    accumulation_steps: 4\n",
            "LOGGING:\n",
            "  INPUT_SIZE: null\n",
            "  STEP_VERBOSE: 100\n",
            "LOSS:\n",
            "- KWARGS:\n",
            "  - {}\n",
            "  LABEL: ''\n",
            "  LAMBDAS:\n",
            "  - 1.0\n",
            "  LOSSES:\n",
            "  - SoftmaxLogitsLoss\n",
            "  NAME: out1\n",
            "LOSS_OPTIMIZER:\n",
            "- BASE_LR: 0.001\n",
            "  LR_BIAS_FACTOR: 1.0\n",
            "  OPTIMIZER: Adam\n",
            "  OPTIMIZER_KWARGS: {}\n",
            "  OPTIMIZER_NAME: opt-1\n",
            "  WEIGHT_BIAS_FACTOR: 0.0005\n",
            "  WEIGHT_DECAY: 0.0005\n",
            "LOSS_SCHEDULER:\n",
            "- LR_KWARGS:\n",
            "    step_size: 20\n",
            "  LR_SCHEDULER: StepLR\n",
            "  SCHEDULER_NAME: opt-1\n",
            "MODEL:\n",
            "  BUILDER: classification_model_builder\n",
            "  MODEL_ARCH: ClassificationResnet\n",
            "  MODEL_BASE: resnet18\n",
            "  MODEL_KWARGS: {}\n",
            "  MODEL_NORMALIZATION: bn\n",
            "  PARAMETER_GROUPS:\n",
            "  - opt-1\n",
            "MODEL_PLUGIN: {}\n",
            "OPTIMIZER:\n",
            "- BASE_LR: 1.0e-05\n",
            "  LR_BIAS_FACTOR: 1.0\n",
            "  OPTIMIZER: Adam\n",
            "  OPTIMIZER_KWARGS: {}\n",
            "  OPTIMIZER_NAME: opt-1\n",
            "  WEIGHT_BIAS_FACTOR: 0.0005\n",
            "  WEIGHT_DECAY: 0.0005\n",
            "SAVE:\n",
            "  CHECKPOINT_DIRECTORY: checkpoint\n",
            "  DRIVE_BACKUP: false\n",
            "  LOG_BACKUP: false\n",
            "  MODEL_BACKBONE: singleclass\n",
            "  MODEL_CORE_NAME: origtoolimgs\n",
            "  MODEL_QUALIFIER: make\n",
            "  MODEL_VERSION: 1\n",
            "  SAVE_FREQUENCY: 1\n",
            "  STEP_SAVE_FREQUENCY: 0\n",
            "SCHEDULER:\n",
            "- LR_KWARGS:\n",
            "    gamma: 0.1\n",
            "    step_size: 20\n",
            "  LR_SCHEDULER: StepLR\n",
            "  SCHEDULER_NAME: opt-1\n",
            "STORAGE:\n",
            "  STORAGE_ARGS: {}\n",
            "  TYPE: BaseStorage\n",
            "  URL: ./\n",
            "TEST_TRANSFORMATION:\n",
            "  ARGS:\n",
            "    channels: 3\n",
            "    i_shape:\n",
            "    - 200\n",
            "    - 200\n",
            "    normalization_mean: 0.5\n",
            "    normalization_scale: 0.5\n",
            "    normalization_std: 0.5\n",
            "  BATCH_SIZE: 32\n",
            "  WORKERS: 2\n",
            "TRAIN_TRANSFORMATION:\n",
            "  ARGS:\n",
            "    channels: 3\n",
            "    h_flip: 0.5\n",
            "    i_shape:\n",
            "    - 200\n",
            "    - 200\n",
            "    normalization_mean: 0.5\n",
            "    normalization_scale: 0.5\n",
            "    normalization_std: 0.5\n",
            "    random_erase: true\n",
            "    random_erase_value: 0.3\n",
            "    t_crop: true\n",
            "  BATCH_SIZE: 32\n",
            "  WORKERS: 2\n",
            "extensions:\n",
            "- EXECUTION\n",
            "- SAVE\n",
            "- STORAGE\n",
            "- TRANSFORMATION\n",
            "- MODEL\n",
            "- LOSS\n",
            "- OPTIMIZER\n",
            "- SCHEDULER\n",
            "- LOSS_OPTIMIZER\n",
            "- LOSS_SCHEDULER\n",
            "- LOGGING\n",
            "- DEPLOYMENT\n",
            "- MODEL_PLUGIN\n",
            "\n",
            "15:53:16 \n",
            "15:53:16 \n",
            "15:53:16 ****************************************\n",
            "15:53:16 No previous stop detected. Will start from epoch 0\n",
            "15:53:16 Loaded BaseStorage from ednaml.storage to build Storage\n",
            "15:53:16 Reading data with DataReader DataReader\n",
            "15:53:16 Default CRAWLER is <class 'ednaml.crawlers.Crawler'>\n",
            "15:53:16 Default DATASET is <class 'torch.utils.data.dataset.Dataset'>\n",
            "15:53:16 Default GENERATOR is <class 'ednaml.generators.ImageGenerator.ImageGenerator'>\n",
            "15:53:16 Updating GENERATOR to queued class ClassificationGenerator\n",
            "15:53:16 Updating CRAWLER to CarZamCrawler\n",
            "15:53:16 Generated training data generator with 648 training data points\n",
            "15:53:16 Running classification model with classes: {'make': {'classes': 34}}\n",
            "15:53:16 Generated test data/query generator\n",
            "15:53:16 Loaded classification_model_builder from ednaml.models to build model\n",
            "15:53:17 Finished instantiating model with ClassificationResnet architecture\n",
            "15:53:17 Adding plugins after constructing model\n",
            "15:53:17 No saved model weights provided.\n",
            "15:53:17 Model Summary retured the following error:\n",
            "15:53:17 Traceback (most recent call last):\n",
            "  File \"/content/GLAMOR/src/ednaml/core/EdnaML.py\", line 888, in getModelSummary\n",
            "    self.cfg.TRAIN_TRANSFORMATION.INPUT_SIZE,\n",
            "AttributeError: 'TransformationConfig' object has no attribute 'INPUT_SIZE'\n",
            "\n",
            "15:53:17 Loaded ClassificationOptimizer from ednaml.optimizer to build Optimizer model\n",
            "15:53:17 Built optimizer\n",
            "15:53:17 Built scheduler\n",
            "15:53:17 Added SoftmaxLogitsLoss with lambda = 1.0 and loss arguments {}\n",
            "15:53:17 Built loss function\n",
            "15:53:17 Built loss optimizer\n",
            "15:53:17 Built loss scheduler\n",
            "15:53:17 Loaded BaseStorage from ednaml.storage to build Storage\n",
            "15:53:17 Loaded ClassificationTrainer from ednaml.trainer to build Trainer\n",
            "15:53:17 Saving model metadata\n",
            "15:53:17 Backing up metadata\n",
            "15:53:17 Finished metadata backup\n",
            "15:53:17 1 GPUs available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eml.train()"
      ],
      "metadata": {
        "id": "H3As1f7w6_59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32ff8d5f-ccb9-481e-95a2-deab4e706896"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "15:53:17 Starting training\n",
            "15:53:17 Logging to:\torigtoolimgs-v1-singleclass-make-logger.log\n",
            "15:53:17 Models will be saved to local directory:\torigtoolimgs-v1-singleclass-make\n",
            "15:53:17 Models will be saved with base name:\torigtoolimgs-v1_epoch[].pth\n",
            "15:53:17 Optimizers will be saved with base name:\torigtoolimgs-v1_epoch[]_optimizer.pth\n",
            "15:53:17 Schedulers will be saved with base name:\torigtoolimgs-v1_epoch[]_scheduler.pth\n",
            "15:53:17 Performing initial evaluation...\n",
            "15:53:18 Obtained features, validation in progress\n",
            "15:53:18 Accuracy: 2.469%\n",
            "15:53:18 Micro F-score: 0.025\n",
            "15:53:18 Weighted F-score: 0.011\n",
            "15:53:18 Starting training from 0\n",
            "15:53:18 Parameter Group `opt-1`: Starting epoch 0 with 20 steps and learning rate 1.00000E-05\n",
            "15:53:25 ********** Completed epoch 0 **********\n",
            "15:53:25 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "15:53:25 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "15:53:26 Parameter Group `opt-1`: Starting epoch 1 with 20 steps and learning rate 1.00000E-05\n",
            "15:53:26 Evaluating model at test-frequency\n",
            "15:53:28 Obtained features, validation in progress\n",
            "15:53:28 Accuracy: 4.938%\n",
            "15:53:28 Micro F-score: 0.049\n",
            "15:53:28 Weighted F-score: 0.054\n",
            "15:53:28 Saving model at save-frequency, at epoch 0, step 0\n",
            "15:53:28 Saving model, optimizer, and scheduler.\n",
            "15:53:32 ********** Completed epoch 1 **********\n",
            "15:53:32 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "15:53:32 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "15:53:33 Parameter Group `opt-1`: Starting epoch 2 with 20 steps and learning rate 1.00000E-05\n",
            "15:53:33 Evaluating model at test-frequency\n",
            "15:53:36 Obtained features, validation in progress\n",
            "15:53:36 Accuracy: 6.173%\n",
            "15:53:36 Micro F-score: 0.062\n",
            "15:53:36 Weighted F-score: 0.068\n",
            "15:53:36 Saving model at save-frequency, at epoch 1, step 0\n",
            "15:53:36 Saving model, optimizer, and scheduler.\n",
            "15:53:40 ********** Completed epoch 2 **********\n",
            "15:53:40 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "15:53:40 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "15:53:41 Parameter Group `opt-1`: Starting epoch 3 with 20 steps and learning rate 1.00000E-05\n",
            "15:53:41 Evaluating model at test-frequency\n",
            "15:53:43 Obtained features, validation in progress\n",
            "15:53:43 Accuracy: 12.346%\n",
            "15:53:43 Micro F-score: 0.123\n",
            "15:53:43 Weighted F-score: 0.119\n",
            "15:53:43 Saving model at save-frequency, at epoch 2, step 0\n",
            "15:53:43 Saving model, optimizer, and scheduler.\n",
            "15:53:49 ********** Completed epoch 3 **********\n",
            "15:53:49 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "15:53:49 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "15:53:50 Parameter Group `opt-1`: Starting epoch 4 with 20 steps and learning rate 1.00000E-05\n",
            "15:53:50 Evaluating model at test-frequency\n",
            "15:53:52 Obtained features, validation in progress\n",
            "15:53:52 Accuracy: 16.049%\n",
            "15:53:52 Micro F-score: 0.160\n",
            "15:53:52 Weighted F-score: 0.152\n",
            "15:53:52 Saving model at save-frequency, at epoch 3, step 0\n",
            "15:53:52 Saving model, optimizer, and scheduler.\n",
            "15:53:56 ********** Completed epoch 4 **********\n",
            "15:53:56 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "15:53:56 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "15:53:57 Parameter Group `opt-1`: Starting epoch 5 with 20 steps and learning rate 1.00000E-05\n",
            "15:53:57 Evaluating model at test-frequency\n",
            "15:53:59 Obtained features, validation in progress\n",
            "15:53:59 Accuracy: 20.988%\n",
            "15:53:59 Micro F-score: 0.210\n",
            "15:53:59 Weighted F-score: 0.186\n",
            "15:53:59 Saving model at save-frequency, at epoch 4, step 0\n",
            "15:53:59 Saving model, optimizer, and scheduler.\n",
            "15:54:05 ********** Completed epoch 5 **********\n",
            "15:54:05 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "15:54:05 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "15:54:05 Parameter Group `opt-1`: Starting epoch 6 with 20 steps and learning rate 1.00000E-05\n",
            "15:54:05 Evaluating model at test-frequency\n",
            "15:54:07 Obtained features, validation in progress\n",
            "15:54:07 Accuracy: 24.691%\n",
            "15:54:07 Micro F-score: 0.247\n",
            "15:54:07 Weighted F-score: 0.221\n",
            "15:54:07 Saving model at save-frequency, at epoch 5, step 0\n",
            "15:54:07 Saving model, optimizer, and scheduler.\n",
            "15:54:12 ********** Completed epoch 6 **********\n",
            "15:54:12 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "15:54:12 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "15:54:13 Parameter Group `opt-1`: Starting epoch 7 with 20 steps and learning rate 1.00000E-05\n",
            "15:54:13 Evaluating model at test-frequency\n",
            "15:54:15 Obtained features, validation in progress\n",
            "15:54:15 Accuracy: 30.864%\n",
            "15:54:15 Micro F-score: 0.309\n",
            "15:54:15 Weighted F-score: 0.292\n",
            "15:54:15 Saving model at save-frequency, at epoch 6, step 0\n",
            "15:54:15 Saving model, optimizer, and scheduler.\n",
            "15:54:20 ********** Completed epoch 7 **********\n",
            "15:54:20 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "15:54:20 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "15:54:21 Parameter Group `opt-1`: Starting epoch 8 with 20 steps and learning rate 1.00000E-05\n",
            "15:54:22 Evaluating model at test-frequency\n",
            "15:54:23 Obtained features, validation in progress\n",
            "15:54:23 Accuracy: 34.568%\n",
            "15:54:23 Micro F-score: 0.346\n",
            "15:54:23 Weighted F-score: 0.336\n",
            "15:54:23 Saving model at save-frequency, at epoch 7, step 0\n",
            "15:54:23 Saving model, optimizer, and scheduler.\n",
            "15:54:29 ********** Completed epoch 8 **********\n",
            "15:54:29 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "15:54:29 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "15:54:29 Parameter Group `opt-1`: Starting epoch 9 with 20 steps and learning rate 1.00000E-05\n",
            "15:54:30 Evaluating model at test-frequency\n",
            "15:54:31 Obtained features, validation in progress\n",
            "15:54:31 Accuracy: 35.802%\n",
            "15:54:31 Micro F-score: 0.358\n",
            "15:54:31 Weighted F-score: 0.342\n",
            "15:54:31 Saving model at save-frequency, at epoch 8, step 0\n",
            "15:54:31 Saving model, optimizer, and scheduler.\n",
            "15:54:36 ********** Completed epoch 9 **********\n",
            "15:54:36 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "15:54:36 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "15:54:36 Parameter Group `opt-1`: Starting epoch 10 with 20 steps and learning rate 1.00000E-05\n",
            "15:54:37 Evaluating model at test-frequency\n",
            "15:54:38 Obtained features, validation in progress\n",
            "15:54:38 Accuracy: 37.037%\n",
            "15:54:38 Micro F-score: 0.370\n",
            "15:54:38 Weighted F-score: 0.350\n",
            "15:54:38 Saving model at save-frequency, at epoch 9, step 0\n",
            "15:54:38 Saving model, optimizer, and scheduler.\n",
            "15:54:44 ********** Completed epoch 10 **********\n",
            "15:54:44 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "15:54:44 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "15:54:44 Final: Evaluating model at test-frequency\n",
            "15:54:45 Obtained features, validation in progress\n",
            "15:54:45 Accuracy: 37.037%\n",
            "15:54:45 Micro F-score: 0.370\n",
            "15:54:45 Weighted F-score: 0.354\n",
            "15:54:45 Final: Saving model at save-frequency\n",
            "15:54:45 Saving model, optimizer, and scheduler.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resp = eml.eval()"
      ],
      "metadata": {
        "id": "JacLY1vFOJkn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efb92453-02b0-43da-8306-556378c0bc04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "15:54:47 Obtained features, validation in progress\n",
            "15:54:47 Accuracy: 37.037%\n",
            "15:54:47 Micro F-score: 0.370\n",
            "15:54:47 Weighted F-score: 0.354\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Multiclass classifiers\n",
        "\n",
        "Multiclass classifiers try to classify multiple things at once, using the same features. Sometimes it works, if the features are colocated or have some overlap. Othertimes, it doesn't work very well. We can examine this in case of our small dataset first."
      ],
      "metadata": {
        "id": "Evv2taNh-yur"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.1 Multi-class classification (color-type)\n",
        "\n",
        "Now we will try a model that performs vehicle type AND vehicle color classification together. The config is already prepared for this in `profiles/color_type.yml`.\n",
        "\n",
        "Our architecture looks like:\n",
        "\n",
        "[<img src=\"https://i.redd.it/7ndvmdlq4yx91.png\" width=\"550\"/>]"
      ],
      "metadata": {
        "id": "lzUnXtOsdffC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_idx = 0          # Change this to whichever index in tuple has path\n",
        "crawler_args = {\"file_name\" : \"original_tool_image.zip\"}"
      ],
      "metadata": {
        "id": "z0VzCR36dffC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "metadata": {
        "id": "c47YhBlvdffC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91dd79ec-ab81-48cd-e632-658d61596d7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ednaml.core import EdnaML\n",
        "from ednaml.generators import ClassificationGenerator\n",
        "\n",
        "eml = EdnaML(config = [\"./GLAMOR/profiles/CarZam/base_config.yml\",\"./GLAMOR/profiles/CarZam/color_type.yml\"])\n",
        "\n",
        "eml.cfg.EXECUTION.DATAREADER.CRAWLER_ARGS = crawler_args\n",
        "eml.cfg.EXECUTION.DATAREADER.DATASET_ARGS[\"pathidx\"] = path_idx\n",
        "# We have already set these in config\n",
        "#eml.cfg.EXECUTION.DATAREADER.DATASET_ARGS[\"annotationidx\"] = class_idx\n",
        "#eml.cfg.EXECUTION.DATAREADER.DATASET_ARGS[\"classificationclass\"] = class_name\n",
        "\n",
        "#eml.addGeneratorClass(MultiClassificationGenerator)\n",
        "eml.addCrawlerClass(CarZamCrawler)"
      ],
      "metadata": {
        "id": "vaP7V7LadffD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eml.apply()"
      ],
      "metadata": {
        "id": "hzSOceAQdffD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fa09cef-596e-47cd-eac6-e502b28bfb74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "15:54:47 ****************************************\n",
            "15:54:47 \n",
            "15:54:47 \n",
            "15:54:47 Using the following configuration:\n",
            "15:54:47 DEPLOYMENT:\n",
            "  DATAREADER:\n",
            "    CRAWLER_ARGS: {}\n",
            "    DATAREADER: DataReader\n",
            "    DATASET_ARGS: {}\n",
            "    GENERATOR: null\n",
            "    GENERATOR_ARGS: {}\n",
            "  DEPLOY: BaseDeploy\n",
            "  DEPLOYMENT_ARGS: {}\n",
            "  EPOCHS: 1\n",
            "  OUTPUT_ARGS: {}\n",
            "  PLUGIN:\n",
            "    HOOKS: always\n",
            "    RESET: false\n",
            "EXECUTION:\n",
            "  DATAREADER:\n",
            "    CRAWLER_ARGS:\n",
            "      file_name: original_tool_image.zip\n",
            "    DATAREADER: DataReader\n",
            "    DATASET_ARGS:\n",
            "      annotationidx:\n",
            "      - 2\n",
            "      - 1\n",
            "      classificationclass:\n",
            "      - color\n",
            "      - vtype\n",
            "      pathidx: 0\n",
            "    GENERATOR: MultiClassificationGenerator\n",
            "    GENERATOR_ARGS: {}\n",
            "  EPOCHS: 10\n",
            "  FP16: false\n",
            "  MODEL_SERVING: Unused\n",
            "  OPTIMIZER_BUILDER: ClassificationOptimizer\n",
            "  PLUGIN:\n",
            "    HOOKS: always\n",
            "    RESET: false\n",
            "  SKIPEVAL: false\n",
            "  TEST_FREQUENCY: 1\n",
            "  TRAINER: MultiClassificationTrainer\n",
            "  TRAINER_ARGS:\n",
            "    accumulation_steps: 4\n",
            "LOGGING:\n",
            "  INPUT_SIZE: null\n",
            "  STEP_VERBOSE: 100\n",
            "LOSS:\n",
            "- KWARGS:\n",
            "  - {}\n",
            "  LABEL: color\n",
            "  LAMBDAS:\n",
            "  - 1.0\n",
            "  LOSSES:\n",
            "  - SoftmaxLogitsLoss\n",
            "  NAME: colorloss\n",
            "- KWARGS:\n",
            "  - {}\n",
            "  LABEL: vtype\n",
            "  LAMBDAS:\n",
            "  - 1.0\n",
            "  LOSSES:\n",
            "  - SoftmaxLogitsLoss\n",
            "  NAME: typeloss\n",
            "LOSS_OPTIMIZER:\n",
            "- BASE_LR: 0.001\n",
            "  LR_BIAS_FACTOR: 1.0\n",
            "  OPTIMIZER: Adam\n",
            "  OPTIMIZER_KWARGS: {}\n",
            "  OPTIMIZER_NAME: opt-1\n",
            "  WEIGHT_BIAS_FACTOR: 0.0005\n",
            "  WEIGHT_DECAY: 0.0005\n",
            "LOSS_SCHEDULER:\n",
            "- LR_KWARGS:\n",
            "    step_size: 20\n",
            "  LR_SCHEDULER: StepLR\n",
            "  SCHEDULER_NAME: opt-1\n",
            "MODEL:\n",
            "  BUILDER: multiclassification_model_builder\n",
            "  MODEL_ARCH: MultiClassificationResnet\n",
            "  MODEL_BASE: resnet18\n",
            "  MODEL_KWARGS:\n",
            "    number_outputs: 2\n",
            "    outputs:\n",
            "    - dimensions: null\n",
            "      label: vtype\n",
            "      name: type\n",
            "    - dimensions: null\n",
            "      label: color\n",
            "      name: out2\n",
            "  MODEL_NORMALIZATION: bn\n",
            "  PARAMETER_GROUPS:\n",
            "  - opt-1\n",
            "MODEL_PLUGIN: {}\n",
            "OPTIMIZER:\n",
            "- BASE_LR: 1.0e-05\n",
            "  LR_BIAS_FACTOR: 1.0\n",
            "  OPTIMIZER: Adam\n",
            "  OPTIMIZER_KWARGS: {}\n",
            "  OPTIMIZER_NAME: opt-1\n",
            "  WEIGHT_BIAS_FACTOR: 0.0005\n",
            "  WEIGHT_DECAY: 0.0005\n",
            "SAVE:\n",
            "  CHECKPOINT_DIRECTORY: checkpoint\n",
            "  DRIVE_BACKUP: false\n",
            "  LOG_BACKUP: false\n",
            "  MODEL_BACKBONE: multiclass\n",
            "  MODEL_CORE_NAME: origtoolimgs\n",
            "  MODEL_QUALIFIER: color-vtype\n",
            "  MODEL_VERSION: 1\n",
            "  SAVE_FREQUENCY: 1\n",
            "  STEP_SAVE_FREQUENCY: 0\n",
            "SCHEDULER:\n",
            "- LR_KWARGS:\n",
            "    gamma: 0.1\n",
            "    step_size: 20\n",
            "  LR_SCHEDULER: StepLR\n",
            "  SCHEDULER_NAME: opt-1\n",
            "STORAGE:\n",
            "  STORAGE_ARGS: {}\n",
            "  TYPE: BaseStorage\n",
            "  URL: ./\n",
            "TEST_TRANSFORMATION:\n",
            "  ARGS:\n",
            "    channels: 3\n",
            "    i_shape:\n",
            "    - 200\n",
            "    - 200\n",
            "    normalization_mean: 0.5\n",
            "    normalization_scale: 0.5\n",
            "    normalization_std: 0.5\n",
            "  BATCH_SIZE: 32\n",
            "  WORKERS: 2\n",
            "TRAIN_TRANSFORMATION:\n",
            "  ARGS:\n",
            "    channels: 3\n",
            "    h_flip: 0.5\n",
            "    i_shape:\n",
            "    - 200\n",
            "    - 200\n",
            "    normalization_mean: 0.5\n",
            "    normalization_scale: 0.5\n",
            "    normalization_std: 0.5\n",
            "    random_erase: true\n",
            "    random_erase_value: 0.3\n",
            "    t_crop: true\n",
            "  BATCH_SIZE: 32\n",
            "  WORKERS: 2\n",
            "extensions:\n",
            "- EXECUTION\n",
            "- SAVE\n",
            "- STORAGE\n",
            "- TRANSFORMATION\n",
            "- MODEL\n",
            "- LOSS\n",
            "- OPTIMIZER\n",
            "- SCHEDULER\n",
            "- LOSS_OPTIMIZER\n",
            "- LOSS_SCHEDULER\n",
            "- LOGGING\n",
            "- DEPLOYMENT\n",
            "- MODEL_PLUGIN\n",
            "\n",
            "15:54:47 \n",
            "15:54:47 \n",
            "15:54:47 ****************************************\n",
            "15:54:47 No previous stop detected. Will start from epoch 0\n",
            "15:54:47 Loaded BaseStorage from ednaml.storage to build Storage\n",
            "15:54:47 Reading data with DataReader DataReader\n",
            "15:54:47 Default CRAWLER is <class 'ednaml.crawlers.Crawler'>\n",
            "15:54:47 Default DATASET is <class 'torch.utils.data.dataset.Dataset'>\n",
            "15:54:47 Default GENERATOR is <class 'ednaml.generators.ImageGenerator.ImageGenerator'>\n",
            "15:54:47 Updating GENERATOR using config specification to MultiClassificationGenerator\n",
            "15:54:47 Updating CRAWLER to CarZamCrawler\n",
            "15:54:47 Generated training data generator with 648 training data points\n",
            "15:54:47 Running classification model with classes: {'color': {'classes': 13}, 'vtype': {'classes': 5}}\n",
            "15:54:47 Generated test data/query generator\n",
            "15:54:47 Loaded multiclassification_model_builder from ednaml.models to build model\n",
            "15:54:47 Finished instantiating model with MultiClassificationResnet architecture\n",
            "15:54:47 Adding plugins after constructing model\n",
            "15:54:47 No saved model weights provided.\n",
            "15:54:47 Model Summary retured the following error:\n",
            "15:54:47 Traceback (most recent call last):\n",
            "  File \"/content/GLAMOR/src/ednaml/core/EdnaML.py\", line 888, in getModelSummary\n",
            "    self.cfg.TRAIN_TRANSFORMATION.INPUT_SIZE,\n",
            "AttributeError: 'TransformationConfig' object has no attribute 'INPUT_SIZE'\n",
            "\n",
            "15:54:47 Loaded ClassificationOptimizer from ednaml.optimizer to build Optimizer model\n",
            "15:54:47 Built optimizer\n",
            "15:54:47 Built scheduler\n",
            "15:54:47 Added SoftmaxLogitsLoss with lambda = 1.0 and loss arguments {}\n",
            "15:54:47 Added SoftmaxLogitsLoss with lambda = 1.0 and loss arguments {}\n",
            "15:54:47 Built loss function\n",
            "15:54:47 Built loss optimizer\n",
            "15:54:47 Built loss scheduler\n",
            "15:54:47 Built loss scheduler\n",
            "15:54:47 Loaded BaseStorage from ednaml.storage to build Storage\n",
            "15:54:47 Loaded MultiClassificationTrainer from ednaml.trainer to build Trainer\n",
            "15:54:47 Saving model metadata\n",
            "15:54:47 Backing up metadata\n",
            "15:54:47 Finished metadata backup\n",
            "15:54:47 1 GPUs available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eml.train()"
      ],
      "metadata": {
        "id": "jtux7QIEdffD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "566a68d9-6fa5-45ad-f15d-7373cc3b3761"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "15:54:47 Starting training\n",
            "15:54:47 Logging to:\torigtoolimgs-v1-multiclass-color-vtype-logger.log\n",
            "15:54:47 Models will be saved to local directory:\torigtoolimgs-v1-multiclass-color-vtype\n",
            "15:54:47 Models will be saved with base name:\torigtoolimgs-v1_epoch[].pth\n",
            "15:54:47 Optimizers will be saved with base name:\torigtoolimgs-v1_epoch[]_optimizer.pth\n",
            "15:54:47 Schedulers will be saved with base name:\torigtoolimgs-v1_epoch[]_scheduler.pth\n",
            "15:54:47 Performing initial evaluation...\n",
            "15:54:48 Obtained features, validation in progress\n",
            "15:54:48 Metrics\tcolorloss\ttypeloss\n",
            "15:54:48 Accuracy\tcolor: 0.012\tvtype: 0.235\n",
            "15:54:48 M F-Score\tcolor: 0.012\tvtype: 0.235\n",
            "15:54:48 W F-Score\tcolor: 0.013\tvtype: 0.089\n",
            "15:54:48 Starting training from 0\n",
            "15:54:49 Parameter Group `opt-1`: Starting epoch 0 with 20 steps and learning rate 1.00000E-05\n",
            "15:54:56 ********** Completed epoch 0 **********\n",
            "15:54:56 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "15:54:56 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "15:54:56 Parameter Group `opt-1`: Starting epoch 1 with 20 steps and learning rate 1.00000E-05\n",
            "15:54:57 Evaluating model at test-frequency\n",
            "15:54:59 Obtained features, validation in progress\n",
            "15:54:59 Metrics\tcolorloss\ttypeloss\n",
            "15:54:59 Accuracy\tcolor: 0.198\tvtype: 0.346\n",
            "15:54:59 M F-Score\tcolor: 0.198\tvtype: 0.346\n",
            "15:54:59 W F-Score\tcolor: 0.230\tvtype: 0.335\n",
            "15:54:59 Saving model at save-frequency, at epoch 0, step 0\n",
            "15:54:59 Saving model, optimizer, and scheduler.\n",
            "15:55:03 ********** Completed epoch 1 **********\n",
            "15:55:03 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "15:55:03 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "15:55:04 Parameter Group `opt-1`: Starting epoch 2 with 20 steps and learning rate 1.00000E-05\n",
            "15:55:04 Evaluating model at test-frequency\n",
            "15:55:07 Obtained features, validation in progress\n",
            "15:55:07 Metrics\tcolorloss\ttypeloss\n",
            "15:55:07 Accuracy\tcolor: 0.383\tvtype: 0.481\n",
            "15:55:07 M F-Score\tcolor: 0.383\tvtype: 0.481\n",
            "15:55:07 W F-Score\tcolor: 0.386\tvtype: 0.470\n",
            "15:55:07 Saving model at save-frequency, at epoch 1, step 0\n",
            "15:55:07 Saving model, optimizer, and scheduler.\n",
            "15:55:11 ********** Completed epoch 2 **********\n",
            "15:55:11 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "15:55:11 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "15:55:12 Parameter Group `opt-1`: Starting epoch 3 with 20 steps and learning rate 1.00000E-05\n",
            "15:55:12 Evaluating model at test-frequency\n",
            "15:55:14 Obtained features, validation in progress\n",
            "15:55:14 Metrics\tcolorloss\ttypeloss\n",
            "15:55:14 Accuracy\tcolor: 0.494\tvtype: 0.531\n",
            "15:55:14 M F-Score\tcolor: 0.494\tvtype: 0.531\n",
            "15:55:14 W F-Score\tcolor: 0.478\tvtype: 0.524\n",
            "15:55:14 Saving model at save-frequency, at epoch 2, step 0\n",
            "15:55:14 Saving model, optimizer, and scheduler.\n",
            "15:55:19 ********** Completed epoch 3 **********\n",
            "15:55:19 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "15:55:19 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "15:55:20 Parameter Group `opt-1`: Starting epoch 4 with 20 steps and learning rate 1.00000E-05\n",
            "15:55:21 Evaluating model at test-frequency\n",
            "15:55:23 Obtained features, validation in progress\n",
            "15:55:23 Metrics\tcolorloss\ttypeloss\n",
            "15:55:23 Accuracy\tcolor: 0.605\tvtype: 0.568\n",
            "15:55:23 M F-Score\tcolor: 0.605\tvtype: 0.568\n",
            "15:55:23 W F-Score\tcolor: 0.603\tvtype: 0.562\n",
            "15:55:23 Saving model at save-frequency, at epoch 3, step 0\n",
            "15:55:23 Saving model, optimizer, and scheduler.\n",
            "15:55:27 ********** Completed epoch 4 **********\n",
            "15:55:27 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "15:55:27 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "15:55:28 Parameter Group `opt-1`: Starting epoch 5 with 20 steps and learning rate 1.00000E-05\n",
            "15:55:28 Evaluating model at test-frequency\n",
            "15:55:30 Obtained features, validation in progress\n",
            "15:55:30 Metrics\tcolorloss\ttypeloss\n",
            "15:55:30 Accuracy\tcolor: 0.630\tvtype: 0.580\n",
            "15:55:30 M F-Score\tcolor: 0.630\tvtype: 0.580\n",
            "15:55:30 W F-Score\tcolor: 0.619\tvtype: 0.568\n",
            "15:55:30 Saving model at save-frequency, at epoch 4, step 0\n",
            "15:55:30 Saving model, optimizer, and scheduler.\n",
            "15:55:35 ********** Completed epoch 5 **********\n",
            "15:55:35 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "15:55:35 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "15:55:36 Parameter Group `opt-1`: Starting epoch 6 with 20 steps and learning rate 1.00000E-05\n",
            "15:55:36 Evaluating model at test-frequency\n",
            "15:55:38 Obtained features, validation in progress\n",
            "15:55:38 Metrics\tcolorloss\ttypeloss\n",
            "15:55:38 Accuracy\tcolor: 0.642\tvtype: 0.642\n",
            "15:55:38 M F-Score\tcolor: 0.642\tvtype: 0.642\n",
            "15:55:38 W F-Score\tcolor: 0.633\tvtype: 0.613\n",
            "15:55:38 Saving model at save-frequency, at epoch 5, step 0\n",
            "15:55:38 Saving model, optimizer, and scheduler.\n",
            "15:55:43 ********** Completed epoch 6 **********\n",
            "15:55:43 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "15:55:43 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "15:55:44 Parameter Group `opt-1`: Starting epoch 7 with 20 steps and learning rate 1.00000E-05\n",
            "15:55:44 Evaluating model at test-frequency\n",
            "15:55:46 Obtained features, validation in progress\n",
            "15:55:46 Metrics\tcolorloss\ttypeloss\n",
            "15:55:46 Accuracy\tcolor: 0.642\tvtype: 0.642\n",
            "15:55:46 M F-Score\tcolor: 0.642\tvtype: 0.642\n",
            "15:55:46 W F-Score\tcolor: 0.609\tvtype: 0.609\n",
            "15:55:46 Saving model at save-frequency, at epoch 6, step 0\n",
            "15:55:46 Saving model, optimizer, and scheduler.\n",
            "15:55:51 ********** Completed epoch 7 **********\n",
            "15:55:51 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "15:55:51 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "15:55:52 Parameter Group `opt-1`: Starting epoch 8 with 20 steps and learning rate 1.00000E-05\n",
            "15:55:53 Evaluating model at test-frequency\n",
            "15:55:54 Obtained features, validation in progress\n",
            "15:55:54 Metrics\tcolorloss\ttypeloss\n",
            "15:55:54 Accuracy\tcolor: 0.667\tvtype: 0.654\n",
            "15:55:54 M F-Score\tcolor: 0.667\tvtype: 0.654\n",
            "15:55:54 W F-Score\tcolor: 0.629\tvtype: 0.620\n",
            "15:55:54 Saving model at save-frequency, at epoch 7, step 0\n",
            "15:55:54 Saving model, optimizer, and scheduler.\n",
            "15:56:00 ********** Completed epoch 8 **********\n",
            "15:56:00 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "15:56:00 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "15:56:00 Parameter Group `opt-1`: Starting epoch 9 with 20 steps and learning rate 1.00000E-05\n",
            "15:56:01 Evaluating model at test-frequency\n",
            "15:56:03 Obtained features, validation in progress\n",
            "15:56:03 Metrics\tcolorloss\ttypeloss\n",
            "15:56:03 Accuracy\tcolor: 0.679\tvtype: 0.654\n",
            "15:56:03 M F-Score\tcolor: 0.679\tvtype: 0.654\n",
            "15:56:03 W F-Score\tcolor: 0.641\tvtype: 0.619\n",
            "15:56:03 Saving model at save-frequency, at epoch 8, step 0\n",
            "15:56:03 Saving model, optimizer, and scheduler.\n",
            "15:56:07 ********** Completed epoch 9 **********\n",
            "15:56:07 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "15:56:07 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "15:56:08 Parameter Group `opt-1`: Starting epoch 10 with 20 steps and learning rate 1.00000E-05\n",
            "15:56:08 Evaluating model at test-frequency\n",
            "15:56:10 Obtained features, validation in progress\n",
            "15:56:10 Metrics\tcolorloss\ttypeloss\n",
            "15:56:10 Accuracy\tcolor: 0.679\tvtype: 0.654\n",
            "15:56:10 M F-Score\tcolor: 0.679\tvtype: 0.654\n",
            "15:56:10 W F-Score\tcolor: 0.637\tvtype: 0.617\n",
            "15:56:10 Saving model at save-frequency, at epoch 9, step 0\n",
            "15:56:10 Saving model, optimizer, and scheduler.\n",
            "15:56:15 ********** Completed epoch 10 **********\n",
            "15:56:15 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "15:56:15 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "15:56:15 Final: Evaluating model at test-frequency\n",
            "15:56:16 Obtained features, validation in progress\n",
            "15:56:16 Metrics\tcolorloss\ttypeloss\n",
            "15:56:16 Accuracy\tcolor: 0.716\tvtype: 0.679\n",
            "15:56:16 M F-Score\tcolor: 0.716\tvtype: 0.679\n",
            "15:56:16 W F-Score\tcolor: 0.679\tvtype: 0.660\n",
            "15:56:16 Final: Saving model at save-frequency\n",
            "15:56:16 Saving model, optimizer, and scheduler.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resp = eml.eval()"
      ],
      "metadata": {
        "id": "up7UiM347TDi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a236a000-605b-4fb5-ced0-3d1b7d748bb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "15:56:18 Obtained features, validation in progress\n",
            "15:56:18 Metrics\tcolorloss\ttypeloss\n",
            "15:56:18 Accuracy\tcolor: 0.716\tvtype: 0.679\n",
            "15:56:18 M F-Score\tcolor: 0.716\tvtype: 0.679\n",
            "15:56:18 W F-Score\tcolor: 0.679\tvtype: 0.660\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.2 Multi-class classification (color-type-make)\n",
        "\n",
        "Now we will try a model that performs vehicle type vehicle color, and vehicle make classification together. The config is already prepared for this in `profiles/color_type_make.yml`\n",
        "\n",
        "Our architecture now looks like:\n",
        "\n",
        "[<img src=\"https://i.redd.it/8sbfqblq4yx91.png\" width=\"550\"/>]"
      ],
      "metadata": {
        "id": "2RJMxoSR7TJr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_idx = 0          # Change this to whichever index in tuple has path\n",
        "crawler_args = {\"file_name\" : \"original_tool_image.zip\"}"
      ],
      "metadata": {
        "id": "uuFxyayo7TJr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "metadata": {
        "id": "vdWCXSU47TJr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "907890ce-639f-4788-bb70-371da7dd8cb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ednaml.core import EdnaML\n",
        "from ednaml.generators import ClassificationGenerator\n",
        "\n",
        "eml = EdnaML(config = [\"./GLAMOR/profiles/CarZam/base_config.yml\",\"./GLAMOR/profiles/CarZam/color_type_make.yml\"])\n",
        "\n",
        "eml.cfg.EXECUTION.DATAREADER.CRAWLER_ARGS = crawler_args\n",
        "eml.cfg.EXECUTION.DATAREADER.DATASET_ARGS[\"pathidx\"] = path_idx\n",
        "# We have already set these in config\n",
        "#eml.cfg.EXECUTION.DATAREADER.DATASET_ARGS[\"annotationidx\"] = class_idx\n",
        "#eml.cfg.EXECUTION.DATAREADER.DATASET_ARGS[\"classificationclass\"] = class_name\n",
        "\n",
        "#eml.addGeneratorClass(ClassificationGenerator)\n",
        "eml.addCrawlerClass(CarZamCrawler)"
      ],
      "metadata": {
        "id": "slDsr0mt7TJr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eml.apply()"
      ],
      "metadata": {
        "id": "klZiqCpg7TJr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a97c26d-e768-4996-f37c-5f8460dde373"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "15:56:18 ****************************************\n",
            "15:56:18 \n",
            "15:56:18 \n",
            "15:56:18 Using the following configuration:\n",
            "15:56:18 DEPLOYMENT:\n",
            "  DATAREADER:\n",
            "    CRAWLER_ARGS: {}\n",
            "    DATAREADER: DataReader\n",
            "    DATASET_ARGS: {}\n",
            "    GENERATOR: null\n",
            "    GENERATOR_ARGS: {}\n",
            "  DEPLOY: BaseDeploy\n",
            "  DEPLOYMENT_ARGS: {}\n",
            "  EPOCHS: 1\n",
            "  OUTPUT_ARGS: {}\n",
            "  PLUGIN:\n",
            "    HOOKS: always\n",
            "    RESET: false\n",
            "EXECUTION:\n",
            "  DATAREADER:\n",
            "    CRAWLER_ARGS:\n",
            "      file_name: original_tool_image.zip\n",
            "    DATAREADER: DataReader\n",
            "    DATASET_ARGS:\n",
            "      annotationidx:\n",
            "      - 2\n",
            "      - 1\n",
            "      - 4\n",
            "      classificationclass:\n",
            "      - color\n",
            "      - vtype\n",
            "      - make\n",
            "      pathidx: 0\n",
            "    GENERATOR: MultiClassificationGenerator\n",
            "    GENERATOR_ARGS: {}\n",
            "  EPOCHS: 10\n",
            "  FP16: false\n",
            "  MODEL_SERVING: Unused\n",
            "  OPTIMIZER_BUILDER: ClassificationOptimizer\n",
            "  PLUGIN:\n",
            "    HOOKS: always\n",
            "    RESET: false\n",
            "  SKIPEVAL: false\n",
            "  TEST_FREQUENCY: 1\n",
            "  TRAINER: MultiClassificationTrainer\n",
            "  TRAINER_ARGS:\n",
            "    accumulation_steps: 4\n",
            "LOGGING:\n",
            "  INPUT_SIZE: null\n",
            "  STEP_VERBOSE: 100\n",
            "LOSS:\n",
            "- KWARGS:\n",
            "  - {}\n",
            "  LABEL: color\n",
            "  LAMBDAS:\n",
            "  - 1.0\n",
            "  LOSSES:\n",
            "  - SoftmaxLogitsLoss\n",
            "  NAME: colorloss\n",
            "- KWARGS:\n",
            "  - {}\n",
            "  LABEL: vtype\n",
            "  LAMBDAS:\n",
            "  - 1.0\n",
            "  LOSSES:\n",
            "  - SoftmaxLogitsLoss\n",
            "  NAME: typeloss\n",
            "- KWARGS:\n",
            "  - {}\n",
            "  LABEL: make\n",
            "  LAMBDAS:\n",
            "  - 1.0\n",
            "  LOSSES:\n",
            "  - SoftmaxLogitsLoss\n",
            "  NAME: makeloss\n",
            "LOSS_OPTIMIZER:\n",
            "- BASE_LR: 0.001\n",
            "  LR_BIAS_FACTOR: 1.0\n",
            "  OPTIMIZER: Adam\n",
            "  OPTIMIZER_KWARGS: {}\n",
            "  OPTIMIZER_NAME: opt-1\n",
            "  WEIGHT_BIAS_FACTOR: 0.0005\n",
            "  WEIGHT_DECAY: 0.0005\n",
            "LOSS_SCHEDULER:\n",
            "- LR_KWARGS:\n",
            "    step_size: 20\n",
            "  LR_SCHEDULER: StepLR\n",
            "  SCHEDULER_NAME: opt-1\n",
            "MODEL:\n",
            "  BUILDER: multiclassification_model_builder\n",
            "  MODEL_ARCH: MultiClassificationResnet\n",
            "  MODEL_BASE: resnet18\n",
            "  MODEL_KWARGS:\n",
            "    number_outputs: 3\n",
            "    outputs:\n",
            "    - dimensions: null\n",
            "      label: vtype\n",
            "      name: type\n",
            "    - dimensions: null\n",
            "      label: color\n",
            "      name: out2\n",
            "    - dimensions: null\n",
            "      label: make\n",
            "      name: makeout\n",
            "  MODEL_NORMALIZATION: bn\n",
            "  PARAMETER_GROUPS:\n",
            "  - opt-1\n",
            "MODEL_PLUGIN: {}\n",
            "OPTIMIZER:\n",
            "- BASE_LR: 1.0e-05\n",
            "  LR_BIAS_FACTOR: 1.0\n",
            "  OPTIMIZER: Adam\n",
            "  OPTIMIZER_KWARGS: {}\n",
            "  OPTIMIZER_NAME: opt-1\n",
            "  WEIGHT_BIAS_FACTOR: 0.0005\n",
            "  WEIGHT_DECAY: 0.0005\n",
            "SAVE:\n",
            "  CHECKPOINT_DIRECTORY: checkpoint\n",
            "  DRIVE_BACKUP: false\n",
            "  LOG_BACKUP: false\n",
            "  MODEL_BACKBONE: multiclass\n",
            "  MODEL_CORE_NAME: origtoolimgs\n",
            "  MODEL_QUALIFIER: color-vtype-make\n",
            "  MODEL_VERSION: 1\n",
            "  SAVE_FREQUENCY: 1\n",
            "  STEP_SAVE_FREQUENCY: 0\n",
            "SCHEDULER:\n",
            "- LR_KWARGS:\n",
            "    gamma: 0.1\n",
            "    step_size: 20\n",
            "  LR_SCHEDULER: StepLR\n",
            "  SCHEDULER_NAME: opt-1\n",
            "STORAGE:\n",
            "  STORAGE_ARGS: {}\n",
            "  TYPE: BaseStorage\n",
            "  URL: ./\n",
            "TEST_TRANSFORMATION:\n",
            "  ARGS:\n",
            "    channels: 3\n",
            "    i_shape:\n",
            "    - 200\n",
            "    - 200\n",
            "    normalization_mean: 0.5\n",
            "    normalization_scale: 0.5\n",
            "    normalization_std: 0.5\n",
            "  BATCH_SIZE: 32\n",
            "  WORKERS: 2\n",
            "TRAIN_TRANSFORMATION:\n",
            "  ARGS:\n",
            "    channels: 3\n",
            "    h_flip: 0.5\n",
            "    i_shape:\n",
            "    - 200\n",
            "    - 200\n",
            "    normalization_mean: 0.5\n",
            "    normalization_scale: 0.5\n",
            "    normalization_std: 0.5\n",
            "    random_erase: true\n",
            "    random_erase_value: 0.3\n",
            "    t_crop: true\n",
            "  BATCH_SIZE: 32\n",
            "  WORKERS: 2\n",
            "extensions:\n",
            "- EXECUTION\n",
            "- SAVE\n",
            "- STORAGE\n",
            "- TRANSFORMATION\n",
            "- MODEL\n",
            "- LOSS\n",
            "- OPTIMIZER\n",
            "- SCHEDULER\n",
            "- LOSS_OPTIMIZER\n",
            "- LOSS_SCHEDULER\n",
            "- LOGGING\n",
            "- DEPLOYMENT\n",
            "- MODEL_PLUGIN\n",
            "\n",
            "15:56:18 \n",
            "15:56:18 \n",
            "15:56:18 ****************************************\n",
            "15:56:18 No previous stop detected. Will start from epoch 0\n",
            "15:56:18 Loaded BaseStorage from ednaml.storage to build Storage\n",
            "15:56:18 Reading data with DataReader DataReader\n",
            "15:56:18 Default CRAWLER is <class 'ednaml.crawlers.Crawler'>\n",
            "15:56:18 Default DATASET is <class 'torch.utils.data.dataset.Dataset'>\n",
            "15:56:18 Default GENERATOR is <class 'ednaml.generators.ImageGenerator.ImageGenerator'>\n",
            "15:56:18 Updating GENERATOR using config specification to MultiClassificationGenerator\n",
            "15:56:18 Updating CRAWLER to CarZamCrawler\n",
            "15:56:18 Generated training data generator with 648 training data points\n",
            "15:56:18 Running classification model with classes: {'color': {'classes': 13}, 'vtype': {'classes': 5}, 'make': {'classes': 34}}\n",
            "15:56:18 Generated test data/query generator\n",
            "15:56:18 Loaded multiclassification_model_builder from ednaml.models to build model\n",
            "15:56:18 Finished instantiating model with MultiClassificationResnet architecture\n",
            "15:56:18 Adding plugins after constructing model\n",
            "15:56:18 No saved model weights provided.\n",
            "15:56:18 Model Summary retured the following error:\n",
            "15:56:18 Traceback (most recent call last):\n",
            "  File \"/content/GLAMOR/src/ednaml/core/EdnaML.py\", line 888, in getModelSummary\n",
            "    self.cfg.TRAIN_TRANSFORMATION.INPUT_SIZE,\n",
            "AttributeError: 'TransformationConfig' object has no attribute 'INPUT_SIZE'\n",
            "\n",
            "15:56:18 Loaded ClassificationOptimizer from ednaml.optimizer to build Optimizer model\n",
            "15:56:18 Built optimizer\n",
            "15:56:18 Built scheduler\n",
            "15:56:18 Added SoftmaxLogitsLoss with lambda = 1.0 and loss arguments {}\n",
            "15:56:18 Added SoftmaxLogitsLoss with lambda = 1.0 and loss arguments {}\n",
            "15:56:18 Added SoftmaxLogitsLoss with lambda = 1.0 and loss arguments {}\n",
            "15:56:18 Built loss function\n",
            "15:56:18 Built loss optimizer\n",
            "15:56:18 Built loss scheduler\n",
            "15:56:18 Built loss scheduler\n",
            "15:56:18 Built loss scheduler\n",
            "15:56:18 Loaded BaseStorage from ednaml.storage to build Storage\n",
            "15:56:18 Loaded MultiClassificationTrainer from ednaml.trainer to build Trainer\n",
            "15:56:18 Saving model metadata\n",
            "15:56:18 Backing up metadata\n",
            "15:56:18 Finished metadata backup\n",
            "15:56:18 1 GPUs available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eml.train()"
      ],
      "metadata": {
        "id": "hLchTC897TJr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c941eda-344c-4aca-9b95-4143edc5eb59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "15:56:18 Starting training\n",
            "15:56:18 Logging to:\torigtoolimgs-v1-multiclass-color-vtype-make-logger.log\n",
            "15:56:18 Models will be saved to local directory:\torigtoolimgs-v1-multiclass-color-vtype-make\n",
            "15:56:18 Models will be saved with base name:\torigtoolimgs-v1_epoch[].pth\n",
            "15:56:18 Optimizers will be saved with base name:\torigtoolimgs-v1_epoch[]_optimizer.pth\n",
            "15:56:18 Schedulers will be saved with base name:\torigtoolimgs-v1_epoch[]_scheduler.pth\n",
            "15:56:18 Performing initial evaluation...\n",
            "15:56:19 Obtained features, validation in progress\n",
            "15:56:19 Metrics\tcolorloss\ttypeloss\tmakeloss\n",
            "15:56:19 Accuracy\tcolor: 0.272\tvtype: 0.185\tmake: 0.012\n",
            "15:56:19 M F-Score\tcolor: 0.272\tvtype: 0.185\tmake: 0.012\n",
            "15:56:19 W F-Score\tcolor: 0.117\tvtype: 0.103\tmake: 0.002\n",
            "15:56:19 Starting training from 0\n",
            "15:56:20 Parameter Group `opt-1`: Starting epoch 0 with 20 steps and learning rate 1.00000E-05\n",
            "15:56:27 ********** Completed epoch 0 **********\n",
            "15:56:27 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "15:56:27 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "15:56:27 Parameter Group `opt-1`: Starting epoch 1 with 20 steps and learning rate 1.00000E-05\n",
            "15:56:28 Evaluating model at test-frequency\n",
            "15:56:29 Obtained features, validation in progress\n",
            "15:56:29 Metrics\tcolorloss\ttypeloss\tmakeloss\n",
            "15:56:30 Accuracy\tcolor: 0.296\tvtype: 0.247\tmake: 0.025\n",
            "15:56:30 M F-Score\tcolor: 0.296\tvtype: 0.247\tmake: 0.025\n",
            "15:56:30 W F-Score\tcolor: 0.344\tvtype: 0.284\tmake: 0.028\n",
            "15:56:30 Saving model at save-frequency, at epoch 0, step 0\n",
            "15:56:30 Saving model, optimizer, and scheduler.\n",
            "15:56:34 ********** Completed epoch 1 **********\n",
            "15:56:34 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "15:56:34 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "15:56:34 Parameter Group `opt-1`: Starting epoch 2 with 20 steps and learning rate 1.00000E-05\n",
            "15:56:35 Evaluating model at test-frequency\n",
            "15:56:37 Obtained features, validation in progress\n",
            "15:56:37 Metrics\tcolorloss\ttypeloss\tmakeloss\n",
            "15:56:37 Accuracy\tcolor: 0.543\tvtype: 0.469\tmake: 0.037\n",
            "15:56:37 M F-Score\tcolor: 0.543\tvtype: 0.469\tmake: 0.037\n",
            "15:56:37 W F-Score\tcolor: 0.589\tvtype: 0.473\tmake: 0.045\n",
            "15:56:37 Saving model at save-frequency, at epoch 1, step 0\n",
            "15:56:37 Saving model, optimizer, and scheduler.\n",
            "15:56:42 ********** Completed epoch 2 **********\n",
            "15:56:42 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "15:56:42 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "15:56:43 Parameter Group `opt-1`: Starting epoch 3 with 20 steps and learning rate 1.00000E-05\n",
            "15:56:43 Evaluating model at test-frequency\n",
            "15:56:45 Obtained features, validation in progress\n",
            "15:56:45 Metrics\tcolorloss\ttypeloss\tmakeloss\n",
            "15:56:45 Accuracy\tcolor: 0.654\tvtype: 0.506\tmake: 0.086\n",
            "15:56:45 M F-Score\tcolor: 0.654\tvtype: 0.506\tmake: 0.086\n",
            "15:56:45 W F-Score\tcolor: 0.670\tvtype: 0.507\tmake: 0.103\n",
            "15:56:45 Saving model at save-frequency, at epoch 2, step 0\n",
            "15:56:45 Saving model, optimizer, and scheduler.\n",
            "15:56:50 ********** Completed epoch 3 **********\n",
            "15:56:50 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "15:56:50 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "15:56:51 Parameter Group `opt-1`: Starting epoch 4 with 20 steps and learning rate 1.00000E-05\n",
            "15:56:52 Evaluating model at test-frequency\n",
            "15:56:54 Obtained features, validation in progress\n",
            "15:56:54 Metrics\tcolorloss\ttypeloss\tmakeloss\n",
            "15:56:54 Accuracy\tcolor: 0.728\tvtype: 0.556\tmake: 0.086\n",
            "15:56:54 M F-Score\tcolor: 0.728\tvtype: 0.556\tmake: 0.086\n",
            "15:56:54 W F-Score\tcolor: 0.729\tvtype: 0.551\tmake: 0.101\n",
            "15:56:54 Saving model at save-frequency, at epoch 3, step 0\n",
            "15:56:54 Saving model, optimizer, and scheduler.\n",
            "15:56:58 ********** Completed epoch 4 **********\n",
            "15:56:58 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "15:56:58 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "15:56:59 Parameter Group `opt-1`: Starting epoch 5 with 20 steps and learning rate 1.00000E-05\n",
            "15:57:00 Evaluating model at test-frequency\n",
            "15:57:01 Obtained features, validation in progress\n",
            "15:57:01 Metrics\tcolorloss\ttypeloss\tmakeloss\n",
            "15:57:01 Accuracy\tcolor: 0.741\tvtype: 0.593\tmake: 0.099\n",
            "15:57:01 M F-Score\tcolor: 0.741\tvtype: 0.593\tmake: 0.099\n",
            "15:57:01 W F-Score\tcolor: 0.743\tvtype: 0.586\tmake: 0.103\n",
            "15:57:01 Saving model at save-frequency, at epoch 4, step 0\n",
            "15:57:01 Saving model, optimizer, and scheduler.\n",
            "15:57:07 ********** Completed epoch 5 **********\n",
            "15:57:07 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "15:57:07 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "15:57:07 Parameter Group `opt-1`: Starting epoch 6 with 20 steps and learning rate 1.00000E-05\n",
            "15:57:08 Evaluating model at test-frequency\n",
            "15:57:09 Obtained features, validation in progress\n",
            "15:57:09 Metrics\tcolorloss\ttypeloss\tmakeloss\n",
            "15:57:09 Accuracy\tcolor: 0.765\tvtype: 0.605\tmake: 0.136\n",
            "15:57:09 M F-Score\tcolor: 0.765\tvtype: 0.605\tmake: 0.136\n",
            "15:57:09 W F-Score\tcolor: 0.767\tvtype: 0.588\tmake: 0.136\n",
            "15:57:09 Saving model at save-frequency, at epoch 5, step 0\n",
            "15:57:09 Saving model, optimizer, and scheduler.\n",
            "15:57:14 ********** Completed epoch 6 **********\n",
            "15:57:14 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "15:57:14 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "15:57:15 Parameter Group `opt-1`: Starting epoch 7 with 20 steps and learning rate 1.00000E-05\n",
            "15:57:15 Evaluating model at test-frequency\n",
            "15:57:17 Obtained features, validation in progress\n",
            "15:57:17 Metrics\tcolorloss\ttypeloss\tmakeloss\n",
            "15:57:17 Accuracy\tcolor: 0.802\tvtype: 0.630\tmake: 0.148\n",
            "15:57:17 M F-Score\tcolor: 0.802\tvtype: 0.630\tmake: 0.148\n",
            "15:57:17 W F-Score\tcolor: 0.802\tvtype: 0.604\tmake: 0.141\n",
            "15:57:17 Saving model at save-frequency, at epoch 6, step 0\n",
            "15:57:17 Saving model, optimizer, and scheduler.\n",
            "15:57:23 ********** Completed epoch 7 **********\n",
            "15:57:23 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "15:57:23 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "15:57:23 Parameter Group `opt-1`: Starting epoch 8 with 20 steps and learning rate 1.00000E-05\n",
            "15:57:24 Evaluating model at test-frequency\n",
            "15:57:26 Obtained features, validation in progress\n",
            "15:57:26 Metrics\tcolorloss\ttypeloss\tmakeloss\n",
            "15:57:26 Accuracy\tcolor: 0.827\tvtype: 0.642\tmake: 0.173\n",
            "15:57:26 M F-Score\tcolor: 0.827\tvtype: 0.642\tmake: 0.173\n",
            "15:57:26 W F-Score\tcolor: 0.829\tvtype: 0.623\tmake: 0.171\n",
            "15:57:26 Saving model at save-frequency, at epoch 7, step 0\n",
            "15:57:26 Saving model, optimizer, and scheduler.\n",
            "15:57:31 ********** Completed epoch 8 **********\n",
            "15:57:31 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "15:57:31 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "15:57:32 Parameter Group `opt-1`: Starting epoch 9 with 20 steps and learning rate 1.00000E-05\n",
            "15:57:32 Evaluating model at test-frequency\n",
            "15:57:34 Obtained features, validation in progress\n",
            "15:57:34 Metrics\tcolorloss\ttypeloss\tmakeloss\n",
            "15:57:34 Accuracy\tcolor: 0.827\tvtype: 0.654\tmake: 0.173\n",
            "15:57:34 M F-Score\tcolor: 0.827\tvtype: 0.654\tmake: 0.173\n",
            "15:57:34 W F-Score\tcolor: 0.820\tvtype: 0.628\tmake: 0.170\n",
            "15:57:34 Saving model at save-frequency, at epoch 8, step 0\n",
            "15:57:34 Saving model, optimizer, and scheduler.\n",
            "15:57:38 ********** Completed epoch 9 **********\n",
            "15:57:38 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "15:57:38 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "15:57:39 Parameter Group `opt-1`: Starting epoch 10 with 20 steps and learning rate 1.00000E-05\n",
            "15:57:39 Evaluating model at test-frequency\n",
            "15:57:41 Obtained features, validation in progress\n",
            "15:57:41 Metrics\tcolorloss\ttypeloss\tmakeloss\n",
            "15:57:41 Accuracy\tcolor: 0.815\tvtype: 0.654\tmake: 0.173\n",
            "15:57:41 M F-Score\tcolor: 0.815\tvtype: 0.654\tmake: 0.173\n",
            "15:57:41 W F-Score\tcolor: 0.808\tvtype: 0.628\tmake: 0.155\n",
            "15:57:41 Saving model at save-frequency, at epoch 9, step 0\n",
            "15:57:41 Saving model, optimizer, and scheduler.\n",
            "15:57:47 ********** Completed epoch 10 **********\n",
            "15:57:47 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "15:57:47 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "15:57:47 Final: Evaluating model at test-frequency\n",
            "15:57:48 Obtained features, validation in progress\n",
            "15:57:48 Metrics\tcolorloss\ttypeloss\tmakeloss\n",
            "15:57:48 Accuracy\tcolor: 0.840\tvtype: 0.679\tmake: 0.198\n",
            "15:57:48 M F-Score\tcolor: 0.840\tvtype: 0.679\tmake: 0.198\n",
            "15:57:48 W F-Score\tcolor: 0.832\tvtype: 0.657\tmake: 0.181\n",
            "15:57:48 Final: Saving model at save-frequency\n",
            "15:57:48 Saving model, optimizer, and scheduler.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resp = eml.eval()"
      ],
      "metadata": {
        "id": "W35-df3dOEil",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97658dc9-cba4-40a5-d7da-5cdcfcf944a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "15:57:49 Obtained features, validation in progress\n",
            "15:57:49 Metrics\tcolorloss\ttypeloss\tmakeloss\n",
            "15:57:49 Accuracy\tcolor: 0.840\tvtype: 0.679\tmake: 0.198\n",
            "15:57:49 M F-Score\tcolor: 0.840\tvtype: 0.679\tmake: 0.198\n",
            "15:57:49 W F-Score\tcolor: 0.832\tvtype: 0.657\tmake: 0.181\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Multibranch classification\n",
        "\n",
        "Now we will try a model that uses multiple branches, each branch for a specific label, for classification. Then we will fuse the branches to classify one more things. So total, three classifications from a single model."
      ],
      "metadata": {
        "id": "AsUQYXSm_DkY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.1 Vehicle color and type, fused to classify vehicle make\n",
        "Now we will try a model that performs vehicle type AND vehicle color classification together, using 2 different branches, and fuses the results together for make classification. The config is already prepared for this in `profiles/multibranch-ctm.yml`\n",
        "\n",
        "Our architecture looks like:\n",
        "\n",
        "[<img src=\"https://i.redd.it/q0urublq4yx91.png\" width=\"550\"/>]\n",
        "\n",
        "Here, each branch yields its own prediction, and also sends features to the fusion branch (which is the make module in our case)"
      ],
      "metadata": {
        "id": "ctIWzhbu6wzY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_idx = 0          # Change this to whichever index in tuple has path\n",
        "crawler_args = {\"file_name\" : \"original_tool_image.zip\"}"
      ],
      "metadata": {
        "id": "2SeUmdsX6wzY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "metadata": {
        "id": "IJi0_kdH6wzZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "462604f6-53ec-4785-9857-856329d990f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ednaml.core import EdnaML\n",
        "from ednaml.generators import ClassificationGenerator\n",
        "\n",
        "eml = EdnaML(config = [\"./GLAMOR/profiles/CarZam/base_config.yml\",\"./GLAMOR/profiles/CarZam/multibranch-ctm.yml\"])\n",
        "\n",
        "eml.cfg.EXECUTION.DATAREADER.CRAWLER_ARGS = crawler_args\n",
        "eml.cfg.EXECUTION.DATAREADER.DATASET_ARGS[\"pathidx\"] = path_idx\n",
        "# We have already set these in config\n",
        "#eml.cfg.EXECUTION.DATAREADER.DATASET_ARGS[\"annotationidx\"] = class_idx\n",
        "#eml.cfg.EXECUTION.DATAREADER.DATASET_ARGS[\"classificationclass\"] = class_name\n",
        "\n",
        "#eml.addGeneratorClass(ClassificationGenerator)\n",
        "eml.addCrawlerClass(CarZamCrawler)"
      ],
      "metadata": {
        "id": "bf8IEB3y6wzZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eml.apply()"
      ],
      "metadata": {
        "id": "Qzf2P3h26wzZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19b79acb-ab6f-4dad-d0fd-86225c6ade33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "15:57:49 ****************************************\n",
            "15:57:49 \n",
            "15:57:49 \n",
            "15:57:49 Using the following configuration:\n",
            "15:57:49 DEPLOYMENT:\n",
            "  DATAREADER:\n",
            "    CRAWLER_ARGS: {}\n",
            "    DATAREADER: DataReader\n",
            "    DATASET_ARGS: {}\n",
            "    GENERATOR: null\n",
            "    GENERATOR_ARGS: {}\n",
            "  DEPLOY: BaseDeploy\n",
            "  DEPLOYMENT_ARGS: {}\n",
            "  EPOCHS: 1\n",
            "  OUTPUT_ARGS: {}\n",
            "  PLUGIN:\n",
            "    HOOKS: always\n",
            "    RESET: false\n",
            "EXECUTION:\n",
            "  DATAREADER:\n",
            "    CRAWLER_ARGS:\n",
            "      file_name: original_tool_image.zip\n",
            "    DATAREADER: DataReader\n",
            "    DATASET_ARGS:\n",
            "      annotationidx:\n",
            "      - 2\n",
            "      - 1\n",
            "      - 4\n",
            "      classificationclass:\n",
            "      - color\n",
            "      - vtype\n",
            "      - make\n",
            "      pathidx: 0\n",
            "    GENERATOR: MultiClassificationGenerator\n",
            "    GENERATOR_ARGS: {}\n",
            "  EPOCHS: 10\n",
            "  FP16: false\n",
            "  MODEL_SERVING: Unused\n",
            "  OPTIMIZER_BUILDER: ClassificationOptimizer\n",
            "  PLUGIN:\n",
            "    HOOKS: always\n",
            "    RESET: false\n",
            "  SKIPEVAL: false\n",
            "  TEST_FREQUENCY: 1\n",
            "  TRAINER: MultiBranchTrainer\n",
            "  TRAINER_ARGS:\n",
            "    accumulation_steps: 4\n",
            "LOGGING:\n",
            "  INPUT_SIZE: null\n",
            "  STEP_VERBOSE: 100\n",
            "LOSS:\n",
            "- KWARGS:\n",
            "  - {}\n",
            "  LABEL: color\n",
            "  LAMBDAS:\n",
            "  - 1.0\n",
            "  LOSSES:\n",
            "  - SoftmaxLogitsLoss\n",
            "  NAME: color-fc\n",
            "- KWARGS:\n",
            "  - {}\n",
            "  LABEL: vtype\n",
            "  LAMBDAS:\n",
            "  - 1.0\n",
            "  LOSSES:\n",
            "  - SoftmaxLogitsLoss\n",
            "  NAME: type-fc\n",
            "- KWARGS:\n",
            "  - {}\n",
            "  LABEL: make\n",
            "  LAMBDAS:\n",
            "  - 1.0\n",
            "  LOSSES:\n",
            "  - SoftmaxLogitsLoss\n",
            "  NAME: fuse\n",
            "- KWARGS:\n",
            "  - {}\n",
            "  LABEL: make\n",
            "  LAMBDAS:\n",
            "  - 1.0\n",
            "  LOSSES:\n",
            "  - SoftmaxLogitsLoss\n",
            "  NAME: colorbranch\n",
            "- KWARGS:\n",
            "  - {}\n",
            "  LABEL: make\n",
            "  LAMBDAS:\n",
            "  - 1.0\n",
            "  LOSSES:\n",
            "  - SoftmaxLogitsLoss\n",
            "  NAME: typebranch\n",
            "LOSS_OPTIMIZER:\n",
            "- BASE_LR: 0.001\n",
            "  LR_BIAS_FACTOR: 1.0\n",
            "  OPTIMIZER: Adam\n",
            "  OPTIMIZER_KWARGS: {}\n",
            "  OPTIMIZER_NAME: opt-1\n",
            "  WEIGHT_BIAS_FACTOR: 0.0005\n",
            "  WEIGHT_DECAY: 0.0005\n",
            "LOSS_SCHEDULER:\n",
            "- LR_KWARGS:\n",
            "    step_size: 20\n",
            "  LR_SCHEDULER: StepLR\n",
            "  SCHEDULER_NAME: opt-1\n",
            "MODEL:\n",
            "  BUILDER: multibranch_model_builder\n",
            "  MODEL_ARCH: MultiBranchResnet\n",
            "  MODEL_BASE: resnet18\n",
            "  MODEL_KWARGS:\n",
            "    branches:\n",
            "    - name: colorbranch\n",
            "      number_outputs: 1\n",
            "      outputs:\n",
            "      - dimensions: null\n",
            "        label: color\n",
            "        name: color-fc\n",
            "    - name: typebranch\n",
            "      number_outputs: 1\n",
            "      outputs:\n",
            "      - dimensions: null\n",
            "        label: vtype\n",
            "        name: type-fc\n",
            "    fuse: true\n",
            "    fuse_dimensions: null\n",
            "    fuse_label: make\n",
            "    fuse_name: fuse\n",
            "    fuse_outputs:\n",
            "    - colorbranch\n",
            "    - typebranch\n",
            "    number_branches: 2\n",
            "    shared_block: 2\n",
            "    soft_target_branch:\n",
            "    - colorbranch\n",
            "    - typebranch\n",
            "    soft_target_output_source: fuse\n",
            "    soft_targets: true\n",
            "  MODEL_NORMALIZATION: bn\n",
            "  PARAMETER_GROUPS:\n",
            "  - opt-1\n",
            "MODEL_PLUGIN: {}\n",
            "OPTIMIZER:\n",
            "- BASE_LR: 1.0e-05\n",
            "  LR_BIAS_FACTOR: 1.0\n",
            "  OPTIMIZER: Adam\n",
            "  OPTIMIZER_KWARGS: {}\n",
            "  OPTIMIZER_NAME: opt-1\n",
            "  WEIGHT_BIAS_FACTOR: 0.0005\n",
            "  WEIGHT_DECAY: 0.0005\n",
            "SAVE:\n",
            "  CHECKPOINT_DIRECTORY: checkpoint\n",
            "  DRIVE_BACKUP: false\n",
            "  LOG_BACKUP: false\n",
            "  MODEL_BACKBONE: multibranch\n",
            "  MODEL_CORE_NAME: origtoolimgs\n",
            "  MODEL_QUALIFIER: color-vtype-make\n",
            "  MODEL_VERSION: 1\n",
            "  SAVE_FREQUENCY: 1\n",
            "  STEP_SAVE_FREQUENCY: 0\n",
            "SCHEDULER:\n",
            "- LR_KWARGS:\n",
            "    gamma: 0.1\n",
            "    step_size: 20\n",
            "  LR_SCHEDULER: StepLR\n",
            "  SCHEDULER_NAME: opt-1\n",
            "STORAGE:\n",
            "  STORAGE_ARGS: {}\n",
            "  TYPE: BaseStorage\n",
            "  URL: ./\n",
            "TEST_TRANSFORMATION:\n",
            "  ARGS:\n",
            "    channels: 3\n",
            "    i_shape:\n",
            "    - 200\n",
            "    - 200\n",
            "    normalization_mean: 0.5\n",
            "    normalization_scale: 0.5\n",
            "    normalization_std: 0.5\n",
            "  BATCH_SIZE: 32\n",
            "  WORKERS: 2\n",
            "TRAIN_TRANSFORMATION:\n",
            "  ARGS:\n",
            "    channels: 3\n",
            "    h_flip: 0.5\n",
            "    i_shape:\n",
            "    - 200\n",
            "    - 200\n",
            "    normalization_mean: 0.5\n",
            "    normalization_scale: 0.5\n",
            "    normalization_std: 0.5\n",
            "    random_erase: true\n",
            "    random_erase_value: 0.3\n",
            "    t_crop: true\n",
            "  BATCH_SIZE: 32\n",
            "  WORKERS: 2\n",
            "extensions:\n",
            "- EXECUTION\n",
            "- SAVE\n",
            "- STORAGE\n",
            "- TRANSFORMATION\n",
            "- MODEL\n",
            "- LOSS\n",
            "- OPTIMIZER\n",
            "- SCHEDULER\n",
            "- LOSS_OPTIMIZER\n",
            "- LOSS_SCHEDULER\n",
            "- LOGGING\n",
            "- DEPLOYMENT\n",
            "- MODEL_PLUGIN\n",
            "\n",
            "15:57:49 \n",
            "15:57:49 \n",
            "15:57:49 ****************************************\n",
            "15:57:49 No previous stop detected. Will start from epoch 0\n",
            "15:57:49 Loaded BaseStorage from ednaml.storage to build Storage\n",
            "15:57:49 Reading data with DataReader DataReader\n",
            "15:57:49 Default CRAWLER is <class 'ednaml.crawlers.Crawler'>\n",
            "15:57:49 Default DATASET is <class 'torch.utils.data.dataset.Dataset'>\n",
            "15:57:49 Default GENERATOR is <class 'ednaml.generators.ImageGenerator.ImageGenerator'>\n",
            "15:57:49 Updating GENERATOR using config specification to MultiClassificationGenerator\n",
            "15:57:49 Updating CRAWLER to CarZamCrawler\n",
            "15:57:49 Generated training data generator with 648 training data points\n",
            "15:57:49 Running classification model with classes: {'color': {'classes': 13}, 'vtype': {'classes': 5}, 'make': {'classes': 34}}\n",
            "15:57:49 Generated test data/query generator\n",
            "15:57:49 Loaded multibranch_model_builder from ednaml.models to build model\n",
            "15:57:50 Finished instantiating model with MultiBranchResnet architecture\n",
            "15:57:50 Adding plugins after constructing model\n",
            "15:57:50 No saved model weights provided.\n",
            "15:57:50 Model Summary retured the following error:\n",
            "15:57:50 Traceback (most recent call last):\n",
            "  File \"/content/GLAMOR/src/ednaml/core/EdnaML.py\", line 888, in getModelSummary\n",
            "    self.cfg.TRAIN_TRANSFORMATION.INPUT_SIZE,\n",
            "AttributeError: 'TransformationConfig' object has no attribute 'INPUT_SIZE'\n",
            "\n",
            "15:57:50 Loaded ClassificationOptimizer from ednaml.optimizer to build Optimizer model\n",
            "15:57:50 Built optimizer\n",
            "15:57:50 Built scheduler\n",
            "15:57:50 Added SoftmaxLogitsLoss with lambda = 1.0 and loss arguments {}\n",
            "15:57:50 Added SoftmaxLogitsLoss with lambda = 1.0 and loss arguments {}\n",
            "15:57:50 Added SoftmaxLogitsLoss with lambda = 1.0 and loss arguments {}\n",
            "15:57:50 Added SoftmaxLogitsLoss with lambda = 1.0 and loss arguments {}\n",
            "15:57:50 Added SoftmaxLogitsLoss with lambda = 1.0 and loss arguments {}\n",
            "15:57:50 Built loss function\n",
            "15:57:50 Built loss optimizer\n",
            "15:57:50 Built loss scheduler\n",
            "15:57:50 Built loss scheduler\n",
            "15:57:50 Built loss scheduler\n",
            "15:57:50 Built loss scheduler\n",
            "15:57:50 Built loss scheduler\n",
            "15:57:50 Loaded BaseStorage from ednaml.storage to build Storage\n",
            "15:57:50 Loaded MultiBranchTrainer from ednaml.trainer to build Trainer\n",
            "15:57:50 Saving model metadata\n",
            "15:57:50 Backing up metadata\n",
            "15:57:50 Finished metadata backup\n",
            "15:57:50 1 GPUs available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eml.train()"
      ],
      "metadata": {
        "id": "LN5jDtyG6wzZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c4892dd-e8c5-482a-ca88-48e3a2dbafd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "15:57:50 Starting training\n",
            "15:57:50 Logging to:\torigtoolimgs-v1-multibranch-color-vtype-make-logger.log\n",
            "15:57:50 Models will be saved to local directory:\torigtoolimgs-v1-multibranch-color-vtype-make\n",
            "15:57:50 Models will be saved with base name:\torigtoolimgs-v1_epoch[].pth\n",
            "15:57:50 Optimizers will be saved with base name:\torigtoolimgs-v1_epoch[]_optimizer.pth\n",
            "15:57:50 Schedulers will be saved with base name:\torigtoolimgs-v1_epoch[]_scheduler.pth\n",
            "15:57:50 Performing initial evaluation...\n",
            "15:57:51 Obtained features, validation in progress\n",
            "15:57:51 Metrics\tcolor-fc\ttype-fc\tfuse\tcolorbranch\ttypebranch\n",
            "15:57:51 Accuracy\tcolor-fc: 0.160\ttype-fc: 0.123\tfuse: 0.037\tcolorbranch: 0.012\ttypebranch: 0.012\n",
            "15:57:51 M F-Score\tcolor-fc: 0.160\ttype-fc: 0.123\tfuse: 0.037\tcolorbranch: 0.012\ttypebranch: 0.012\n",
            "15:57:51 W F-Score\tcolor-fc: 0.102\ttype-fc: 0.096\tfuse: 0.018\tcolorbranch: 0.020\ttypebranch: 0.000\n",
            "15:57:51 Starting training from 0\n",
            "15:57:52 Parameter Group `opt-1`: Starting epoch 0 with 20 steps and learning rate 1.00000E-05\n",
            "15:57:59 ********** Completed epoch 0 **********\n",
            "15:57:59 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "15:57:59 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "15:58:00 Parameter Group `opt-1`: Starting epoch 1 with 20 steps and learning rate 1.00000E-05\n",
            "15:58:01 Evaluating model at test-frequency\n",
            "15:58:02 Obtained features, validation in progress\n",
            "15:58:02 Metrics\tcolor-fc\ttype-fc\tfuse\tcolorbranch\ttypebranch\n",
            "15:58:02 Accuracy\tcolor-fc: 0.296\ttype-fc: 0.395\tfuse: 0.049\tcolorbranch: 0.025\ttypebranch: 0.049\n",
            "15:58:02 M F-Score\tcolor-fc: 0.296\ttype-fc: 0.395\tfuse: 0.049\tcolorbranch: 0.025\ttypebranch: 0.049\n",
            "15:58:02 W F-Score\tcolor-fc: 0.331\ttype-fc: 0.346\tfuse: 0.060\tcolorbranch: 0.015\ttypebranch: 0.076\n",
            "15:58:02 Saving model at save-frequency, at epoch 0, step 0\n",
            "15:58:02 Saving model, optimizer, and scheduler.\n",
            "15:58:07 ********** Completed epoch 1 **********\n",
            "15:58:07 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "15:58:07 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "15:58:09 Parameter Group `opt-1`: Starting epoch 2 with 20 steps and learning rate 1.00000E-05\n",
            "15:58:09 Evaluating model at test-frequency\n",
            "15:58:11 Obtained features, validation in progress\n",
            "15:58:11 Metrics\tcolor-fc\ttype-fc\tfuse\tcolorbranch\ttypebranch\n",
            "15:58:11 Accuracy\tcolor-fc: 0.420\ttype-fc: 0.444\tfuse: 0.148\tcolorbranch: 0.012\ttypebranch: 0.037\n",
            "15:58:11 M F-Score\tcolor-fc: 0.420\ttype-fc: 0.444\tfuse: 0.148\tcolorbranch: 0.012\ttypebranch: 0.037\n",
            "15:58:11 W F-Score\tcolor-fc: 0.470\ttype-fc: 0.423\tfuse: 0.148\tcolorbranch: 0.008\ttypebranch: 0.040\n",
            "15:58:11 Saving model at save-frequency, at epoch 1, step 0\n",
            "15:58:11 Saving model, optimizer, and scheduler.\n",
            "15:58:16 ********** Completed epoch 2 **********\n",
            "15:58:16 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "15:58:16 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "15:58:17 Parameter Group `opt-1`: Starting epoch 3 with 20 steps and learning rate 1.00000E-05\n",
            "15:58:17 Evaluating model at test-frequency\n",
            "15:58:19 Obtained features, validation in progress\n",
            "15:58:19 Metrics\tcolor-fc\ttype-fc\tfuse\tcolorbranch\ttypebranch\n",
            "15:58:19 Accuracy\tcolor-fc: 0.556\ttype-fc: 0.519\tfuse: 0.210\tcolorbranch: 0.025\ttypebranch: 0.074\n",
            "15:58:19 M F-Score\tcolor-fc: 0.556\ttype-fc: 0.519\tfuse: 0.210\tcolorbranch: 0.025\ttypebranch: 0.074\n",
            "15:58:19 W F-Score\tcolor-fc: 0.581\ttype-fc: 0.487\tfuse: 0.207\tcolorbranch: 0.024\ttypebranch: 0.081\n",
            "15:58:19 Saving model at save-frequency, at epoch 2, step 0\n",
            "15:58:19 Saving model, optimizer, and scheduler.\n",
            "15:58:25 ********** Completed epoch 3 **********\n",
            "15:58:25 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "15:58:25 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "15:58:26 Parameter Group `opt-1`: Starting epoch 4 with 20 steps and learning rate 1.00000E-05\n",
            "15:58:27 Evaluating model at test-frequency\n",
            "15:58:29 Obtained features, validation in progress\n",
            "15:58:29 Metrics\tcolor-fc\ttype-fc\tfuse\tcolorbranch\ttypebranch\n",
            "15:58:29 Accuracy\tcolor-fc: 0.654\ttype-fc: 0.568\tfuse: 0.198\tcolorbranch: 0.062\ttypebranch: 0.111\n",
            "15:58:29 M F-Score\tcolor-fc: 0.654\ttype-fc: 0.568\tfuse: 0.198\tcolorbranch: 0.062\ttypebranch: 0.111\n",
            "15:58:29 W F-Score\tcolor-fc: 0.661\ttype-fc: 0.530\tfuse: 0.193\tcolorbranch: 0.061\ttypebranch: 0.120\n",
            "15:58:29 Saving model at save-frequency, at epoch 3, step 0\n",
            "15:58:29 Saving model, optimizer, and scheduler.\n",
            "15:58:34 ********** Completed epoch 4 **********\n",
            "15:58:34 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "15:58:34 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "15:58:35 Parameter Group `opt-1`: Starting epoch 5 with 20 steps and learning rate 1.00000E-05\n",
            "15:58:36 Evaluating model at test-frequency\n",
            "15:58:37 Obtained features, validation in progress\n",
            "15:58:37 Metrics\tcolor-fc\ttype-fc\tfuse\tcolorbranch\ttypebranch\n",
            "15:58:37 Accuracy\tcolor-fc: 0.691\ttype-fc: 0.605\tfuse: 0.235\tcolorbranch: 0.086\ttypebranch: 0.148\n",
            "15:58:37 M F-Score\tcolor-fc: 0.691\ttype-fc: 0.605\tfuse: 0.235\tcolorbranch: 0.086\ttypebranch: 0.148\n",
            "15:58:37 W F-Score\tcolor-fc: 0.690\ttype-fc: 0.573\tfuse: 0.210\tcolorbranch: 0.092\ttypebranch: 0.157\n",
            "15:58:37 Saving model at save-frequency, at epoch 4, step 0\n",
            "15:58:37 Saving model, optimizer, and scheduler.\n",
            "15:58:42 ********** Completed epoch 5 **********\n",
            "15:58:42 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "15:58:42 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "15:58:43 Parameter Group `opt-1`: Starting epoch 6 with 20 steps and learning rate 1.00000E-05\n",
            "15:58:43 Evaluating model at test-frequency\n",
            "15:58:45 Obtained features, validation in progress\n",
            "15:58:45 Metrics\tcolor-fc\ttype-fc\tfuse\tcolorbranch\ttypebranch\n",
            "15:58:45 Accuracy\tcolor-fc: 0.716\ttype-fc: 0.605\tfuse: 0.284\tcolorbranch: 0.123\ttypebranch: 0.185\n",
            "15:58:45 M F-Score\tcolor-fc: 0.716\ttype-fc: 0.605\tfuse: 0.284\tcolorbranch: 0.123\ttypebranch: 0.185\n",
            "15:58:45 W F-Score\tcolor-fc: 0.716\ttype-fc: 0.569\tfuse: 0.261\tcolorbranch: 0.139\ttypebranch: 0.172\n",
            "15:58:45 Saving model at save-frequency, at epoch 5, step 0\n",
            "15:58:45 Saving model, optimizer, and scheduler.\n",
            "15:58:51 ********** Completed epoch 6 **********\n",
            "15:58:51 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "15:58:51 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "15:58:52 Parameter Group `opt-1`: Starting epoch 7 with 20 steps and learning rate 1.00000E-05\n",
            "15:58:52 Evaluating model at test-frequency\n",
            "15:58:54 Obtained features, validation in progress\n",
            "15:58:54 Metrics\tcolor-fc\ttype-fc\tfuse\tcolorbranch\ttypebranch\n",
            "15:58:54 Accuracy\tcolor-fc: 0.753\ttype-fc: 0.580\tfuse: 0.296\tcolorbranch: 0.136\ttypebranch: 0.210\n",
            "15:58:54 M F-Score\tcolor-fc: 0.753\ttype-fc: 0.580\tfuse: 0.296\tcolorbranch: 0.136\ttypebranch: 0.210\n",
            "15:58:54 W F-Score\tcolor-fc: 0.746\ttype-fc: 0.540\tfuse: 0.268\tcolorbranch: 0.143\ttypebranch: 0.178\n",
            "15:58:54 Saving model at save-frequency, at epoch 6, step 0\n",
            "15:58:54 Saving model, optimizer, and scheduler.\n",
            "15:59:00 ********** Completed epoch 7 **********\n",
            "15:59:00 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "15:59:00 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "15:59:01 Parameter Group `opt-1`: Starting epoch 8 with 20 steps and learning rate 1.00000E-05\n",
            "15:59:02 Evaluating model at test-frequency\n",
            "15:59:04 Obtained features, validation in progress\n",
            "15:59:04 Metrics\tcolor-fc\ttype-fc\tfuse\tcolorbranch\ttypebranch\n",
            "15:59:04 Accuracy\tcolor-fc: 0.778\ttype-fc: 0.605\tfuse: 0.309\tcolorbranch: 0.148\ttypebranch: 0.198\n",
            "15:59:04 M F-Score\tcolor-fc: 0.778\ttype-fc: 0.605\tfuse: 0.309\tcolorbranch: 0.148\ttypebranch: 0.198\n",
            "15:59:04 W F-Score\tcolor-fc: 0.764\ttype-fc: 0.568\tfuse: 0.290\tcolorbranch: 0.167\ttypebranch: 0.168\n",
            "15:59:04 Saving model at save-frequency, at epoch 7, step 0\n",
            "15:59:04 Saving model, optimizer, and scheduler.\n",
            "15:59:08 ********** Completed epoch 8 **********\n",
            "15:59:08 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "15:59:09 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "15:59:09 Parameter Group `opt-1`: Starting epoch 9 with 20 steps and learning rate 1.00000E-05\n",
            "15:59:10 Evaluating model at test-frequency\n",
            "15:59:12 Obtained features, validation in progress\n",
            "15:59:12 Metrics\tcolor-fc\ttype-fc\tfuse\tcolorbranch\ttypebranch\n",
            "15:59:12 Accuracy\tcolor-fc: 0.753\ttype-fc: 0.605\tfuse: 0.309\tcolorbranch: 0.160\ttypebranch: 0.198\n",
            "15:59:12 M F-Score\tcolor-fc: 0.753\ttype-fc: 0.605\tfuse: 0.309\tcolorbranch: 0.160\ttypebranch: 0.198\n",
            "15:59:12 W F-Score\tcolor-fc: 0.736\ttype-fc: 0.568\tfuse: 0.280\tcolorbranch: 0.168\ttypebranch: 0.162\n",
            "15:59:12 Saving model at save-frequency, at epoch 8, step 0\n",
            "15:59:12 Saving model, optimizer, and scheduler.\n",
            "15:59:18 ********** Completed epoch 9 **********\n",
            "15:59:18 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "15:59:18 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "15:59:19 Parameter Group `opt-1`: Starting epoch 10 with 20 steps and learning rate 1.00000E-05\n",
            "15:59:19 Evaluating model at test-frequency\n",
            "15:59:21 Obtained features, validation in progress\n",
            "15:59:21 Metrics\tcolor-fc\ttype-fc\tfuse\tcolorbranch\ttypebranch\n",
            "15:59:21 Accuracy\tcolor-fc: 0.790\ttype-fc: 0.617\tfuse: 0.309\tcolorbranch: 0.173\ttypebranch: 0.198\n",
            "15:59:21 M F-Score\tcolor-fc: 0.790\ttype-fc: 0.617\tfuse: 0.309\tcolorbranch: 0.173\ttypebranch: 0.198\n",
            "15:59:21 W F-Score\tcolor-fc: 0.779\ttype-fc: 0.565\tfuse: 0.301\tcolorbranch: 0.172\ttypebranch: 0.165\n",
            "15:59:21 Saving model at save-frequency, at epoch 9, step 0\n",
            "15:59:21 Saving model, optimizer, and scheduler.\n",
            "15:59:27 ********** Completed epoch 10 **********\n",
            "15:59:27 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "15:59:27 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "15:59:27 Final: Evaluating model at test-frequency\n",
            "15:59:28 Obtained features, validation in progress\n",
            "15:59:28 Metrics\tcolor-fc\ttype-fc\tfuse\tcolorbranch\ttypebranch\n",
            "15:59:28 Accuracy\tcolor-fc: 0.778\ttype-fc: 0.605\tfuse: 0.309\tcolorbranch: 0.185\ttypebranch: 0.210\n",
            "15:59:28 M F-Score\tcolor-fc: 0.778\ttype-fc: 0.605\tfuse: 0.309\tcolorbranch: 0.185\ttypebranch: 0.210\n",
            "15:59:28 W F-Score\tcolor-fc: 0.761\ttype-fc: 0.555\tfuse: 0.285\tcolorbranch: 0.196\ttypebranch: 0.172\n",
            "15:59:28 Final: Saving model at save-frequency\n",
            "15:59:28 Saving model, optimizer, and scheduler.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resp = eml.eval()"
      ],
      "metadata": {
        "id": "1TKOd-tGOBGY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c423fe10-ccfd-4c1c-8ced-b5ee3a2131d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "15:59:29 Obtained features, validation in progress\n",
            "15:59:29 Metrics\tcolor-fc\ttype-fc\tfuse\tcolorbranch\ttypebranch\n",
            "15:59:29 Accuracy\tcolor-fc: 0.778\ttype-fc: 0.605\tfuse: 0.309\tcolorbranch: 0.185\ttypebranch: 0.210\n",
            "15:59:29 M F-Score\tcolor-fc: 0.778\ttype-fc: 0.605\tfuse: 0.309\tcolorbranch: 0.185\ttypebranch: 0.210\n",
            "15:59:29 W F-Score\tcolor-fc: 0.761\ttype-fc: 0.555\tfuse: 0.285\tcolorbranch: 0.196\ttypebranch: 0.172\n"
          ]
        }
      ]
    }
  ]
}