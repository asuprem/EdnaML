EXECUTION:
  OPTIMIZER_BUILDER: ClassificationOptimizer
  MODEL_SERVING: False
  EPOCHS: 5
  SKIPEVAL: False
  TEST_FREQUENCY: 1
  TRAINER: ClassificationTrainer
  TRAINER_ARGS: 
    accumulation_steps: 1

DATAREADER: 
  DATAREADER: TorchvisionDatareader
  GENERATOR_ARGS:
    tv_dataset: CIFAR10
    tv_args: 
      root: "Data/"
      args:
        download: true
  DATASET_ARGS:
    label_name: cifar_classes
    num_labels:

SAVE:
  MODEL_VERSION: 1
  MODEL_CORE_NAME: cifar10_resnet
  MODEL_BACKBONE: res18
  MODEL_QUALIFIER: cifar


TRANSFORMATION:
  BATCH_SIZE: 32
  WORKERS: 2
  ARGS:
    i_shape: [32,32]
    normalization_mean: [0.4914, 0.4822, 0.4465]
    normalization_std: [0.2470, 0.2435, 0.2616]
    normalization_scale: 0.5
    channels: 3

TRAIN_TRANSFORMATION:
  ARGS:
    i_shape: [32,32]
    normalization_mean: [0.4914, 0.4822, 0.4465]
    normalization_std: [0.2470, 0.2435, 0.2616]
    normalization_scale: 0.5
    channels: 3
    h_flip: 0.5
    t_crop: True

TEST_TRANSFORMATION:
  ARGS:
    i_shape: [32,32]
    normalization_mean: [0.4914, 0.4822, 0.4465]
    normalization_std: [0.2470, 0.2435, 0.2616]
    normalization_scale: 0.5
    channels: 3
    h_flip: 0

MODEL:
  BUILDER: ednaml_model_builder
  MODEL_ARCH: ClassificationResnet
  MODEL_BASE: resnet18
  MODEL_NORMALIZATION: bn
  MODEL_KWARGS: {}


LOSS:
  - LOSSES: ['SoftmaxLogitsLoss']
    KWARGS: [{}]
    LAMBDAS: [1.0]
    NAME: out1
    LABEL: cifar_classes

OPTIMIZER:
  - OPTIMIZER: AdamW
    OPTIMIZER_NAME: opt-1
    OPTIMIZER_KWARGS: {}
    BASE_LR: 1.0e-3
    LR_BIAS_FACTOR: 1.0
    WEIGHT_DECAY: 0.0005
    WEIGHT_BIAS_FACTOR: 0.0005
  
SCHEDULER:
  - LR_SCHEDULER: StepLR
    SCHEDULER_NAME: opt-1
    LR_KWARGS: 
      step_size: 1
      gamma: 0.8

LOGGING:
  STEP_VERBOSE: 100 # Batch
  INPUT_SIZE: [32, 3, 32, 32] 