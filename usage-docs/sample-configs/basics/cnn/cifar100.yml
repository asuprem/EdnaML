EXECUTION:
  OPTIMIZER_BUILDER: ClassificationOptimizer
  MODEL_SERVING: False
  EPOCHS: 10
  SKIPEVAL: True
  TEST_FREQUENCY: 5
  FP16: False
  TRAINER: ClassificationTrainer
  TRAINER_ARGS: 
    accumulation_steps: 1

DATAREADER: 
  DATAREADER: TorchvisionDatareader
  GENERATOR_ARGS:
    tv_dataset: CIFAR100
    tv_args: 
      root: "Data/"
      args:
        download: true
  DATASET_ARGS:
    label_name: label
    num_labels:


SAVE:
  MODEL_VERSION: 1
  MODEL_CORE_NAME: configtest
  MODEL_BACKBONE: res18
  MODEL_QUALIFIER: cifar100
  DRIVE_BACKUP: False
  SAVE_FREQUENCY: 5 # Epoch
  CONFIG_BACKUP:
    STORAGE: mlflow
    FREQUENCY: 0  # i.e. only once
  LOG_BACKUP:
    STORAGE: mlflow
    FREQUENCY: -1 # never
  MODEL_BACKUP:
    STORAGE: mlflow
    FREQUENCY: # If none, use SAVE_FREQUENCY
  MODEL_ARTIFACTS_BACKUP:
    STORAGE: mlflow
  MODEL_PLUGIN_BACKUP:
    STORAGE: mlflow
  METRICS_BACKUP:
    STORAGE: mlflow

STORAGE:
  - NAME: mlflow
    TYPE: MlflowStorage
    STORAGE_ARGS:
    URL: "./Backup/"

TRANSFORMATION:
  BATCH_SIZE: 32
  WORKERS: 2
  ARGS:
    i_shape: [32,32]
    normalization_mean: 0.1307
    normalization_std: 0.3081
    normalization_scale: 0.5
    random_erase: False
    random_erase_value: 0.5
    channels: 3

TRAIN_TRANSFORMATION:
  ARGS:
    h_flip: 0.5
    t_crop: True

TEST_TRANSFORMATION:
  ARGS:
    h_flip: 0

MODEL:
  BUILDER: ednaml_model_builder
  MODEL_ARCH: ClassificationResnet
  MODEL_BASE: resnet18
  EMBEDDING_DIMENSIONS:
  MODEL_NORMALIZATION: bn
  MODEL_KWARGS:
    
  PARAMETER_GROUPS: 
    - opt-1

LOSS:
  - LOSSES: ['SoftmaxLogitsLoss']
    KWARGS: [{}]
    LAMBDAS: [1.0]
    NAME: out1
    LABEL: label

OPTIMIZER:
  - OPTIMIZER: Adam
    OPTIMIZER_NAME: opt-1
    OPTIMIZER_KWARGS: {}
    BASE_LR: 1.0e-4
    LR_BIAS_FACTOR: 1.0
    WEIGHT_DECAY: 0.0005
    WEIGHT_BIAS_FACTOR: 0.0005
  
SCHEDULER:
  - LR_SCHEDULER: StepLR
    SCHEDULER_NAME: opt-1
    LR_KWARGS: 
      step_size: 5
      gamma: 0.1

LOGGING:
  STEP_VERBOSE: 100 # Batch