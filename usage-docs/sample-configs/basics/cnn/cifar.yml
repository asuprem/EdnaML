EXECUTION:
  OPTIMIZER_BUILDER: ClassificationOptimizer
  MODEL_SERVING: False
  EPOCHS: 10
  SKIPEVAL: True
  TEST_FREQUENCY: 5
  FP16: False
  DATAREADER: 
    DATAREADER: TorchvisionDatareader
    GENERATOR_ARGS:
      tv_dataset: CIFAR10
      tv_args: 
        root: "Data/"
        args:
          download: true
    DATASET_ARGS:
      label_name: label
      num_labels:
  TRAINER: ClassificationTrainer
  TRAINER_ARGS: 
    accumulation_steps: 1

SAVE:
  MODEL_VERSION: 1
  MODEL_CORE_NAME: configtest
  MODEL_BACKBONE: res18
  MODEL_QUALIFIER: cifar
  DRIVE_BACKUP: False
  LOG_BACKUP: False
  SAVE_FREQUENCY: 5 # Epoch


TRANSFORMATION:
  BATCH_SIZE: 32
  WORKERS: 2
  ARGS:
    i_shape: [28,28]
    normalization_mean: 0.1307
    normalization_std: 0.3081
    normalization_scale: 0.5
    random_erase: False
    random_erase_value: 0.5
    channels: 3

TRAIN_TRANSFORMATION:
  ARGS:
    h_flip: 0.5
    t_crop: True

TEST_TRANSFORMATION:
  ARGS:
    h_flip: 0

MODEL:
  BUILDER: ednaml_model_builder
  MODEL_ARCH: ClassificationResnet
  MODEL_BASE: resnet18
  EMBEDDING_DIMENSIONS:
  MODEL_NORMALIZATION: bn
  MODEL_KWARGS:
  PARAMETER_GROUPS: 
    - opt-1

LOSS:
  - LOSSES: ['SoftmaxLogitsLoss']
    KWARGS: [{}]
    LAMBDAS: [1.0]
    NAME: out1
    LABEL: label

OPTIMIZER:
  - OPTIMIZER: Adam
    OPTIMIZER_NAME: opt-1
    OPTIMIZER_KWARGS: {}
    BASE_LR: 1.0e-4
    LR_BIAS_FACTOR: 1.0
    WEIGHT_DECAY: 0.0005
    WEIGHT_BIAS_FACTOR: 0.0005
  
SCHEDULER:
  - LR_SCHEDULER: StepLR
    SCHEDULER_NAME: opt-1
    LR_KWARGS: 
      step_size: 5
      gamma: 0.1

LOGGING:
  STEP_VERBOSE: 100 # Batch