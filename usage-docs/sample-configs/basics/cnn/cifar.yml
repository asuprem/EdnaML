EXECUTION:
  OPTIMIZER_BUILDER: ClassificationOptimizer
  MODEL_SERVING: False
  EPOCHS: 5
  SKIPEVAL: False
  TEST_FREQUENCY: 1
  FP16: False
  TRAINER: ClassificationTrainer
  TRAINER_ARGS: 
    accumulation_steps: 1

DATAREADER: 
  DATAREADER: TorchvisionDatareader
  GENERATOR_ARGS:
    tv_dataset: CIFAR10
    tv_args: 
      root: "Data/"
      args:
        download: true
  DATASET_ARGS:
    label_name: label
    num_labels:

SAVE:
  MODEL_VERSION: 1
  MODEL_CORE_NAME: cifar10_resnet
  MODEL_BACKBONE: res18
  MODEL_QUALIFIER: cifar
  DRIVE_BACKUP: False
  LOG_BACKUP: False
  SAVE_FREQUENCY: 5 # Epoch


TRANSFORMATION:
  BATCH_SIZE: 32
  WORKERS: 2
  ARGS:
    i_shape: [32,32]
    normalization_mean: 0.1307
    normalization_std: 0.3081
    normalization_scale: 0.5
    random_erase: False
    random_erase_value: 0.5
    channels: 3

TRAIN_TRANSFORMATION:
  ARGS:
    h_flip: 0.5
    t_crop: True

TEST_TRANSFORMATION:
  ARGS:
    h_flip: 0

MODEL:
  BUILDER: ednaml_model_builder
  MODEL_ARCH: ClassificationResnet
  MODEL_BASE: resnet18
  EMBEDDING_DIMENSIONS:
  MODEL_NORMALIZATION: bn
  MODEL_KWARGS:
  PARAMETER_GROUPS: 
    - opt-1

LOSS:
  - LOSSES: ['SoftmaxLogitsLoss']
    KWARGS: [{}]
    LAMBDAS: [1.0]
    NAME: out1
    LABEL: label

OPTIMIZER:
  - OPTIMIZER: Adam
    OPTIMIZER_NAME: opt-1
    OPTIMIZER_KWARGS: {}
    BASE_LR: 1.0e-3
    LR_BIAS_FACTOR: 1.0
    WEIGHT_DECAY: 0.0005
    WEIGHT_BIAS_FACTOR: 0.0005
  
SCHEDULER:
  - LR_SCHEDULER: StepLR
    SCHEDULER_NAME: opt-1
    LR_KWARGS: 
      step_size: 5
      gamma: 0.1

LOGGING:
  STEP_VERBOSE: 100 # Batch
  INPUT_SIZE: [32, 3, 32, 32] 