{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "3LtQmhmQ1T_8"
      },
      "source": [
        "# Metrics in EdnaML and EdnaDeploy\n",
        "\n",
        "Here, we examine EdnaML's metrics infrastructure. Most metrics are essentially wrappers around their Torchmetrics "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "BZOO_ELa0PRM"
      },
      "source": [
        "# Setup Steps (If EdnaML is not already installed)\n",
        " \n",
        "We can install either from source or from PyPi. The appropriate option can be selected from the first cell below.\n",
        "\n",
        "**Very Important**. Due to the way Colab installs certain packages, you will need to restart the runtime after installing EdnaML. Then you can proceed with future steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9n75eBgQXl7p",
        "outputId": "285a4edf-df02-4d0c-83b8-4af1d2b3c88a"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J7AZehvZ0i2X"
      },
      "outputs": [],
      "source": [
        "install_from = \"source\" # source | pypi\n",
        "branch = \"suprem-devel-mongo-metrics\"           # DO NOT CHANGE THIS unless you know what you are doing\n",
        "version = \"0.1.5\"           # DO NOT CHANGE THIS unless you know what you are doing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5j3WfN0fpIT"
      },
      "source": [
        "###  Installation steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBWvd4b10spk",
        "outputId": "80382658-b13b-4383-b9ef-b0ec10827ad1"
      },
      "outputs": [],
      "source": [
        "if install_from == \"source\":\n",
        "  ! rm -rf -- EdnaML ||:\n",
        "  ! git clone -b $branch https://github.com/asuprem/EdnaML\n",
        "  ! pip install -e EdnaML/\n",
        "else:\n",
        "  ! python -V\n",
        "  ! pip3 install --pre ednaml==$version"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Restart Runtime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "  import ednaml\n",
        "except (ImportError, KeyError, ModuleNotFoundError):\n",
        "  print('Stopping RUNTIME. Colaboratory will restart automatically.')\n",
        "  exit()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "JY04vJjxCGaD"
      },
      "source": [
        "# Metrics Basics\n",
        "\n",
        "We will run a few experiments using the basic [MNIST configuration](./mnist.yml). See [cnn.ipynb](../0-basics/cnn/cnn.ipynb) for more details on MNIST and EdnaML.\n",
        "\n",
        "We have added a few things here for Metrics on top of the Storage and experimentation components. Specifically, we have added the `METRICS` section with a single metric:\n",
        "\n",
        "```\n",
        "METRICS:                      # Defining metrics to be tracked. This needs to be made top-level\n",
        "  MODEL_METRICS:\n",
        "    - METRIC_NAME: avgacc\n",
        "      METRIC_CLASS: BaseTorchMetric\n",
        "      METRIC_ARGS:\n",
        "        metric_name: Accuracy\n",
        "        aggregate: 100\n",
        "        metric_kwargs:\n",
        "          task: 'multiclass'\n",
        "          num_classes: 10\n",
        "      METRIC_PARAMS: \n",
        "        preds: logits\n",
        "        targets: labels  # basically, key is what the metric expects, value is what WILL be there, e.g. HFTrainer could have labels, not targets, so it would be targets: labels\n",
        "      METRIC_TRIGGER: step\n",
        "      METRIC_STORAGE: null\n",
        "```\n",
        "\n",
        "Here, we have set up a Metric for the model (more details about specific metrics can be found at []). You can add metrics for each component to track different KPIs, e.g. metrics for the Logger, Cnfiguration manager, Deployment, and Code. For example you may want to record code quality of provided custom code through some backend service as a metric. You may also want to record number of error logs, warning logs, or debug logs per X training steps. \n",
        "\n",
        "In this case, we have added an Accuracy Metric. Since we want to use the excellent Torchmetrics package, we will use our internal wrapper `BaseTorchMetric`, and provide the correct arguments (`metric_name` is the specific torchmetric we wish to use, and `metric_kwargs` are the arguments for the above class). \n",
        "\n",
        "Then, we have `METRIC_PARAMS`. Each module publishes a set of parameters internally that metrics have access to. For example, `BaseTrainer` publishes `loss` at each step. `ClassificationTrainer`, which we use for MNIST, publishes loss, as well as `logits`, `labels`, `features` and the current `epoch` and `step`, among others. For accuracy, we require `logits` and `labels`. However, `torchmetrics.Accuracy` takes in `preds` and `targets` as input. So we provide this mapping in `METRIC_PARAMS` so that our metrics can access the correct arguments to compute metrics.\n",
        "\n",
        "Finally, we have `METRIC_TRIGGER`, which can be one of `[once | always | step | batch]`, meaning it is triggered just once at beginning, always whenever some parameter changes inside a module, at the end of each step, or at the end of a batch of steps (batch determined by `LOGGING.STEP_VERBOSE`). We want to compute accuracy at each step. However, we also want to aggregate the accuracy for saving across 100 steps, so we set the `aggregate` parameter in `METRIC_ARGS` to 100.\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "QzffsEaj1P2e"
      },
      "source": [
        "## 0. Setting up the MNIST model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93KF2dwKk9HO"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wP4BmCySkb85"
      },
      "outputs": [],
      "source": [
        "# Here we define our custom model class\n",
        "from ednaml.models import ModelAbstract\n",
        "from torch import nn\n",
        "import ednaml.core.decorators as edna\n",
        "\n",
        "class MNISTModel(ModelAbstract):\n",
        "  def model_attributes_setup(self, **kwargs):\n",
        "    pass\n",
        "  def model_setup(self, **kwargs):\n",
        "    self.conv1 = nn.Sequential(         \n",
        "        nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, stride=1, padding=2), \n",
        "        nn.ReLU(), \n",
        "        nn.MaxPool2d(kernel_size=2),    \n",
        "    )\n",
        "    self.conv2 = nn.Sequential(         \n",
        "        nn.Conv2d(16, 32, 5, 1, 2), nn.ReLU(), nn.MaxPool2d(2),                \n",
        "    )\n",
        "    # fully connected layer, output 10 classes\n",
        "    self.out = nn.Linear(32 * 7 * 7, 10)\n",
        "    \n",
        "  def forward_impl(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.conv2(x)\n",
        "    # flatten the output of conv2 to (batch_size, 32 * 7 * 7)\n",
        "    x = x.view(x.size(0), -1)       \n",
        "    output = self.out(x)\n",
        "    # A ModelAbstract returns prediction, features, and secondary output (empty list)\n",
        "    return output, x, []    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "hgqvDUeTUK6R",
        "outputId": "e2e60aaf-b5d3-4eb0-e5f0-79194f7a4f29"
      },
      "outputs": [],
      "source": [
        "import torch, ednaml\n",
        "from ednaml.core import EdnaML\n",
        "torch.__version__"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Basic MNIST Experiment\n",
        "\n",
        "We first run our basic MNIST experiment, with the default options."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOdO13uRkiyu",
        "outputId": "f817dcbd-d72c-4745-d9db-65aefd7cca89"
      },
      "outputs": [],
      "source": [
        "EdnaML.clear_registrations()\n",
        "cfg = \"./EdnaML/usage-docs/sample-configs/3-metrics/mnist.yml\"\n",
        "eml = EdnaML(config=cfg, config_inject = [\n",
        "    (\"MODEL.MODEL_BASE\", \"simple\"),  \n",
        "    (\"SAVE.MODEL_BACKBONE\", \"simple\"),  \n",
        "    (\"EXECUTION.SKIPEVAL\", True),  \n",
        "    (\"TRANSFORMATION.BATCH_SIZE\", 64),   # We will also increase the batch size\n",
        "    (\"LOGGING.INPUT_SIZE\", [64,1,28,28]),   # We will also fix the input size\n",
        "])\n",
        "eml.cfg.MODEL.MODEL_KWARGS = {}       # We delete the old MODEL_KWARGS, because our new model needs no arguments\n",
        "eml.addModelClass(MNISTModel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOoRZIDdmac5",
        "outputId": "87f6f70e-1ce9-4f6f-fc3f-0fcb203bdb01"
      },
      "outputs": [],
      "source": [
        "# These are the default options.\n",
        "eml.apply(  storage_manager_mode = \"strict\",\n",
        "            storage_mode = \"local\",\n",
        "            backup_mode = \"hybrid\",\n",
        "            tracking_run = 0,\n",
        "            new_run = False,\n",
        "            skip_storage = False\n",
        "          )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djlAOyYdmo9w",
        "outputId": "d58a57ae-3e49-43d0-ba1c-7e7d3c92388e"
      },
      "outputs": [],
      "source": [
        "eml.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FiCRi_eBgghQ"
      },
      "outputs": [],
      "source": [
        "eml.eval()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## What to note\n",
        "\n",
        "On the file view (if you are on Colab), you should see a directory called `mnist_resnet-v1-simple-mnist` that contains a directory `0`. Inside this, there should be several pytorch files and log files.\n",
        "\n",
        "Here, the name of the experiment is `mnist_resnet-v1-simple-mnist`, inherited from the `MODEL_CORE_NAME`, `MODEL_VERSION`, `MODEL_BACKBONE`, and `MODEL_QUALIFIER` in the `SAVE` section of the [configuration, linked here](mnist.yml#L20).\n",
        "\n",
        "`0` is the run for this experiment. There should be a `metrics.json` with the computed metrics."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Backing up metrics (in canonical mode)\n",
        "\n",
        "We will let `storage_mode=\"empty\"` instead of `local`. Here, no local files will be created. Note: we have incremented the version to `2` in `config_inject`, so if `storage_mode` was local, the expected directory would be `mnist_resnet-v2-simple-mnist`. However, it will not be created."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOdO13uRkiyu",
        "outputId": "f817dcbd-d72c-4745-d9db-65aefd7cca89"
      },
      "outputs": [],
      "source": [
        "EdnaML.clear_registrations()\n",
        "cfg = \"./EdnaML/usage-docs/sample-configs/3-metrics/mnist.yml\"\n",
        "storage = \"./EdnaML/usage-docs/sample-configs/3-metrics/mnist_simple_storage.yml\"\n",
        "eml = EdnaML(config=[cfg,storage], config_inject = [\n",
        "    (\"MODEL.MODEL_BASE\", \"simple\"),  \n",
        "    (\"SAVE.MODEL_BACKBONE\", \"simple\"),  \n",
        "    (\"EXECUTION.SKIPEVAL\", True),  \n",
        "    (\"TRANSFORMATION.BATCH_SIZE\", 64),   # We will also increase the batch size\n",
        "    (\"LOGGING.INPUT_SIZE\", [32,1,28,28]),   # We will also fix the input size\n",
        "])\n",
        "eml.cfg.MODEL.MODEL_KWARGS = {}       # We delete the old MODEL_KWARGS, because our new model needs no arguments\n",
        "eml.addModelClass(MNISTModel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOoRZIDdmac5",
        "outputId": "87f6f70e-1ce9-4f6f-fc3f-0fcb203bdb01"
      },
      "outputs": [],
      "source": [
        "# These are the default options.\n",
        "eml.apply(  storage_manager_mode = \"strict\",\n",
        "            storage_mode = \"local\",\n",
        "            backup_mode = \"hybrid\",\n",
        "            tracking_run =1,\n",
        "            new_run = False,\n",
        "            skip_storage = False\n",
        "          )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djlAOyYdmo9w",
        "outputId": "d58a57ae-3e49-43d0-ba1c-7e7d3c92388e"
      },
      "outputs": [],
      "source": [
        "eml.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FiCRi_eBgghQ"
      },
      "outputs": [],
      "source": [
        "eml.eval()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Logging ad-hoc metrics\n",
        "\n",
        "Occasionally, we wish to log metrics independent of the built-in metrics classes. Here, we show such an example: we will create a custom trainer where we log the l2 norm of the model params. While there is already a metric for this [Link??](), this is simply an example.\n",
        "\n",
        "In the custom trainer below, we calculate the running average of the l2 norm over the past 25 steps and save it into the metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ednaml.trainer import ClassificationTrainer\n",
        "import torch\n",
        "class CustomTrainer(ClassificationTrainer):\n",
        "    def beginning_of_training_hook(self):\n",
        "        self.l2check = []\n",
        "    def end_of_step_metrics(self):\n",
        "        l2_norm = sum(torch.linalg.norm(p, 2) for p in self.model.parameters())\n",
        "        self.l2check.append(l2_norm)\n",
        "        if len(self.l2check) >= 25:\n",
        "            final_l2 = sum(self.l2check) / len(self.l2check)\n",
        "            self.log_metric(metric_name = \"modell2\", metric_val = final_l2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOdO13uRkiyu",
        "outputId": "f817dcbd-d72c-4745-d9db-65aefd7cca89"
      },
      "outputs": [],
      "source": [
        "EdnaML.clear_registrations()\n",
        "cfg = \"./EdnaML/usage-docs/sample-configs/3-metrics/mnist.yml\"\n",
        "storage = \"./EdnaML/usage-docs/sample-configs/3-metrics/mnist_simple_storage.yml\"\n",
        "eml = EdnaML(config=[cfg,storage], config_inject = [\n",
        "    (\"MODEL.MODEL_BASE\", \"simple\"),  \n",
        "    (\"SAVE.MODEL_BACKBONE\", \"simple\"),  \n",
        "    (\"EXECUTION.SKIPEVAL\", True),  \n",
        "    (\"TRANSFORMATION.BATCH_SIZE\", 64),   # We will also increase the batch size\n",
        "    (\"LOGGING.INPUT_SIZE\", [32,1,28,28]),   # We will also fix the input size\n",
        "])\n",
        "eml.cfg.MODEL.MODEL_KWARGS = {}       # We delete the old MODEL_KWARGS, because our new model needs no arguments\n",
        "eml.addModelClass(MNISTModel)\n",
        "eml.addTrainerClass(CustomTrainer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOoRZIDdmac5",
        "outputId": "87f6f70e-1ce9-4f6f-fc3f-0fcb203bdb01"
      },
      "outputs": [],
      "source": [
        "# These are the default options.\n",
        "eml.apply(  storage_manager_mode = \"strict\",\n",
        "            storage_mode = \"local\",\n",
        "            backup_mode = \"hybrid\",\n",
        "            tracking_run =2,\n",
        "            new_run = False,\n",
        "            skip_storage = False\n",
        "          )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djlAOyYdmo9w",
        "outputId": "d58a57ae-3e49-43d0-ba1c-7e7d3c92388e"
      },
      "outputs": [],
      "source": [
        "eml.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FiCRi_eBgghQ"
      },
      "outputs": [],
      "source": [
        "eml.eval()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "BZOO_ELa0PRM",
        "MBJsh5aTBzM6",
        "ET2xAQ2Lb9Cs"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "ednaml",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.11 (main, Mar 30 2022, 02:45:55) [MSC v.1916 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "19686624b004a6cf552f6ad0efbc4b51ca83ef7ea52cc5f8653ac17021c6f95e"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
