EXECUTION:
  OPTIMIZER_BUILDER: ClassificationOptimizer
  MODEL_SERVING: False
  EPOCHS: 10
  SKIPEVAL: True
  TEST_FREQUENCY: 5
  FP16: False
  DATAREADER: 
    DATAREADER: DataReader
    CRAWLER_ARGS: {}
    DATASET_ARGS: {}
    GENERATOR: 
    GENERATOR_ARGS: {}
    DATALOADER_ARGS: {}
  TRAINER: BaseTrainer
  TRAINER_ARGS: 
    accumulation_steps: 1
  PLUGIN: {}

DEPLOYMENT:
  OUTPUT_ARGS:
    file_path: deploy-out.txt
  DEPLOY: BaseDeploy
  DEPLOYMENT_ARGS: {}
  EPOCHS: 1
  DATAREADER:
    CRAWLER_ARGS: {}
    DATAREADER: DataReader
    DATASET_ARGS: {}
    GENERATOR: 
    GENERATOR_ARGS: {}
    DATALOADER_ARGS: {}
  FP16: False
  PLUGIN: {}

MODEL_PLUGIN:
  - PLUGIN: ModelPlugin
    PLUGIN_NAME: mp-1
    PLUGIN_KWARGS: {}

SAVE:
  MODEL_VERSION: 1
  MODEL_CORE_NAME: "config"
  MODEL_BACKBONE: "backbone"
  MODEL_QUALIFIER: "all"
  DRIVE_BACKUP: True
  SAVE_FREQUENCY: 5 # Epoch
  CONFIG_BACKUP:
    STORAGE: mongo
    FREQUENCY: 0  # i.e. only once
  LOG_BACKUP:
    STORAGE: gdrive
    FREQUENCY: -1 # never
  MODEL_BACKUP:
    STORAGE: model
    FREQUENCY: # If none, use SAVE_FREQUENCY
  MODEL_ARTIFACTS_BACKUP:
    STORAGE: model
  MODEL_PLUGIN_BACKUP:
    STORAGE: model
  METRICS_BACKUP:
    STORAGE: mlflow

STORAGE:
  - NAME: base
    TYPE: BaseStorage
    STORAGE_ARGS: {}
    URL: ./
  - NAME: mongo
    TYPE: MongoStorage
    STORAGE_ARGS: {"user": "something", "password": something, "port": 8080}
    URL: ./
  - NAME: gdrive
    TYPE: NetworkDriveStorage
    STORAGE_ARGS: {"directory": "./drive/MyDrive/Projects/Experiment/Models"}
    URL: ./
  - NAME: model # and for artifacts and plugins
    TYPE: GDriveStorage
    STORAGE_ARGS: {"user": "something", "token": something}
    URL: ./
  - NAME: mlflow  # for metrics
    TYPE: MlflowStorage
    STORAGE_ARGS: {"tracking_url": "something", "auth": something, "port": 8080}
    URL: ./

TRANSFORMATION:
  BATCH_SIZE: 8
  WORKERS: 1
  ARGS:
    i_shape: [100,100]
    normalization_mean: 0.5
    normalization_std: 0.5
    normalization_scale: 0.5
    random_erase: False
    random_erase_value: 0.5
    channels: 3

TRAIN_TRANSFORMATION:
  ARGS:
    h_flip: 0.5
    t_crop: True

TEST_TRANSFORMATION:
  ARGS:
    h_flip: 0

MODEL:
  BUILDER: ednaml_model_builder
  MODEL_ARCH: ClassificationResnet
  MODEL_BASE: resnet18
  EMBEDDING_DIMENSIONS:
  MODEL_NORMALIZATION: bn
  MODEL_KWARGS:
  PARAMETER_GROUPS: 
    - opt-1

LOSS:
  - LOSSES: ['SoftmaxLogitsLoss']
    KWARGS: [{}]
    LAMBDAS: [1.0]
    NAME: out1
    LABEL: labelname

OPTIMIZER:
  - OPTIMIZER: Adam
    OPTIMIZER_NAME: opt-1
    OPTIMIZER_KWARGS: {}
    BASE_LR: 1.0e-3
    LR_BIAS_FACTOR: 1.0
    WEIGHT_DECAY: 0.0005
    WEIGHT_BIAS_FACTOR: 0.0005
  
SCHEDULER:
  - LR_SCHEDULER: StepLR
    SCHEDULER_NAME: opt-1
    LR_KWARGS: 
      step_size: 5
      gamma: 0.1

LOGGING:
  STEP_VERBOSE: 100 # Batch